身為3D網頁視覺特效工程師，深知此坑水深，我自己時常掉入陷阱。因此希望能夠幫助大家往網頁特效邁進。

前端視覺特效可以做什麼？
很多，最常見的用途是網頁品牌形象、互動體驗。包含你在awwwards.com看到的網站。這是B2C、C2C上常見的。

而我專攻的領域，是B2B，其範圍就很大。例如：

GIS（Geographic Information System 地理資訊系統）
BIM（Building Information Modeling 建築資訊模型）
CFD（Computational Fluid Dynamics 計算流體力學）
廠房監控系統（Facility Monitoring Control System）
模擬系統（如人流、車流模擬）。
數位戰情室（Digital Boardroom）
網頁視覺特效包含哪些做法？
很多。可以用CSS，也可以用SVG。兩者都能做得很傑出。但我會聚焦在使用WebGL做特效。

為什麼選擇WebGL？
因為WebGL的延展性很大，它可以很底層。

先介紹CSS跟SVG如何運作：

CSS可透過修改DOM元素屬性產生特效
SVG身為XML-based的圖檔，修改標籤元素的屬性做特效。甚至透過修改path等方式實作動畫。這些都是相當直覺且快速的特效開發，甚至可以用到少許3D的效果。
然而，如果要往3D走，而且要製作一個自定義的場景，那走入WebGL是不可或缺的。

比如說你要有物理設定：你要做一個有重力的場景，所有物體都會往下掉，甚至每個物體互相有引力。在這個場域中，你就可以完很多互動特效，但若要在CSS或SVG上做，限制就會很多，而且效能上也沒辦法作太多處理。

所以，我這30天會專注在WebGL開發。

WebGL負責將畫面渲染到螢幕上，是低階的API，其寫法跟網頁差異甚大。而開發實務上，大多還是會選定一個較為高階的套件，例如下面幾種：

Three.js(最多網路資源)
Babylon(微軟員工為首所創)
P5.js(Processing.org為首，專注於互動藝術)
以上都能幫助我們實現WebGL。

接下來30天的介紹內容：
我們主題是前端視覺特效，其應用方法很多種，不會只是單一的three.js，但會由它打頭陣。因為它對前端工程師來說是很好的進入點。

反觀如果從WebGL開始學，那學習曲線就太陡了。

第一章：Three.js世界觀
第一篇聚焦在Three.js，因為它網路資源相當多。雖然它官方說明少得可憐，但很多他沒提到的東西，都是業界知識，我除了介紹Three.js以外，業界知識也本次鐵人賽的重點。從入門到進階，逐一介紹three.js的概念模型。包含：

Day2: ThreeJS、OpenGL、WebGL：誰是誰？我要怎麼開始？
https://ithelp.ithome.com.tw/upload/images/20221016/201425058n0ICB5YXs.png
Day3: Three.js空間座標！讓世界繞著我旋轉！
https://ithelp.ithome.com.tw/upload/images/20221016/20142505nJj9eZUx4I.png
Day4: Three.js 什麼！空間被扭曲了？我願稱你為最強——矩陣
https://ithelp.ithome.com.tw/upload/images/20221016/20142505Dl0iNnRAiM.png
Day5: The World！砸瓦魯多！歐拉歐拉歐拉！——歐拉角跟四元數
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-dfa53ca8fc%20(1).gif
Day6: three.js 圓弧的藝術家！弧線的教授！——OrbitControl軌道控制器
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-641e877353.gif
Day7: three.js的一方通行：矢量操作——全面釐清向量與底層特性
https://ithelp.ithome.com.tw/upload/images/20221016/20142505ouFr9wgQ5i.png
Day8: Three.js 你有被光速踢過嗎？解析3D界的黃猿——光的底層原理與介紹
https://ithelp.ithome.com.tw/upload/images/20221016/20142505rxlnLHNJOQ.png
Day9: Three.js 傲慢的太陽——光的開發與矩形區域光原理
https://ithelp.ithome.com.tw/upload/images/20221016/20142505Rwbo4wO4YP.png
第二章：Three.js實戰視覺特效
介紹完後，我會接著在Three.js上介紹視覺特效的應用，包含鏡面特效以及反射玻璃特效，使得作品精緻度可以提高。這階段你會很有成就感。包含：

Day10: three.js 前端視覺特效工程師實戰：全球戰情室—貼圖原理
https://ithelp.ithome.com.tw/upload/images/20221016/20142505jPdnsGlCSd.png
Day11: three.js 前端3D視覺特效開發實戰：全球戰情室—實作地球
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-b504ae8f7a.gif
Day12: three.js 3D地球特效開發實戰：留下飛雷神術式吧！—經緯度座標轉換
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-dbe7549055.gif
Day13: three.js 3D地球特效開發實戰：飛雷神之術走跳地球！—鏡頭追蹤與浮動文字
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-4746f36208.gif
Day14: three.js 3D圖表特效開發實戰—繪畫就跟佐為下棋一樣簡單：線段原理
https://ithelp.ithome.com.tw/upload/images/20221016/20142505oHrqTZzgSE.png
Day15: three.js 前端3D視覺特效開發實戰——3D儀表板：圓餅圖
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-2f1752f7fe.gif
Day16: three.js 前端3D視覺特效開發實戰——3D儀表板：立體圓餅圖、extrude在three獨特差異
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-20fd8bcf1b.gif
Day17: three.js 前端3D視覺特效開發實戰—GIS系統：台灣地理資訊地圖、SVG匯入
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-9d908ba440.gif
Day18: three.js 前端3D視覺特效開發實戰——鄉鎮市區GIS系統：一次搞懂陰影原理並實作
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-ec805edf51.gif
Day19: three.js 前端3D鏡面特效開發實戰：梅利奧達斯的全反射！—智慧工廠檢視器
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-ea0930bb88.gif
Day20: three.js 前端3D視覺特效開發實戰——智慧工廠：倒影特效
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-5c87c77686.gif
Day21: three.js 前端3D視覺特效開發實戰—智慧工廠：鏡頭投影、追蹤與飄移特效
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-f69b6faf45.gif
第三章：Shader實戰視覺特效
等到這些都介紹完之後，會敞開Shader的大門。從這邊開始世界會變得不太一樣。從認識Shader開始，透過Shader創造漸層、光暈。

Day22: WebGL Shader—你好啊大哥哥，沒想到你可以到Shader來呢！
https://ithelp.ithome.com.tw/upload/images/20221016/20142505jiyDr3bh47.png
Day23: WebGL Shader——從認識GLSL開始釐清Shader
https://ithelp.ithome.com.tw/upload/images/20221016/20142505qQaieANOka.png
Day24: WebGL Shader——透過自製環境光實作shader傳值
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-10cecbe3cd.gif
Day:25 使用Shader創造漸層
https://ithelp.ithome.com.tw/upload/images/20221016/20142505UFAloJ3aaH.png
Day26: WebGL Shader—透過Shader製作光暈：速成篇
https://ithelp.ithome.com.tw/upload/images/20221016/2014250518NvoIyVP6.png
Day27: WebGL Shader—透過Shader製作光暈：Shader傳值的原理
https://ithelp.ithome.com.tw/upload/images/20221016/20142505JnYl8YOJbb.png
Day28: WebGL Shader—透過Shader製作光暈（三）
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-375cb61289.gif
Day29: WebGL Shader—用Shader做全視角內光暈、星球材質
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-7694efd45c.gif
Day30: WebGL Shader—製作物件的邊框
https://storage.googleapis.com/umas_public_assets/michaelBay/day01/ezgif-5-3cd8708267.gif
以上內容繁多而且涉及很多面向的應用。但我相信看完這些之後一定功力大增。

https://ithelp.ithome.com.tw/upload/images/20220917/20142505gHhLZLhHuO.png
在開始Three.js之前，得先解釋清楚三者關係。接下來我也會不斷解釋三者關聯。

三者關係
Three.js

上層的API函式庫，負責讓在Canvas裡面執行一些繪圖。他底層是用WebGL API處理繪圖的。

WebGL

一個JS的API，它讓工程師可以控制每一顆像素要呈現的RGB顏色。它會再跟CPU, GPU溝通，最後成功繪製畫面。

OpenGL 或他的子集OpenGL ES

是一個業界標準，他不像WebGL是函式庫，WebGL就是基於這個標準的API。另一方面，假如NVIDIA要制定GPU接口，就需要支援OpenGL標準。

繪製一張圖釐清關聯：
https://ithelp.ithome.com.tw/upload/images/20220917/20142505KIuI3jkJHE.png

我們會從three.js開始，因為比較快速入門。

從three.js開始，要怎麼起頭？
從three.js開始：四個物件
要滿足四樣東西。用現實世界來形容，就是：

鏡頭（camera）捕捉了
畫面（Scene），透過
Renderer 渲染到畫面上，並藉由
requestAnimationFrame不斷更新畫面
前兩個很好理解，但後兩個是什麼？

https://ithelp.ithome.com.tw/upload/images/20220917/20142505NtlVqo0eZJ.png

從three.js開始：Renderer是什麼？
比如說你的螢幕有1920 x 1280，那就有兩百多萬畫素。鏡頭camera捕捉到了場景Scene，要如何呈現在你兩百多萬畫素的螢幕？就需要透過 Renderer了。

從three.js開始：requestAnimationFrame是什麼？
理想上鏡頭一秒60幀渲染在畫面上。這個如「狂按快門」的邏輯就要靠requestAnimationFrame 來處理。

從three.js開始：四者總結
換句話說，WebGLRenderer 是鏡頭捕捉到的場景，呈現在上的重要推手。而requestAnimationFrame 使得它每一幀捕捉一次。在理想狀態下每秒捕捉60次（60FPS）。

從three.js開始：three.js世界觀
在Three的世界裡，大家都是活在笛卡兒三維座標裡面，不像HTML的元素都活在XY的座標系統中。所以說，代表每個物件都有X,Y,Z位置，可以縮放、旋轉、位移。（幾乎啦，但也有例外，如ambientLight）

開始程式碼
要製作最簡單的畫面，承上篇結尾需要四樣的東西。先從scene開始。

開始程式碼：Scene。用來裝所有場景物件的根物件。

const scene = new THREE.Scene();
開始程式碼：Camera。做為我們的鏡頭，選用透視鏡頭PerspectiveCamera即可。

// PerspectiveCamera 需設定四個參數，下面接著介紹
const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
// Camera 身為鏡頭，有位置屬性，設定在Z軸即可。
camera.position.set(0, 0, 15)
四個參數代表什麼？代表fov, aspect, far,near等四個參數。

補充說明：PerspectiveCamera
Camera主要跟兩個：PerspectiveCamera 跟 OrthographicCamera，前者有透視，透者則無。本次我們使用前者，需給定四個參數，以下介紹：

我這邊用攝影鏡頭補充說明。它跟FOV融會貫通：

https://ithelp.ithome.com.tw/upload/images/20220917/20142505FTryM7Vnba.png

（PerspectiveCamera透視說明。圖片來源）

PerspectiveCamera參數：Field Of View (FOV)
我們拿最蝦趴的三鏡頭iPhone為例，他三顆分別是：長焦(52mm)、廣角(26mm)、高級廣角(13mm)。

長焦：你去拿52mm對照上圖。它呈現的範圍相當小，則遠方的細節也相當清楚，看起來很扁。
廣角：一個越廣角的鏡頭，它可以呈現的畫面越廣。
超級廣角：你去拿13mm對照上圖會發現他扭曲的程度。我們假設攝影機可以捕捉的範圍是一個四角錐，則廣角鏡頭的四角錐範圍就相當大，然而邊緣都會扭曲。
而這個變化差距就稱作Field of View，也就是視野的範圍。在這裡，是以角度為單位，一般來說預設是50度（不是mm喔）。這是three.js當中少數以角度而非弧度做為單位的參數。

PerspectiveCamera參數：Aspect
則代表畫面的寬高比例。基本上只要設定為Canvas的寬高比例即可。

PerspectiveCamera參數：Near 與 Far
代表鏡頭最短與最遠可以捕捉到的範圍。

https://ithelp.ithome.com.tw/upload/images/20220917/20142505panmRBoxNs.png
（圖片來源）

開始程式碼：WebGLRenderer。渲染器，用來渲染場景。顧名思義就是渲染出畫布執行。過去three.js提供很多種渲染器，例如CSSRenderer，但以我們的需求WebGLRenderer即可。

// 實例化渲染器
const renderer = new THREE.WebGLRenderer();
// 渲染器負責投影畫面在螢幕上，會需要寬高
renderer.setSize(window.innerWidth, window.innerHeight);
// 渲染器會產生canvas物件，我們在html的body放置它
document.body.appendChild( renderer.domElement );
開始程式碼：再回到Scene。我們要在Scene內建立Mesh物件

可想像成Scene底下的物件。我們可以在場景上加上Mesh物件。
Mesh物件就是最常見的3D物件，你會用它呈現物體。除了Mesh以外，還有Curve、Light這種沒有體積的物件。
Mesh由兩個東西組成，一個是Geometry，一個是Material。可以想像成：Geometry是一個物體的形狀，可以定義成球形、平面、矩形等。Material則是物體所穿的衣服（亦即材質）。
// 建立一個形狀，用來定義物體的形狀為長寬高為1的正方體
const geometry = new THREE.BoxGeometry(1,1,1)
// 建立一個材質，可想像成一個物體所穿的衣服，設定材質為藍色
const material = new THREE.MeshBasicMaterial({color: 0x0000ff})
// 依據前兩者，建立物體
const cube = new THREE.Mesh(geometry, material);
// 放到場景裡，預設位置會是(0,0,0)
scene.add(cube);
開始程式碼：requestAnimationFrame。用以捕捉每幀畫面。在調用requestAnimationFrame()時，它會呼叫自己以執行下一幀。作用很像setinterval()。

提供這個函式後，工程師可以使用特定功能，例如Raycaster、Project、Unproect等等。

// 很像setInterval的函式。每一幀都會執行這個函式
function animate() {
	// 每一幀物體都會自轉
  cube.rotation.x += 0.01;
  cube.rotation.y += 0.01;
	// 它每一幀執行animate()
	requestAnimationFrame( animate );
	// 每一幀，場景物件都會被鏡頭捕捉
	renderer.render( scene, camera );
}
// 函式起始點
animate();
有了以後東西之後，新場景就完成了。

CodePen Example
https://codepen.io/umas-sunavan/pen/VwxpxVB?editors=0010

Three.js跟WebGL之間的關聯
兩者關聯：為什麼場景不需要光？
現實中，我們之所以可以看到東西，是因為有物體、眼睛跟光。你會問為什麼沒有光。

在Three.js的世界裡，一個Mesh（最常見的3D物件）由Geometry跟Material組成。

Geometry：代表物體的形狀。Three.js提供方形、球形等多種形狀，你也可以自訂。
Material：代表材質。則很像是物體「所穿的衣服」。Three提供很多種材質，有些可以反射光，有些根本不理會光。
Shader：three.js提供的Material基本上是由WebGL的Shader渲染。在WebGL的世界裡，沒有光的概念，它只Care每個螢幕像素要裝入什麼顏色。Three.js透過材質跟光，提供給WebGL一個算式，使得WebGL可以計算出每個像素的顏色。
我們目前用的MeshBasicMaterail不需要光，它只看工程師給定給它什麼顏色參數，它就直接傳遞給Shader渲染。我們給他純藍，那他就是純藍，所以這場景不需要光。
兩者關聯：WebGL裡面真的會藏有鏡頭
這是一個延伸思考。實際上，鏡頭什麼的都是Three.js提供的，WebGL裡面沒有所謂鏡頭這東西，WebGL只要求你螢幕上每一個像素你都要給一個顏色。

可是Three.js將鏡頭所投影的成像，經過計算，算出螢幕中每一個像素的顏色。由此，你不需要考慮那麼底層，你只要考慮Three.js的鏡頭怎麼放置就好了。

兩者關聯：以透視為例
我們以透視為例。今天Three.js要在WebGL之上實作透視，那要怎麼處理呢？現在有一條線在三維座標裡，XY的起點是(0,0)終點是(0,10)

假設今天Z值都在1，那麼經由一個計算(10/1=10)，它是10單位寬。
假設今天Z值改在2，那麼經由一個計算(10/2=5)，變成5單位寬。
假設今天Z值改在3，那麼經由一個計算(10/3=3.33)，變成3.33單位寬。
可見，在這個計算下，Z值越大，長度越短。

所以今天那條線是(0,0,1)到(0,10,3)，那Z值大的地方比較短，Z值小的地方比較長。這時候透視就出來了，而這個計算概念變複雜點就變成透視的計算。

在WebGL裡面，透視要自己來做，但在three.js裡面，設定鏡頭的FOV跟位置就解決了。你要是用WebGL自幹透視，包你到最後認不得自己在寫啥，你同事看了保證也不想跟你Code review。所以three.js提供的鏡頭，為的就是加速底層的實作。同理可套用在文中一開始提到的Scene, Renderer，以及three.js官網的所有東西。

我這邊就先帶個概念就好。至少，我們已經做出three.js基本的畫面了。這是踏入Three.js偉大的一步。我們明天介紹座標系。

參考資料

FOV
Perspective
Rendering HTML/CSS in GPU
SKIA Docs
簡書
Cuora
autodesk
discoverthreejs

在HTML我們有X與Y。

但在Three.js的座標系中是三維空間：不僅有XY，還有Z。一切都複雜起來。

我會介紹3D的樹狀結構，這個不只是Three.js，在3D建模也通用。

樹狀結構
3D的世界裡，一個物體底下可以有多個物體組成，形成樹狀結構。

如果你有用過Maya，應該有用過parenting的功能。它讓一個物件變成另一個物件的child。

maya的畫面

在Three.js也是一樣：你可以有Parent物件，內含多個Child物件，組成一個樹狀結構。（這裡的物件可以是群組、可以是Mesh。）

https://ithelp.ithome.com.tw/upload/images/20220918/20142505iIVGIusOfn.png
而parent本身可能自有3D的形狀(geometry)，也可能沒有，比如group就沒有。

樹狀結構：最大的影響是空間
不就XYZ嗎？是這樣沒錯啦….但包含XYZ也成為樹狀結構。

每一個物件都有一個空間數值，這些空間數值都是相對於Parent的。最上層根部的空間，就是世界空間。

https://ithelp.ithome.com.tw/upload/images/20220918/20142505f1Tce2KcMJ.png

再畫嚴謹一點，每一個Mesh都有geometry，都位在local space，而Mesh本身位在parent的local space。最上面的space就是world space。

https://ithelp.ithome.com.tw/upload/images/20220918/20142505w9bMQOSMt2.png

所以說，你會遇到一個情形：parent空間位在世界空間的(10,0,0)，child又活在parent空間的(5,0,0)，但由於Child的位置置相對於parent的，所以它實際上位於(15,0,0)。

https://ithelp.ithome.com.tw/upload/images/20220918/201425056M89DDoakV.png

以程式碼示範
以程式碼示範：準備場景
直接用上一篇的場景：

import * as THREE from 'three';

const scene = new THREE.Scene();

// PerspectiveCamera 需設定四個參數，下面接著介紹
const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
// Camera 身為鏡頭，有位置屬性，設定在Z軸即可。
camera.position.set(0, 0, 15)

// 實例化渲染器
const renderer = new THREE.WebGLRenderer();
// 渲染器負責投影畫面在螢幕上，會需要寬高
renderer.setSize(window.innerWidth, window.innerHeight);
// 渲染器會產生canvas物件，我們在html的body放置它
document.body.appendChild( renderer.domElement );

// 建立一個形狀，用來定義物體的形狀為長寬高為1的正方體
const geometry = new THREE.BoxGeometry(1,1,1)
// 建立一個材質，可想像成一個物體所穿的衣服，設定材質為藍色
const material = new THREE.MeshBasicMaterial({color: 0x0000ff})
// 依據前兩者，建立物體
const cube = new THREE.Mesh(geometry, material);
// 放到場景裡，預設位置會是(0,0,0)
scene.add(cube);

// 很像setInterval的函式。每一幀都會執行這個函式
function animate() {
	// 每一幀物體都會自轉
  cube.rotation.x += 0.01;
  cube.rotation.y += 0.01;
	// 它每一幀執行animate()
	requestAnimationFrame( animate );
	// 每一幀，場景物件都會被鏡頭捕捉
	renderer.render( scene, camera );
}
// 函式起始點
animate();
以程式碼示範：建立child → parent → scene樹狀結構
我把cube拿掉，然後新增了兩個物件：parent跟child


// 換成兩個物件
- const cube = new THREE.Mesh(geometry, material);
+ const parent = new THREE.Mesh(geometry, material);
+ const child = new THREE.Mesh(geometry, material);
然後設定兩個物體的位置

// 接著，把parent加到世界裡，把child加到parent裡
scene.add(parent);
parent.add(child);
// 依據前面的說明，把parent位置改成10，child位置改成5
parent.position.x = 10
child.position.x = 5
這時候，parent位在世界座標的(10,0,0)，child又比parent往左邊5單位

https://ithelp.ithome.com.tw/upload/images/20220918/201425052pcoL0aqXz.png

為了看清楚點，我們把鏡頭往上移動一點點，然後再換一下材質

// 修改鏡頭位置
- camera.position.set(0, 0, 15)
+ camera.position.set(0, 10, 15)
// 換成MeshNormalMaterial
- const material = new THREE.MeshBasicMaterial({color: 0x0000ff})
+ const material = new THREE.MeshNormalMaterial({color: 0x0000ff})
MeshNormalMaterial幫助我們看清楚物件，具體功能之後說明。目前成品如下：

https://ithelp.ithome.com.tw/upload/images/20220918/20142505lDEybWEZ1D.png

現在我們的場景基本上關係長這樣

https://ithelp.ithome.com.tw/upload/images/20220918/20142505x4wdAb8JfQ.png

以程式碼示範：自轉與公轉
接下來我們設定parent自轉，你猜child會往哪裡轉？

function animate() {
-  cube.rotation.x += 0.01;
-  cube.rotation.y += 0.01;
+  parent.rotation.y += 0.01;
	requestAnimationFrame( animate );
	renderer.render( scene, camera );
}
gif圖檔

你會發現，parent在自轉，child在公轉。

為什麼Child在公轉？因為他的local是座標相對於parent的。parent的座標在選轉，child的世界也隨著他選轉。

以程式碼示範：旋轉咖啡杯為例
https://ithelp.ithome.com.tw/upload/images/20220918/20142505wIDxCePHLK.png

圖片版權：Studio Sarah Lou

圖中有茶壺跟茶杯。大家坐在茶杯自轉，茶壺又帶著大家旋轉。

Child是就像是茶杯，Parent就像是茶壺。茶壺是茶杯的座標中心，茶杯就會繞著茶壺公轉。

希望這樣能清楚解釋關聯。

CodePen
https://codepen.io/umas-sunavan/pen/YzLZvpM?editors=0010

有了以上概念之後，我們明天就可以往矩陣繼續解釋。但在繼續之前，先容我介紹設定空間的方法。

設定空間的方法？
設定空間的方法：先解釋目前漏掉沒講的
你可能上一篇就在疑問這一行旋轉的程式碼：

// 旋轉cube
cube.rotation.x += 0.01
你可能會問，如果cube有旋轉（cube.rotation），那是否還有位置（cube.position）？跟縮放（cube.scale）？

答案是有的。

// 指定位置
cube.position.x += 0.01
// 縮放
cube.scale.x += 0.01
那你可能又會問：如果都是有的，那之前code的這一行怎麼邏輯不太一樣？

// 跟前面的指定位置不太一樣
camera.position.set(0, 0, 15)
到底哪個才是正確的，有差別嗎？

這個問題，我會連著空間設置，一起解釋：

設定空間的方法：cube在parent的空間位置
cube是一個Mesh物件，這在我們建立cube就知道了。回顧一下：

// cube是一個Mesh
const cube = new THREE.Mesh(geometry, material);
Mesh是有面的3D物體，重要的屬性有：

Mesh.position 是三維向量Vector3
Mesh.scale 是三維向量Vector3
Mesh**.**rotation 是歐拉角（姑且將他當作三維向量Vector3理解）
以上皆可用.set()來設定該Mesh在parent的絕對位置、旋轉、跟縮放。.set()就像setter。

當然也可以直接取值，例如camera.position.x = 5

又或者，使用函式修改空間位置：

Mesh.translate() 可以位移Mesh.position。

跟.set()不同，.set()設定絕對位置，而它則單純移動位置

https://ithelp.ithome.com.tw/upload/images/20220918/20142505bPXGevQIXe.png

以上這些，都是設定Mesh在parent空間中的位置。

設定空間的方法：cube在local的空間位置
cube 是有自己的形狀的（cube.geometry），自己的形狀活在自己的空間裡。

Mesh.geometry.translate 修改形狀在local空間的位置
Mesh.geometry.rotateXYZ 修改形狀在local空間的旋轉
Mesh.geometry.scale 修改形狀在local空間的縮放
https://ithelp.ithome.com.tw/upload/images/20220918/201425057L3FhB9hy9.png

以上就是設定空間的方法。明天將繼續解釋矩陣。

https://ithelp.ithome.com.tw/upload/images/20220920/201425056NkogjXqqZ.jpg
圖片來源

「矩陣」是最強大的空間扭曲招數。

它比其他「空間忍數」：位移、縮放、旋轉這三個加起來都強！因為他一次就可以作掉這三個，而且解決了這三個的致命缺點——順序！它堪稱像是火影忍者扭曲空間一樣強大！

現在，讓我們習得扭曲空間吧！
回顧上篇，介紹了3D場景中每一個物件的上下層樹狀結構關係。

亦即：child的空間是相對於parent的，parent的空間又是相對於它的parent。

這種結構，位移、縮放、旋轉（下面總稱「形變」）相當麻煩，那不要有樹狀結構不就好了？就把它展開來，大家都在世界空間裡面。

這是很好的方法，但如果你的形變一複雜，你仍要面對順序問題，形變的順序會影響結果。

順序為什麼有差？
我們先看看你隔壁的同事怎麼面對這個問題：

在Figma看這個問題：
他是一個設計師，有一天PM叫他修改設計稿，說要「兩按鈕距離變成30px，然後畫布等比例放大一倍」。

https://ithelp.ithome.com.tw/upload/images/20220919/201425056UOj7T2EjS.png

你同事就往下30px，然後等比例放大一倍。

https://ithelp.ithome.com.tw/upload/images/20220919/20142505t2DywuVbp6.png

PM後來問他：「不是往下30px嗎？怎麼往下60px了？」

同事說：「你不是要變成60px，『然後』放大一倍嗎？」

如果PM今天前後顛倒，講「畫布等比例放大一倍，然後按鈕距離要變成60px」，那結果就會不一樣。

登楞，這才發現這個「然後」很重要。

好啦以上都是虛構我知道很瞎，只是想表達「順序有差」。你在3D場景中「先縮放再位移」，會跟「先位移再縮放」有差別。直接看Code。

在Three.js看這個問題
一樣我從上次的程式碼開始，這邊附上昨天的codePen

https://codepen.io/umas-sunavan/pen/YzLZvpM

我們把樹狀結構拿掉，變成一個只有一個方形的場景。

作法是：先把parent跟child刪掉，改成只剩下cube


// 刪掉parent跟child，換成cube
// const parent = new THREE.Mesh(geometry, material);
// const child = new THREE.Mesh(geometry, material);
const cube = new THREE.Mesh(geometry, material);

// 刪掉parent跟child
// scene.add(parent);
// scene.add(child);
scene.add(cube);

// 不旋轉了
// parent.position.x = 10
// child.position.x = 5

function animate() {
	// 不旋轉了
  // parent.rotation.y += 0.01;
	requestAnimationFrame( animate );
	renderer.render( scene, camera );
}
現在長這樣，很單純。

https://ithelp.ithome.com.tw/upload/images/20220919/20142505xmkQOhwZIi.png

在Three.js看順序問題：先觀察
左圖是先位移再縮放，右圖是先縮放再位移，你會看出差別。

這是CodePen，可以點進去把18、19行互相置換

https://codepen.io/umas-sunavan/pen/JjvNYwY

https://ithelp.ithome.com.tw/upload/images/20220919/20142505NaJOfArx2Y.png

由此可知，順序出現問題。

那該如何解決問題呢？

矩陣
如果沒有學過線性代數也不用慌張，我們重新溫習矩陣，我很簡單的介紹一下。

你還有印象的話，矩陣的乘法像這樣：

https://ithelp.ithome.com.tw/upload/images/20220919/20142505uzo5RPhdQL.png

第一列的4 ，乘上了第一欄的2。那列乘上那欄，變成24

https://ithelp.ithome.com.tw/upload/images/20220919/201425050sOZmAXWCZ.png

第一列的再接續乘上第二欄，得到52。

這樣應該可以喚起你高中的記憶。

矩陣：在程式語言的表示方式與數學不同
喚醒之後，我們這邊要做一點改變：在程式語言中，欄列是相反的。

為什麼？由於程式語言很難表達下面這組矩陣。

// matrix1 x matrix2 = answer
           |2 5|
|4  0 4| x |5 7| = | 24  52|
|1 -9 3|   |4 8|   |-31 -34|
畢竟寫成陣列不太方便計算。為了方便運算起見，從前的工程師就把欄改成列，列改成欄，變成用這個方式表達矩陣：

const matrix1 = [4, 1
				 0,-9
				 4, 3]

const matrix2 = [2, 5, 4
				 5, 7, 8]

const answer = [24, -31,
				52, -34]
你會發現，欄跟列顛倒了！

https://ithelp.ithome.com.tw/upload/images/20220919/201425057YAfhKveHY.png

如果很好奇其中的原因，可以參考這邊：

https://webglfundamentals.org/webgl/lessons/webgl-matrix-vs-math.html

接下來我都改成用程式語言方式表達

矩陣：用來位移
從前從前，有一個天才，發現可以用上面那個計算方式，同時代表位移、縮放、旋轉！

他是這樣辦到的，下面以二維空間說明：

有一個位置，假設(x,y)好了，要位移(tx, ty)。

const position = [x,y]
const translation = [tx, ty]
為了能夠計算，這位天才幫(x,y)加上一個1，變成(x,y,1)

const position = [x,y,1]
天才準備了「單位矩陣」，用來乘以向量

const identityMatrix = [1,0,0,
						0,1,0,
						0,0,1]
position與identityMatrix以相乘，結果會是自己！

// 兩者計算：
//           [x*1 + y*0 + 1*0,
//			x*0 + y*1 + 1*0,
//			x*0 + y*0 + 1*1]

const answer = [x, y, 0]
記得程式的欄列跟數學是相反的。數學用列乘以欄，程式用欄乘以列

https://ithelp.ithome.com.tw/upload/images/20220919/20142505KAE3Bwpd6F.png

這個天才最大的發現是，若修改矩陣，就能位移！假設今天position 要位移 (tx,ty) 單位，至 (x+tx, y+ty)。

const position = [x,y,1]

// 假設今天要移動tx, ty
const translation = [tx, ty]

// 把tx跟ty放在特定的位置即可
const translationMatrix = [1,0,tx,
												0,1,ty,
												0,0,1]

// 兩者計算乘積：
//           [x*1 + y*0 + 1*tx,
//			  x*0 + y*1 + 1*ty,
//			  x*0 + y*0 + 1*1
//						]

//最後位移了
const answer = [x+tx, y+ty, 1]
https://ithelp.ithome.com.tw/upload/images/20220919/201425056nx17Xmj0K.png

這個天才利用矩陣位移了position。回顧他的作法：把tx放到陣列第七位，ty放到第八位。

矩陣：用來縮放
接著，這個天才發現縮放的方法。假設今天position (x,y) 要縮放成 (xsx, ysy)：

const position = [x,y,1]

// 假設今天要縮放sx, sy
const scale = [sx, sy]
把sx, sy放到陣列第一位、第五位即可

// 把sx, sy放在特定的位置即可
const scaleMatrix = [sx,0,0,
					0,sy,0,
					0,0,1]
接著計算

// 兩者計算：
//           [x*sx + y*0 + 1*0,
//			  x*0 + y*sy + 1*0,
//			  x*0 + y*0 + 1*1
//						]

//最後縮放了
const answer = [xs*x, ys*y, 1]
https://ithelp.ithome.com.tw/upload/images/20220919/20142505E4nI4uzimJ.png

矩陣：用來旋轉
這個天才不善罷甘休，他找到了旋轉的方法。假設今天position (x,y) 要旋轉θ (假設移動90度，也就是1/4的PI)

const position = [x,y,1]
const θ = Math.PI / 4
這個天才想到了旋轉的公式。

const ax = x * cos(θ) + y * sin(θ)
const ay = x * -sin(θ) + y * cos(θ)
他端倪了一下，說了聲「那還不簡單」然後毅然決然的放在正確的位置

const rotationMatrix = [cos(θ) ,sin(θ), 0,
						-sin(θ),cos(θ), 0,
					          0,     0, 1]
經過計算，矩陣仍然完勝。

// 兩者計算外積：
//           [x*cos(θ) + y*sin(θ) + 1*0,
//			 -x*sin(θ) + y*cos(θ) + 1*0,
//			       x*0 +      y*0 + 1*1
//						]

const answer = [x*cos(θ)+y*sin(θ), x*-sin(θ)+y*cos(θ), 1]
https://ithelp.ithome.com.tw/upload/images/20220919/20142505QVWPvF4q58.png

因為篇幅關係沒有介紹旋轉的公式。我們先記住這個旋轉的公式就好了。之後再提到Shader時，旋轉的公式會再講解釋一遍。
在Three.js實作該方法
上面可以看出，位移、縮放、旋轉都可以用3x3的矩陣辦到。

這麼好用的東西，再也不用擔心形變的順序問題了。

我只要把參數放在矩陣的正確位置，無論多複雜，都可以用一個矩陣搞定！

Three.js身為強大的函式庫也不會放過這點，提供了一個物件，讓我們快速完成矩陣運算。

const matrix = new THREE.matrix4()
使用set()即可將我們的矩陣放上去，使用applyMatrix4() 能夠將此矩陣套用到cube上。

// 給定單位矩陣（不會有變化）
const matrixArray = [
	1, 0, 0, 0,
	0, 1, 0, 0,
	0, 0, 1, 0,
	0, 0, 0, 1
]
const matrix = new THREE.Matrix4().set(...matrixArray)
cube.applyMatrix4(matrix)
重新溫習一下位移：如果要將cube.position位移到(5,0,0)的話，要改成

const tx = 5
const ty = 0
const tz = 0

const matrixArray = [
	1, 0, 0, tx,
	0, 1, 0, ty,
	0, 0, 1, tz,
	0, 0, 0, 1
]
const matrix = new THREE.Matrix4().set(...matrixArray)
cube.applyMatrix4(matrix)
不僅可以放位移，還能再加上縮放

const sx = 2
const sy = 1
const sz = 1

const matrixArray = [
	sx, 0, 0, tx,
	0, sy, 0, ty,
	0, 0, sz, tz,
	0, 0, 0, 1
]
const matrix = new THREE.Matrix4().set(...matrixArray)
cube.applyMatrix4(matrix)
如此一來，無論是位移、縮放、旋轉，都可以在矩陣裡面完成。如果我們拿上一篇的程式碼來示範，那麼這是我們目前的成果。

https://ithelp.ithome.com.tw/upload/images/20220919/20142505EGQdSYTYG9.png

CodePen
https://codepen.io/umas-sunavan/pen/JjvNYwY

＊請把31~46註解打開，把18、19行註解關掉

在Three.js實作：Matrix4的寫化寫法
每一次都要寫四排數字，也太麻煩了吧？

對，所以Matrix4提供幾個功能方便應用。

makeRotationX, makeRotationY, makeRotationZ: 給定一個弧度，它將回傳全新的旋轉矩陣

const rotateMatrix = new THREE.Matrix4().makeRotationY(Math.PI/4)
cube.applyMatrix4(rotateMatrix)
makeScale: 給定一個縮放倍率，它將回傳全新的縮放矩陣

const scaleMatrix = new THREE.Matrix4().makeScale(2)
cube.applyMatrix4(scaleMatrix)
makeTranslation: 給定一個位移，它將回傳全新的位移矩陣

const translationMatrix = new THREE.Matrix4().makeTranslation(5,0,0)
cube.applyMatrix4(scaleMatrix)
注意，這些都是回傳全新的喔，所以新的會覆蓋舊的。

那要怎樣才能不互相覆蓋？再用乘的即可。

multiply

// 矩陣相乘
const translationMatrix = new THREE.Matrix4().makeTranslation(5,0,0)
const scaleMatrix = new THREE.Matrix4().makeScale(2,1,1)
const combineMatrix = translationMatrix.multiply(scaleMatrix)
cube.applyMatrix4(combineMatrix)
https://ithelp.ithome.com.tw/upload/images/20220919/201425059KueBve1FZ.png

即使我的旋轉跟位移調換，結果仍然一致：

const translationMatrix = new THREE.Matrix4().makeTranslation(5,0,0)
const rotateMatrix = new THREE.Matrix4().makeRotationZ(Math.PI/4)
cube.applyMatrix4(translationMatrix.multiply(rotateMatrix))
https://ithelp.ithome.com.tw/upload/images/20220919/20142505Cv6i1HmooS.png

在Three.js實作：錯誤情境
// 下面這樣順序仍然會有差異
const translationMatrix = new THREE.Matrix4().makeTranslation(5,0,0)
const rotateMatrix = new THREE.Matrix4().makeScale(2,1,1)
cube.applyMatrix4(translationMatrix)
cube.applyMatrix4(rotateMatrix)
// 這樣Translation就被Scale蓋掉了
const wrongMatrix2 = new THREE.Matrix4().makeTranslation(5,0,0).makeScale(2,1,1)
cube.applyMatrix4(wrongMatrix2)
在Three.js實作：附上CodePen
CodePen
可以註解掉我已經寫好的多種方法玩看看。

https://codepen.io/umas-sunavan/pen/JjvNYwY

當然，還有其他好用的函式：

Three.js矩陣的函式
進階旋轉函式
makeRotationAxis ：選定一個軸，以該軸旋轉（不限定純XYZ軸）

makeRotationFromEuler：以歐拉角旋轉（下篇介紹）

makeRotationFromQuaternion：以四元數旋轉

匯入匯出函式
extractRotation：給matrix4.extractRotation()一個Matrix參數，matrix4會把旋轉的部分解出來放到該參數裡面。

setFromMatrixPosition：給matrix4.setFromMatrixPosition()一個Matrix參數，matrix4會把位移的部分解出來放到該參數裡面。

setFromMatrixScale：給matrix4.setFromMatrixScale()一個Matrix參數，matrix4會把縮放的部分解出來放到該參數裡面。

compose 和 decompose：給它三個參數，它可以一口氣組成/解出位移、四元數與縮放

toArray：將matrix匯出成陣列

set：匯入陣列到matrix

進階操作函式
lookAt：給定eye跟target，會根據兩者的方向產生旋轉（up為上）

multiply：相乘matrix，可以用它將不同的matrix串在一起。

以上這些就是矩陣的介紹，希望能幫助大家問題。

想必你已經有疑問了，Quaternion 跟 Euler 到底是什麼？我不斷提及又不斷跳過。

明天我接下來將接著描述Quaternion 四元數跟 Euler 歐拉角，這將比矩陣更難理解，敬請期待。


https://ithelp.ithome.com.tw/upload/images/20220920/2014250542U12mWD7w.jpg

圖片來源

當我們在場景空間裡面對物體旋轉時，它到底是怎麼旋轉的呢？又怎麼儲存旋轉資訊呢？這是因為Three.js召喚了替身——歐拉角與四元數！

它們代替我們在時間暫停下處理旋轉大小事，它是THE WOLRD！
每當我們單純的對物體旋轉時，就好像在時間暫停的時候召喚出歐拉角或是四元數，它們如此強大，導致我們在開發時，都忘記他們的存在。

現在我們就來介紹歐拉角跟四元數。

上一篇矩陣提升了我們對於形變的運用，讓它更簡單。但是「旋轉」仍然是一個難題。

天球問題
假如今天物體要旋轉的軸，既不是X軸，也不是Y軸，亦不是Z軸，它就是指著某一個方向作為軸心旋轉，那該如何實作？

我們舉生活的例子，天空中的北極星。

今天要做一個天球，天空是一個穹頂，天軸是北極星，北極星不在x,y或z=0的位置，那該如何旋轉？

這個單純用rotate.x, rotate.y, rotate.z很難滿足的。

天球

圖片來源

說到這裡，你可能有一個解法：

準備三個Mesh，一個包一個，呈現樹狀結構
第一個Mesh負責旋轉X，第二個Mesh負責旋轉Y，第三個Mesh負責旋轉Z。
最後只保留第三個Mesh呈現物體就好。
就像這樣：

Euler2a.gif

圖片來源

恭喜你，如果你有想到這個解法，看來你就是歐拉轉世。因為歐拉角就是用類似的概念，去描述所謂的旋轉。

要理解歐拉角，你以想像成三個轉軸所旋轉的角度。

這跟絕對位置不太一樣，歐拉角是相對的概念。

假如你是一個戰鬥機，你往北飛，突然你要往左上方飛，那到底有多麼左上呢？

首先，因為你要往上仰，所以你的飛機頭會拉升，產生俯仰（Pitch）的角度。

euler_pitch.gif

接著，因為你往左，所以會有偏航（Yaw）的角度。

euler_yaw.gif

最後，因為你往左飛，所以飛機也會往左傾斜，出現滾轉（Roll）。

euler_roll.gif

上面三張圖來自wiki.ogre3d.org

這三個軸向旋轉了一些角度，來完成「多麼」左上方這件事。

「飛機的方向一定是朝北嗎？所以這三個軸心就是X,Y,Z囉？」答案是：不知道。看你怎麼開飛機，不過以three.js來說，是以X,Y,Z這樣沒錯。

你可能會問：「誰開飛機會記得這樣搞啊？」對啊，你飛機像附圖那樣轉的話，你也差不多要墜機了。

在Three.js應用歐拉角
歐拉提出的歐拉角，設定三個軸的夾角，描述一個角度。

事實上，所有Mesh中的rotation就是用歐拉角描述的。如果你從three.js觀察它物件的屬性，你會看到物件的旋轉資訊，就是用歐拉角儲存的。

也就是說，Mesh、Group、Camera的旋轉，都是用歐拉角來儲存資訊的，就如同用向量來儲存位置、縮放資訊。你不用刻意實例化一個歐拉角來運用，直接使用物件裡的旋轉資料即可應用歐拉角。

我們看three.js官方文件，可以看到Object3D（Mesh, Group, Camera的父類別）的rotation即是一個歐拉角物件。你不用刻意用他，因為你前三個章節都一直用歐拉角來存取角度。

因為你前三個章節取角度

歐拉物件幫助我們描述任何角度的旋轉。

歐拉物件也可以互相轉換，並包含幾個實用的函式：

setFromVector3() ：向量轉成歐拉角。
setFromQuaternion() ：歐拉角轉四元數。
set() ：給定XYZ來轉歐拉角。
setFromRotationMatrix() ：矩陣轉歐拉角 。
在Three.js應用四元數
四元數為四維空間的數，可以用在描述三維的旋轉。

這個影片可以深入了解：

https://eater.net/quaternions/video/intro

與歐拉角所表現的參數不同，四元數在應用上的概念是，描述一個向量，再以該軸旋轉一個角度。而這個方法，就不像歐拉角那樣選定三個軸的夾角。

Untitled

影片節錄自https://eater.net/quaternions/video/intro

而這個方法，就很適合天球的實作。

只要實例化四元數

let quaternion = new THREE.Quaternion()
即可透過這些方法，讓四元數儲存旋轉資料：

setFromAxisAngle：給定一個方向跟角度，它將依據方向為軸心，旋轉角度
setFromEuler：由歐拉角轉成四元數。這讓任何Mesh都可以轉成四元數
setFromRotationMatrix：由旋轉矩陣轉成四元數
set：由x,y,z轉成四元數
此外，還有非常實用的函式：

angleTo：傳入另一個四元數，它可以得出兩者夾角
dot：計算四維點積。
順帶一提在三維向量（Vector3）中，dot()這非常好用，它是計算點積的意思，透過點積，可得知兩向量正交為0，而同方向為1，反方向為-1。前提是它們都是單位向量，亦即向量長度為1。
製作天球
拿上一篇的程式碼修改：

CodePen
https://codepen.io/umas-sunavan/pen/JjvNYwY

import * as THREE from 'three';

const scene = new THREE.Scene();

const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.set(0, 3, 15)

const renderer = new THREE.WebGLRenderer();
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild( renderer.domElement );

const geometry = new THREE.BoxGeometry(1,1,1)
const material = new THREE.MeshNormalMaterial({color: 0x0000ff})
const cube = new THREE.Mesh(geometry, material);
scene.add(cube);

// 錯誤：依序形變，這樣順序相反會有差別
cube.geometry.translate(5,0,0)
cube.geometry.scale(2,1,1)

function animate() {
	// cube.rotation.y += 0.1
	requestAnimationFrame( animate );
	renderer.render( scene, camera );
}
animate();
先把cube改成sphere，讓他變成圓形。

import * as THREE from 'three';

const scene = new THREE.Scene();

const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.set(0, 3, 15)

const renderer = new THREE.WebGLRenderer();
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild( renderer.domElement );

// 改成球體
- const geometry = new THREE.BoxGeometry(1,1,1)
+ const geometry = new THREE.SphereGeometry(1,50,50)// 參數帶入半徑、水平面數、垂直面數
const material = new THREE.MeshNormalMaterial()
//改名為sphere
- const cube = new THREE.Mesh(geometry, material);
- scene.add(cube);
+ const sphere = new THREE.Mesh(geometry, material);
+ scene.add(sphere);

- cube.geometry.translate(5,0,0)
- cube.geometry.scale(2,1,1)

function animate() {
	requestAnimationFrame( animate );
	renderer.render( scene, camera );
}
animate();
https://ithelp.ithome.com.tw/upload/images/20220920/20142505p9FmW0SMuf.png

製作天球：上貼圖
天球是有貼圖的。球的材質必須能夠貼貼圖。我們改一成MeshStandardMaterial，然後建立光源。

// 改成MeshStandardMaterial
- const material = new THREE.MeshNormalMaterial()
+ const material = new THREE.MeshStandardMaterial( { color: 0xffffff}) // 帶入顏色
// 新增環境光
const light = new THREE.AmbientLight(0xffffff,1)
scene.add(light)
我們找到星空的貼圖，貼到球面上。

https://ithelp.ithome.com.tw/upload/images/20220920/20142505cRVibaQ5oD.png

現在球是全白的，因為我們設定MeshStandardMaterial 為白色。

他除了可以帶入顏色作參數，也可以帶入貼圖作參數。

為了要呈現星空，必須帶入貼圖參數（texture），並且由於Mesh預設只有單面可以呈現貼圖，背面不呈現。所以我們要在參數中設定球體雙面（內部跟外部）都可以看見貼圖 （side: THREE.DoubleSide）。

// 匯入材質
const texture = new THREE.TextureLoader().load('/chapter3/free_star_sky_hdri_spherical_map_by_kirriaa_dbw8p0w.jpg')
// 帶入材質，設定內外面
- const material = new THREE.MeshStandardMaterial( { color: 0xffffff, map: texture, side: THREE.DoubleSide})
+ const material = new THREE.MeshStandardMaterial( { map: texture, side: THREE.DoubleSide})
現在，貼圖貼上去了，只是球太小，要放大一下。

+ const geometry = new THREE.SphereGeometry(100,50,50)
- const geometry = new THREE.SphereGeometry(1,50,50)
天球就完成了
圖片來源

接著我們的天球就完成了。

製作天球：讓滑鼠控制鏡頭（非必要）
為了有更棒的體驗，可以加上OrbitControls ，他讓你可以用滑鼠控制鏡頭。注意，它並不屬於three module本身，它位在/examples/jsm/controls/OrbitControls.js 。這個之後會解釋。

import { OrbitControls } from 'https://unpkg.com/three@latest/examples/jsm/controls/OrbitControls.js';
// 帶入鏡頭跟renderer.domElement實例化它即可
new OrbitControls( camera, renderer.domElement );
現在可以透過滑鼠旋轉鏡頭了。

Untitled

製作天球：找出北極星（非必要）
為了找到北極星，我加了兩個東西：

axesHelper 顯示XYZ軸，防止我頭暈迷失方向。
arrowHelper 一個箭頭，幫我指向北極星。
// axesHelper
const axesHelper = new THREE.AxesHelper( 5 );
scene.add( axesHelper );

// arrowHelper
const dir = new THREE.Vector3(-2.49, 4.74, -3.01).normalize();
const origin = new THREE.Vector3( 0, 0, 0 );
const length = 10;
const hex = 0xffff00;
const arrowHelper = new THREE.ArrowHelper( dir, origin, length, hex );
scene.add( arrowHelper );
現在有了箭頭，我找到了北極星，北極星方向在-2.49, 4.74, -3.01的位置：

Untitled

有了這個北極星的位置，就可以把它當作四元數的軸心，讓天球以北極星為中心旋轉。

// 建立四元數
let quaternion = new THREE.Quaternion()
// 即將旋轉的弧度
let rotation = 0
// 由dir為軸心，rotation為旋轉弧度
quaternion.setFromAxisAngle( dir, rotation );
function animate() {
	// 不斷增加弧度
	rotation += 0.001
	// 更新四元數
	quaternion.setFromAxisAngle(dir, rotation)
	// 增加的弧度，要更新在天球上
	sphere.rotation.setFromQuaternion(quaternion)
	...
}
Untitled

這樣一來，我們不僅知道如何應用歐拉角以及四元數，還因此得到一個天球。

事實上，除了四元數很適合製作天球以外，四維矩陣的函式Matrix4.makeRotationAxis() 也可以給定一個軸跟角度來達成天球喔！

Untitled

實作這顆天球也引出了其他角色，例如OrbitControls、MeshStandardMaterial、texture。

我們下一篇將繼續介紹OrbitControls 。

CodePen
天球HDRI來源為CC4.0，作者為kirriaa

https://codepen.io/umas-sunavan/pen/ExLmgGm?editors=1010

參考資料
歐拉角三個角度的解釋

最推薦的四元數介紹互動網站

通俗的介紹四元數

Three.js四元數旋轉

分解四元數

賽馬娘 弧線的教授 圓弧的藝術家 軌道控制器
圖片來源

每個場景都有OrbitControl，就好像每個賽道都有彎道一樣。要是你沒有Orbitcontrol，那就像你沒有「圓弧的藝術家」或是「弧線的教授」一樣，沒辦法在場景發揮作用。

身為一個3D場景，用戶最好可以用滑鼠控制鏡頭。如此一來就可以自由的選擇想要看的角度。如果沒辦法用滑鼠跟畫面互動，那就失去了網頁的意義了。

上一篇，我們用到OrbitControl控制鏡頭，今天我們針對它深入解析。

Control
OrbitControl是什麼？——它即是Control的一種，但Control又是什麼？——是我們對物體的控制，一般來說是控制鏡頭。

OrbitControl顧名思義，就是一個可以環繞中心點的控制鏡頭方式，所以名字才有Orbit。一般來說OrbitControl就可以滿足大部分的需求。

事實上還有很多種控制鏡頭的方式，下面介紹：

OrbitControls：

軌道控制，最常用。你的鏡頭在一個隱形的圓形的軌道中移動，它永遠面向場景中的一個點。預設原點。

ArcballControls：

弧球控制，比軌道控制難用一點的控制，差在可以360度旋轉鏡頭，使得你的鏡頭水平不平衡。

DragControls：

用來拖曳場景中的物件，鏡頭不會移動。

FirstPersonControls & FlyControls & PointerLockControls：

第一人稱視角，沒有軌道概念。

TrackballControls：

跟OrbitControls很像，可是當用戶把鏡頭繞過最頂端之後，並不會繞過頭，而TrackballControls則會。亦即：TrackballControls不會維持正Y軸為上，

TransformControls：

主要是作為控制物件，而非控制鏡頭的。

OrbitControl控制「目標」跟「鏡頭」
它可以控制鏡頭旋轉，但無論怎麼旋轉，鏡頭都看向目標(target) 本身。target是一個位置，描述著鏡頭所看向的中心點。

OrbitControl target rotate orbit

所以OrbitControl主要有兩個東西我們需要注意：

OrbitControl：它會操控你的鏡頭。
你會修改自己的鏡頭位置，它也會。控制鏡頭為至的方式就是修改Camera.position。
OrbitControl.target：鏡頭所看向的目標物件，是一個位置資訊Vecro3。
OrbitControl會控制鏡頭面向target。
OrbitControl為了讓鏡頭面向target，它會修改camera.lookAt()。
你不應該直接修改camera.lookAt()，應當由OrbitControl處理。
可是，OrbitControl不會在每幀渲染時自動控制，得用OrbitControl.update()更新。
好，我知道很複雜，看code最方便。我們看code就好：

實作
直接從上一篇的codePen拿來用

https://codepen.io/umas-sunavan/pen/ExLmgGm

首先，畫面旋轉好暈喔，先把旋轉關掉，並把不必要的東西拔掉，像是箭頭。

- // arrowHelper
- const dir = new THREE.Vector3(-2.49, 4.74, -3.01).normalize();
- const origin = new THREE.Vector3( 0, 0, 0 );
- const length = 10;
- const hex = 0xffff00;
- const arrowHelper = new THREE.ArrowHelper( dir, origin, length, hex );
- scene.add( arrowHelper );

- // 建立四元數
- let quaternion = new THREE.Quaternion()
- // 即將旋轉的弧度
- let rotation = 0
- // 由dir為軸心，rotation為旋轉弧度
- quaternion.setFromAxisAngle( dir, rotation );
function animate() {
- 	// 不斷增加弧度
- 	rotation += 0.001
- 	// 更新四元數
- 	quaternion.setFromAxisAngle(dir, rotation)
- 	// 增加的弧度，要更新在天球上
- 	sphere.rotation.setFromQuaternion(quaternion)
	requestAnimationFrame( animate );
	renderer.render( scene, camera );

}
animate();
以上移除了34~54除了48行外的程式碼。

實作：加上地球做為目標物件（非必要）
加上一顆地球方便我們看結果。其作法跟上篇天球的做法雷同。只是鏡頭活在天球內部、地球外部。

const earthGeometry = new THREE.SphereGeometry(5,50,50)
// 匯入材質
const earthTexture = new THREE.TextureLoader().load('2k_earth_daymap.jpeg')
// 帶入材質，設定內外面
const earthMaterial = new THREE.MeshStandardMaterial( { map: earthTexture, side: THREE.DoubleSide})
const earth = new THREE.Mesh(earthGeometry, earthMaterial);
scene.add(earth);
對了，我還修改了天球的名稱，這段我就不秀出來了。

我所使用的材質圖來源在此。並準備codePen提供大家運用

CodePen
https://codepen.io/umas-sunavan/pen/WNJOxxj

地球材質圖來源

實作：鏡頭上下移動 Pedestal Up/Down
事實上，你可以看到第15行我們其實就已經設定了鏡頭的位置。

// 已經存在的鏡頭位置設定
camera.position.set(0, 10, 15)
如果要讓鏡頭移動，可以在animate中不斷更新值

// 宣告旋轉變數
let rotation = 0

function animate() {
// 每幀更新旋轉變數
	rotation += 0.05
// 更新到位置
	camera.position.set(0,10 + Math.cos(rotation),15) // Math.cos的結果會在1~-1之間移動
	...
}
animate();
如此一來，你的鏡頭就在上下升降。

Pedestal Up, Pedestal Down, earth, camera

CodePen
https://codepen.io/umas-sunavan/pen/qBYjNRw?editors=1010

實作：上下搖攝 Tilt Up/Down
它現在旋轉的是鏡頭的position，你也可以移動鏡頭所面對方向。

你可能有在官方文件看到lookAt()函式，它顧名思義就是旋轉鏡頭的方向，朝向所想的地方，於是這樣寫：

// 建立一個向量，以儲存鏡頭方向
const cameraLookAt = new THREE.Vector3(0,0,0)
let rotation = 0

function animate() {
	rotation += 0.05
-	camera.position.set(0,10 + Math.cos(rotation),15)
+	// 變化該向量
+	cameraLookAt.set(0,0 + Math.cos(rotation),0)
+	// 看向該向量
+	camera.lookAt(cameraLookAt)
	...
}
這樣也行。你的鏡頭會一直點頭，術語叫Tilt，中文翻譯是「上下搖攝」。

Tilt Up, Tilt Down, earth, camera

CodePen
https://codepen.io/umas-sunavan/pen/JjvJKNV?editors=1010

你也可以讓鏡頭靜靜的指向某方，例如(10,10,10)。而不是一直移動：


// 建立一個向量，以儲存鏡頭方向
    const cameraLookAt = new THREE.Vector3(0,0,0)
-   let rotation = 0
    // 移動到animate()之外
    cameraLookAt.set(10,0,0)
    // 移動到animate()之外
    camera.lookAt(cameraLookAt)
    function animate() {
-       // 每幀更新旋轉變數
-       rotation += 0.05
-       // 變化該向量
-       cameraLookAt.set(0,0 + Math.cos(rotation),0)
-       // 看向該向量
-       camera.lookAt(cameraLookAt)
    }
當你玩一玩會發現一個問題：為什麼當滑鼠重新控制鏡頭時，會跳一下？

target, bug, lookAt, earth, camera

這就遇到一個問題了：target不正確

Target不正確問題
我提供了Codepen給大家看這問題：

CodePen
用滑鼠移動鏡頭看看，會發現鏡頭跳掉了。

https://codepen.io/umas-sunavan/pen/vYjZKmO?editors=1010

所謂target不正確，意思是雖然你的鏡頭面向（指lookAt()）了某個方向，但當你再用滑鼠操作時，它從lookAt()的方向重新回到target。你可能會問，lookAt()不就是看向target嗎？

其實不然，這是陷阱。

target問題：那lookAt() 到底是什麼？
如果我們追跟溯源，會看到lookAt()其實是Object3D的函式。Object3D就是Mesh, Group, Camera等物件的父類別，指的是：旋轉物體的方向朝向指定的向量。

也就是說，它只負責旋轉物件。

https://ithelp.ithome.com.tw/upload/images/20220921/20142505TSUSR3q4X7.png

你可能會問：旋轉鏡頭物件不就可以重新指向target嗎？

target問題：不應該用lookAt()旋轉鏡頭？
不應該。target其實是orbitControl所儲存一個向量，表示它所應該要看向的目標。而且在滑鼠事件出現之後，它就會自動執行函式OrbitControl.update() ，使得鏡頭可以看向目標。

所以，嚴格來說，我們「應當」要修改target的位置，使得OrbitControl成為鏡頭轉向的代理人，處理鏡頭轉向的部分，而不是直接用lookAt()修改鏡頭面向的地方。簡而言之就是：不要修改camera的lookAt()，讓OrbitControl來處理，我們只要透過設定OrbitControl.target即可。

為什麼要這樣做呢？

原因藏在它的定義裡頭，你還記得OrbitControl的意思嗎？就是Orbit就是軌道。不是一般的軌道喔！是繞著某個物體旋轉的軌道，就像行星一樣。

＊three.js有些物件有target（例如DirectionalLight），有些則無（如RectAreaLight）。有target就用，沒target那用lookAt()也OK的。

target, orbit, orbitcontrols, earth, camera

圖片來源：https://www.scientificamerican.com/podcast/episode/jupiter-and-venus-squeeze-earths-orbit/

target問題：OrbitControl的本質
Orbit就是繞著某個中心旋轉的軌道，OrbitControl就是繞著中心(target)旋轉的鏡頭，你不讓他朝向中心，那它要繞著誰旋轉？

所以我們總不能搶人家的飯碗，那是它存在的定義啊！

所以說，當我們需要修改位置時，可以執行orbitControl.update() 或者car.position.clone() ，這兩個都可以讓OrbitControl更新鏡頭位置。

在程式上，先將OrbitControls 儲存於一個變數。

- new OrbitControls( camera, renderer.domElement );
+ const control = new OrbitControls( camera, renderer.domElement );
接著，我們把lookAt() 等邏輯移除，改用control.target 。

- // 建立一個向量，以儲存鏡頭方向
- const cameraLookAt = new THREE.Vector3(0,0,0)
- cameraLookAt.set(10,0,0)
- camera.lookAt(cameraLookAt)
+ // 改用這個方法來控制鏡頭的方向
+ control.target.set(10,0,0)
+ control.update()
即可解決前面所提到的錯誤。

target, bug, lookAt, earth, camera

CodePen
https://codepen.io/umas-sunavan/pen/JjvJKJV?editors=1010

總結：target跟lookAt的差異
我們常誤用lookAt()來改變鏡頭面向，但此舉並無改變中心點target。導致用戶操作鏡頭時，OrbitControl變成預設的中心點0,0。
改使用 orbitControl.target = car.position.clone() 就能移動中心點，即使在用戶操作鏡頭時，也能從中心點控制。
希望以上的整理能夠幫助大家。一方通行 矢量操作 three.js 全面釐清向量與底層特性
圖片出處

我們都要有矢量（向量）操作能力
只是差別是，我們不需要像一方通行那樣，吸入必要的氧氣防止能力消失，我們學會了就可以操作！

向量一般來說，是指一個同時具有大小和方向，且滿足平行四邊形法則的幾何對象，在three.js裡面，向量變成一個物件的概念，也就是Vector2, Vector3, Vector4 等。在前面幾篇的介紹理，一定對向量的操作有所體悟，但今天我要打破你對向量在three.js與WebGL效能上的認知。

學一方通行在短時間內分析底層特性來反擊immutable
底層特性：向量構成了這個世界
在three.js，三維的向量稱作Vecor3存在於非常多地方，你的鏡頭位置、鏡頭方向、鏡頭縮放、鏡頭目標都是向量組成，再加上你場景上的所有物件。

底層特性：three.js的向量是不喜歡immutable的
three.js的世界裡有一個區塊是animate()，也就是JS裡面渲染的迴圈。在那個區域裡面，理想上一秒執行60次。如果你在JS渲染的迴圈裡面不斷實例化Vector3，那麼它將一直重新分配Vector3的記憶體位置。再加上場景本身已經有那麼多向量，很容易就會消耗非常多的CPU資源。

舉一個例子好了，今天你修改Vector3的X位置，修改後回傳了新的Vector3物件，導致記憶體重新分配了不只X的位置，還有Y、Z、整個Vector3的位置。雖然說看起來還好，但當你整個場景都是用向量構成，而且每一秒要重新分配60次的時候，這個問題就變得很大了。

於是，這造就了three.js為了最佳化效能，所應用的mutable模式。

底層特性：假設今天你要開發新的three.js
假設你今天是發明three.js的天才工程師，為了避免資源的浪費，你會怎麼設計你的程式呢？

//假設今天要相加兩個向量：
vectorA.add(vectorB) // 方法一、把相加結果加在A上
vectorA.add(vectorB) // 方法二、把相加結果加在B上
vectorA.add(vectorB) // 方法三、把相加結果加在新回傳的向量
雖然方法三才是最immutable的方法，這避免了潛在的javascript開發疏忽，可是如果它放在render()裡面，每次執行都要實例化新向量然後更換整個Vector3的記憶體位置，那就太浪費資源了，不行不行。

而方法A跟方法B相比，放在render裡面的話，好像都沒什麼差別。可是如果選A的話，可以讓函式像chain一樣一直加上去，好像不錯！那就選A好了！

於是乎大家都這樣設計向量的應用方式，你看隔壁棚跟three.js打對台的babylon.js也一樣這麼做。

不止向量，這概念遍佈three.js
跟Immutable概念相反，three.js的很多物件偏向mutable。亦即：物件內部的資訊會一直更動，而物件本身指向的記憶體位址不變。

而這都是效能的考量。

事實上，不止Vecotr3，這樣的概念到處可見。你一旦理解了，就更能快速的認知three.js的世界，成為three.js的一方通行。例如：

Quaternion.multiply()
Matrix4.copyPosition()
Object3D.copy() （Object3D是Mesh, Group, Camera等物件的父類別）
還有很多
事實上你只要在three.js看到有關運算的函式，其運算結果基本上不會實例化新的物件！

不會實例化物件…那要把運算結果放哪裡？但它一定得找地方放計算結果，基本上就是將物件自己的數值換成計算結果。

必備的向量函式
這邊以vector3做介紹：

.lerp()

執行一次就會往v2移動「一段距離」，第二個參數是百分比，定義移動多遠的距離。

執行第二次時，會移動「剩下距離」的再一段距離。以此類推。

以下面這個為例子，第一次執行時v1已經往v3移動了25%，第二次則是剩下距離(75

5)的再25%。然後就會創造出類似ease-out的效果。

lerp vector3 向量函式 three.js webgl

圖片來源

const v1 = new THREE.Vector3(0,0,0)
const v2 = new THREE.Vector3(10,10,10)
const a = v1.lerp(v2,0.25)
console.log(a);
// Vector3 {x: 2.5, y: 2.5, z: 2.5}
順帶一提，四元數有slerp的函式，概念類似。

lerp, slerp, 四元數, vector, three.js, webgl

圖片來源

.addScalar()

幫x,y,z各加上一個數。適合用在拉長一個長度的時候。

const v = new THREE.Vector3(10,5,0)
const a = v.addScalar(5)
console.log(a);
// Vector3 {x: 15, y: 10, z: 5}
.addVectors()

兩向量相加。

const v1 = new THREE.Vector3(10,5,0)
const v2 = new THREE.Vector3(2,6,4)
const a = new THREE.Vector3(0,0,0).addVectors(v1, v2)
console.log(a);
// Vector3 {x: 12, y: 11, z: 4}
.angleTo()

取得兩向量角度

const v1 = new THREE.Vector3(0,5,0)
const v2 = new THREE.Vector3(5,0,0)
const a = v1.angleTo(v2)
console.log(a);
// 1.5707963267948966
// = 0.5 π
.clampLength()

提供上下界，如果達不到上下界，那向量就會被拉長到下界；反之，如果超過上界，那向量就會被壓縮到上界。

const v = new THREE.Vector3(3,4,0)
v.clampLength(10,12)
console.log(v);
// Vector3 {x: 6.000000000000001, y: 8, z: 0}
.distanceTo()

取得兩向量的距離

const v1 = new THREE.Vector3(7,24,0)
const v2 = new THREE.Vector3(14,48,0)
const a = v1.distanceTo(v2)
console.log(a);
// 5
.length()

計算出向量的長度

const v1 = new THREE.Vector3(5,12,0)
const a = v1.length()
console.log(a);
// 13
.multiplyScalar()

向量被拉長N倍。

const v = new THREE.Vector3(9,40,0)
const a = v.multiplyScalar(2)
console.log(a);
// Vector3 {x: 18, y: 80, z: 0}
最推的向量函式
掌握了乘法就是控制了向量。

積（Product）就是「乘出來的結果」。Vector3提供兩個非常有用的工具，在應用網頁時解決我們數學上面的難題。

「積」如果是兩數字相乘的話，結果會是一個數字沒錯。但如果是兩個向量相乘，結果應該要是一個數值呢？還是另一個向量？都幾？

這個「乘」就有不同的作法。在三維向量的乘法中，有兩種最有名，最可以代表向量中的「積」。

那兩種中，有一種乘出來會是一個數字，有一種乘起來會是另外一個向量。

＊以下我們以單位向量（即長度為一單位的向量）來討論。

最推的向量函式：乘出來會是一個數字的那種
Vector3.dot()
可以代表兩個向量的關係。到底在一個空間中，兩條現有「多麼」相近呢？可以給我一個數字代表他們多相近嗎？如果有的話，就是用它了！

舉一個例子說明：假設你在開發開飛機遊戲好了，遊戲要求玩家往目標方向飛，但玩家飛偏了。那到底有多偏呢？玩家飛行方向跟目標方向有多麼相近？這時就可以用Vector3.dot()來表達。

Vector3.dot() 回傳的結果，兩向量越是相近，越是趨近於1。最終如果是同方向，那就是1。相反的，如果兩個向量越是相反，則越趨近-1，如果完全相反，那就是-1。概念很簡單吧？

有這麼一個數字可以代表兩個向量的關係，就可以在開發上解決很多問題了，並且更快做出很多效果了！

就很像在向量A垂直的方向開一盞燈，看向量B有多長一段長度可以投影在A身上。如果是垂直則沒有長度可投影（所以值呈0），如果平行則全部長度都可以投影，同方向是1，反方向是-1

dot, three.js, vector3, webgl, math, cross, dot product

const v1 = new THREE.Vector3(1,0,0)
const v2 = new THREE.Vector3(0.8,0.6,0)
const a = v1.dot(v2)
console.log(a);
// 0.8
最推的向量函式：乘起來會是另外一個向量的那種
Vector3.cross()
前一個方法能很快速的找到兩個向量的關係，但它終究是一個數字，沒辦法代表方向。可不可以給一個「積」是能告訴我兩個向量都面向哪裡，而且多麼相近啊？有的，就是用這種。

這個方法，可以得出一個公垂（亦即都垂直）於兩個向量的向量，於是我們就可以依據這個得出來的向量，觀察原本的兩者有多相近，而那兩者的公垂方向在哪裡。

Vector3.cross() 可呈現藍色部分的向量。A.corss(B)是製造一個公垂向量，同時垂直於A也垂直B。由此，我們不僅可以知道兩個向量多近，還可以透過這個公垂向量，去回推他們發生在哪一個面上。

cross product, dot product, vector3, webgl

影片來自https://www.mathsisfun.com/algebra/vectors-cross-product.html

const v1 = new THREE.Vector3(1,0,0)
const v2 = new THREE.Vector3(0.8,0.6,0)
const a = v1.cross(v2)
console.log(a);
// Vector3 {x: 0, y: 0, z: 0.6}
最推的向量函式：這兩個積到底是何方神聖？
乘出來會是一個數字的那種 ，使用函式Vector3.dot() 。其中的「dot」一詞其實就是dot product的意思，dot product就是點積啦，也就是內積。

乘起來會是另外一個向量的那種，使用函式Vector3.cross() 。其中的「cross」一詞，其實就是cross product，也就是叉積。在三維空間中也可以稱它為外積。

由於它「公垂」兩個向量，所以他至少得存在於三維空間中，在二維空間中是不存在的。
而且，在四維空間中，有點積（dot）、外積（outer）、偶積（even）、叉積（cross）。所以在四維空間中不應稱之為外積，而是叉積。
參考資料
向量，乘就乘，為什麼要叫「內積」？

Dot Product

Cross Product

向量的定義

Section 5-3 : Dot Product

向量外積與四元數

Understanding the Dot Product and the Cross Product

為什麼three.js的vector是mutable的討論
three.js的光
https://ithelp.ithome.com.tw/upload/images/20220923/20142505lBQCIkrPtD.png

圖片來源

有看過航海王的人，應該對這句話非常有印象：「你有被光速踢過嗎？」。

身為海軍三大將的黃猿，最能利用光速打敗對手。跟我們的視覺特效一樣，很多都敗給了光——尤其在處理shader的時候。

開發視覺特效的我們，光暈、光的反射、鏡面等等都需要光。即使在比較高階的three.js裡面開發光，無論是DirectionalLight、AmbientLight、RectAreaLight、HemosphereLight、PointLight都一樣，只要是照到Mesh的，都離不開光。及使用WebGL開發也是。以下介紹：

最常用的光源及其原理
在three.js裡面，光分成很多種，包含：

AmbientLight：環境光
物體的每一個面都吸到一樣的光。其實就是很像直接調整物件的曝光度，簡單粗暴。

AmbientLight, three.js, webGL, light

// 新增環境光
const light = new THREE.AmbientLight(0xffffff,1)
scene.add(light)
AmbientLight, three.js, webGL, light

DirectionalLight：平行光
由一個方向發光。對所有面來說，光的方向都是一樣的

DirectionalLight, three.js, webGL, light

// 新增平行光
const directionalLight = new THREE.DirectionalLight(0xffffff,0.4)
scene.add(directionalLight);
// 新增Helper
const lightHelper = new THREE.DirectionalLightHelper(directionalLight, 20, 0xffff00)
scene.add(lightHelper);
// 更新光源位置
directionalLight.target.position.set(0,0,0);
directionalLight.target.updateMatrixWorld();
// 更新Helper
lightHelper.update();
DirectionalLight, three.js, webGL, light

PointLight：點光
由一個點發光。對所有面來說，光的方向是不一樣的

PointLight, three.js, webGL, light

// 新增點光
const pointLight = new THREE.PointLight(0xffffff, 0.4)
scene.add(pointLight);
// 更新光源位置
pointLight.position.set(3,3,0)
// 新增Helper
const lightHelper = new THREE.PointLightHelper(pointLight, 20, 0xffff00)
// 更新Helper
lightHelper.update();
PointLight, three.js, webGL, light

RectAreaLight：區域光
由一個面發光。對於被投影到的面來說，光的方向是一樣的。對沒被投影到的面來說，光的方向是不一樣的。另外，這是不支援陰影的光。

RectAreaLight, three.js, webGL, light

// 區域光
const rectLight = new THREE.RectAreaLight( 0xffffff, 0.2,  10, 10 );
scene.add( rectLight )
// 更新光源位置
rectLight.position.set( 5, 5, 0 );
// 新增Helper
const rectLightHelper = new RectAreaLightHelper( rectLight );
rectLight.add( rectLightHelper );
RectAreaLight, three.js, webGL, light

不得不說，把區域光放在場景裡真的很漂亮

RectAreaLight, three.js, webGL, light

HemisphereLight：半圓球的光
光從上下發出。等同天空與地面發出的光。

「為什麼叫半圓球？只是兩方向平行光而已」

HemisphereLight, three.js, webGL, light

// 半球光
const hemisphereLight = new THREE.HemisphereLight( 0xffff99, 0x9999ff, 0.2 );
scene.add( hemisphereLight );
上方是黃色，下方是藍色。黃色可以照到地面，使得場景很像黃昏，藍色又可以照到天球，使得天空還是藍色。

HemisphereLight, three.js, webGL, light

這些光怎麼來的？
three.js提供這些光，那麼WebGL會有這些光嗎？

如果有的話，這些光子是怎麼投射到物體，然後反射到鏡頭的？

反射到鏡頭之後，又是怎麼投影到多麼多顆像素上呢？

這邊一一解釋：

dot product, three.js, webGL, light

光就是內積算出的結果
內積的結果：平行光
你現在有一顆球。

dot product,directional light, three.js, webGL, light

假設這球解析度很低，所以這顆球法線長這樣：

dot product, normal, directional light, three.js, webGL, light

然後有一道光，照在球上面：

dot product, normal, directional light, three.js, webGL, light

換句話說，每一個面都指向光源：

dot product, normal, directional light, three.js, webGL, light

光也是一個向量，為了方便計算，我們也給它一個單位向量（長度為一單位的向量），而法線也是：

dot product, normal, unit vector, directional light, three.js, webGL, light

有了這兩個單位向量，就可以透過內積計算這兩條有多相似。內積要怎麼計算兩個單位向量？可以參考上一篇文章。


光的強度 = 法線的單位向量．向光的單位向量
光的強度 = |法線|*|向光|*cos(θ)
由此，我們可以得知每一個法線有多麼面向光，用一個數值表示。

dot product, normal, unit vector, directional light, three.js, webGL, light

你看面向光的那一面，其法線單位向量等同於光，所以最亮，經過內積計算唯一。斜面次之，垂直的面則為零。

而這個數值，就可以成為每一個面有多亮的依據了。

Three.js 以我們常用的光，來實作上面這一段。如此一來，你只要調整光，就不用我們親手處理內積。

dot product, normal, unit vector, directional light, three.js, webGL, light

要怎麼求出法線？它存在的地方：Normal
上面所提及的法線是跟面垂直的線。而3D的世界裡，法線應該要存在哪裡？

法線要由面構成，面是由三角面構成，三角面是透過三個錨點所構成。三個錨點是最原始的資料！因此，我們把「法線」的資料儲存在錨點裡面，於是我們就有了Normal。

「那個向量就叫normal」

normal, directional light, three.js, webGL, light

圖片來源

事實上，不只three.js，隔壁棚的babylon，連3Ds Max、Maya的Arnold，跟非常多3D渲染的工具都如此。

內積的結果：點光
平行光是這樣的：拿法線跟光的方向來計算內積。那點光呢？點光的概念跟平行光相同，但多了點東西，那就是：在點光中，每個面所朝向的光，其方向都不同。

normal, point light, three.js, webGL, light

轉成單位向量之後，即可以看出變化：在平行光時，球體的頭頂的腳底，都是垂直，也就是90度，得出來就是0；可是在點光時，還不到球的頭頂，就已經超過90度了。

normal, point light, three.js, webGL, light

而這樣的角度也意味其內積的結果，如圖：
你如果比較前面所提到的平行光，你會發現：原本朝上跟朝下的面跟光源垂直90度（計算結果為0），但在這裡則垂直超過90度，計算結果為負數，也就是說光照射的範圍更小了。

normal, point light, three.js, webGL, light

聚光燈
讓我們來想想聚光燈是怎麼產生的。

normal, spot light, three.js, webGL, light

其實就是具有遮罩的點光。只要傳入參數，使得聚光可以修改可接受的內積範圍，即可控制大小。

normal, spot light, three.js, webGL, light

重新整理一次
DirectionalLight
也就是平行光，光打在每一個面的方向是一樣的。
PointLight
就是點光，光打在每一個面的方向是輻射狀的。
SpotLight
就是被限制光源角度的點光。
AmbientLight
直接調整物件本身顏色的亮度。沒有陰影
RectAreaLight
非常奇妙，下篇解釋。沒有陰影
以上three.js都幫你包好了
那為什麼我們需要知道？因為在後期，當我們要實作「內光暈」、「外光暈」或是一些特殊的特效時，我們仍需要透過底層的邏輯來實現，身為開發網頁視覺特效的我們不得不知道。而「光」是實作特效的最佳範例，它可是模範生呢！

以上都是比較底層的東西，其實也就是WebGL的計算過程。在WebGL裡面，我們要自己創作光源，得寫一個函式去計算光跟物體normal的關係。

但到了three.js，已經透過WebGL處理掉了光源的製作，並且提供了幾個物件，使我們快速導入光。

雖然人家都包好了，但我們還是得知道以上原理，身為做視覺特效的我們得學會！因為在後面的Shader，我們就得靠自己，不能靠three.js了，不過沒關係，我到時候也會帶大家介紹一遍。

既然知道原理
下一篇將介紹實作。我們知道光的原理，勢必得來實作看看。

除此之外，我也將介紹 RectAreaLight 的原理。


https://ithelp.ithome.com.tw/upload/images/20220924/20142505XJE7Bv3neW.jpg
圖片來源

艾斯卡諾在正中午最強，就如同three.js的光。你可能會覺得：

https://ithelp.ithome.com.tw/upload/images/20220924/20142505XZhOLAs5y4.jpg

圖片來源

我可不是瞎掰喔，聽我解釋。

中午光線最強，就像艾斯卡諾中午最猛，而這是因為跟太陽的角度最小。一切都是角度！我們只要能夠釐清這一切，就能像艾斯卡諾一樣強！

黃猿那篇告訴我們，之所以能夠在3D創造光，是因為有內積。而內積之所以使我們的光線最強，正是因為面的法線角度，跟太陽光的角度最小。

而因為有了內積，我們才能在中午的時候最強大！一起來創造傲慢的太陽吧！

實作地球與太陽
有了上一篇的邏輯概念，我們得知：three.js封裝了幾個物件，使我們快速導入光。

我們以地球為例，示範該如何給地球照光。

實作地球與太陽：附上篇的codepen作開頭
我們一樣拿上一篇的程式碼。

https://codepen.io/umas-sunavan/pen/JjvJKJV

先把上次有關更新target的程式碼拿掉

 // 移除下面三行
- // 改用這個方法來控制鏡頭的方向
- control.target.set(10,0,0)
- control.update()
實作地球與太陽：新增太陽
作法跟地球一致，只是缺一張貼圖：

https://ithelp.ithome.com.tw/upload/images/20220924/20142505QKP6tUZbXx.png

圖片來源

這裡有很不錯的星球材質可以使用，載入圖檔即可。

// 新增太陽
const sunGeometry = new THREE.SphereGeometry(5,50,50)
const sunTexture = new THREE.TextureLoader().load('2k_sun.jpeg')
const sunMaterial = new THREE.MeshBasicMaterial( { map: sunTexture, side: THREE.DoubleSide})
const sun = new THREE.Mesh(sunGeometry, sunMaterial);
scene.add(sun);
實作地球與太陽：把地球移到旁邊
移動position即可。

earth.position.set(20,0,0)
實作地球與太陽：新增DirectionalLight
https://ithelp.ithome.com.tw/upload/images/20220924/20142505cc2fbpRCqM.png

太陽系非常大，大到實際上照到地球的，就是平行光。我們先從平行光開始。

平行光就是DirectionalLight，先實例化它。

// 新增平行光
const directionalLight = new THREE.DirectionalLight(0xffffff, 1)
scene.add(directionalLight);
// 新增Helper
const lightHelper = new THREE.DirectionalLightHelper(directionalLight, 20, 0xffff00)
scene.add(lightHelper);
// 更新位置
directionalLight.target.position.set(20,0,0);
directionalLight.target.updateMatrixWorld();
// 更新Helper
lightHelper.update();
Helper是什麼？
three.js 提供很多種Helper，顧名思義就是輔助你視覺化一些看不到的東西，例如鏡頭邊界、光的邊界。在這裡，DirectionalLightHelper幫我們視覺化平行光的方向跟位置
啊這裡怎麼也有target？
這裡怎麼跟之前****Day6: three.js 圓弧的藝術家！弧線的教授！——軌道控制器****的OrbitControl一樣有target? 因為如同OrbitControl，DirectionalLight 也指向某一個目標，我們必須設定。
updateMatrixWorld()是什麼？
target設定之後，它預設不會更新。我們必須手動更新，所以執行updateMatrixWorld()。
https://ithelp.ithome.com.tw/upload/images/20220924/20142505uSaUnh1lqy.png

這樣就完成了，非常簡單。

https://ithelp.ithome.com.tw/upload/images/20220924/20142505dDBzTR7jD2.png

CodePen
https://codepen.io/umas-sunavan/pen/yLjoqNg?editors=1010

實作地球與太陽：點光的太陽
https://ithelp.ithome.com.tw/upload/images/20220924/20142505GovFXwK0aH.png

雖然說太陽照到地球時幾乎是平行光，但實際上，太陽是一個點光。我們來實作看看點光的太陽。

// 新增點光
const pointLight = new THREE.PointLight(0xffffff, 1)
scene.add(pointLight);
// 新增Helper
const lightHelper = new THREE.PointLightHelper(pointLight, 20, 0xffff00)
scene.add(lightHelper);
// 更新Helper
lightHelper.update();
比較不同的是，點光沒有方向，是四射的，所以沒有target。

https://ithelp.ithome.com.tw/upload/images/20220924/201425058WhQssBUTk.png

可以看到，光在地球的上方跟下方變得比較暗，因為這兩端的面其法線與向光的線夾角過大，導致在內積的計算結果很小。

我已經把地球拉到太陽旁，幾乎世界末日的距離了，相信大家可以看出差別。

CodePen
https://codepen.io/umas-sunavan/pen/WNJEKZo

以上就是太陽光源的實作。

等一下，你都沒介紹RectAreaLight呢！
我介紹平行光、點光、聚光燈（本質是點光）、環境光、半球光，但就是沒有介紹矩形區域光。

矩形區域光很有趣，它可以模擬窗戶進入室內的光。

我沒有找到實際上的程式碼，但有找到有神人實作區域光的過程。

兩種光的合體
根據它的過程，區域光同時有點光，也有平行光的特性。

意思是，一個物體如果都在矩形區域光的投影範圍內，它是平行光。但如果它為位在區域範圍外，它就是點光。而這個邏輯又該怎麼實作呢？也同樣的是內積嗎？

先看看原文：

Step 1.- Project the soon-to-be-shaded point on the plane that contains the area light.
// 將「即將被計算光的點」投影到發光的平面上，以找到面上「被投影的點」

Step 2.- Calculate distance from the center of the rectangle to the projected point.
// 計算發光面的中心到面上被投影的點的距離

Step 3.- Obtain 2D coordinates of the projected point on the plane (how do you call this? the area´s object space?) using the distance calculated in (2) along with area height and width.
// 取得「被投影的點」位在發光面的平面座標

Step 4.- Clamp the projected point in 2D so that it lies inside the area.
// 如果投影過去不在面上，那就取到面上。

Step 5.- This is the area point that lies nearest to our point. Retrieve distance between both points, using the width and height of the area to take back the nearest point to eye-space. This is used to calculate attenuation as usual.
// 接著就可以找到「被投影（且取到面上）的點」，也可因此計算「即將被計算光的點」對它的距離。
// 用發光的面其寬高來把最近的點帶回鏡頭視線（這句我其實也看不太懂），而這也用來計算光的衰減。

Step 6.- In an area light each point is shaded from several directions at once, to simulate this multiply the usual dot product between normal and light direction by a factor and clamp it, so that you get a range of normals that get maximum illumination, then a smooth decay as they turn away from the light.
// 計算「被投影（且取到面上）的點」與面的normal（可理解為法線）的內積。剩下的句子我也不太能理解，但至少我們理解其光的計算方式。
首先，有一個區域光投影在物體上

https://ithelp.ithome.com.tw/upload/images/20220924/20142505PQ9ktxF1sc.png

光投向面，就如同面投向光。我們以這三點為例好了

https://ithelp.ithome.com.tw/upload/images/20220924/2014250573Lu36LNEQ.png

第一步：將「即將被計算光的點」投影到發光的平面上，以找到面上「被投影的點」

https://ithelp.ithome.com.tw/upload/images/20220924/20142505HHbawxyGU8.png

第二步：發光面的中心到被投影的點的距離

https://ithelp.ithome.com.tw/upload/images/20220924/20142505XE0R2VMPUK.png

第三步：取得「被投影的點」位在發光面的平面座標

第四步：如果投影過去不在面上，那就取到面上。

https://ithelp.ithome.com.tw/upload/images/20220924/20142505l1bCCCnE0r.png

第五步：找到「被投影（且取到面上）的點」，也可因此計算「即將被計算光的點」對它的距離。

第六步：計算「被投影（且取到面上）的點」與面的normal（可理解為法線）的內積

https://ithelp.ithome.com.tw/upload/images/20220924/20142505rB0ORTpH5Q.png

如此一來，光就完成了。

從此圖我們可以觀察到，在投影範圍內的物件，向光的單位向量是同方向的，等同於平行光。而不在投影範圍內的物件，其向光的單位向量是不一致的，等同於點光。

https://ithelp.ithome.com.tw/upload/images/20220924/20142505y4mR6j1SgD.png

不在投影範圍內的面，它在三個點的亮度排名中第三名。這是因為它投影到面上面的點，被移動了，而這樣的移動導致它向光的角度有所改變，角度較大，也導致後續在向量的計算中，內積數值最小。

釐清光的原理對於視覺特效有什麼用？
光是向量計算非常實用的運算過程，我們在後續WebGL Shader的製作當中，如果有這樣的概念，要製作自製的特效有非常大的幫助。這道理就如同：一個設計師若理解了圖層、錨點工具或是混合模式之後，不管是Photoshop、illustrator、figma都可以得心應手。
即使我們脫離了three.js的知識領域，到了babylon、webGL或是其他領域時，也可以知道它底層的概念，並且快速上手。
附上所有常用光源的程式碼
程式碼裡面的物件是我自己建模的，可以自行取用。

https://ithelp.ithome.com.tw/upload/images/20220924/20142505yPiVUJvx9i.png

https://ithelp.ithome.com.tw/upload/images/20220924/20142505yPiVUJvx9i.png

CodePen
https://codepen.io/umas-sunavan/pen/xxjXggj?editors=1010

下一步
接下來，我將介紹貼圖，進入貼圖的領域。

參考資料：

頂點法向量

矩形區域光的解釋

WebGL 3D - Directional Lighting


成品
Screen Recording
Screen Recording 2022-09-25 at 3.27.28 PM.gif

本篇我們將完成圖中的地球畫面，從介紹貼圖開始。

做一個地球可以幹嘛？——地球的應用
地球的應用：B2C應用
B2C主要是行銷網站、企業形象網站、活動網站等等。有很多網站都會客製化地球，例如github.com首頁。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505lK9U58L18l.png
圖片來源

地球的應用：B2B應用
至於B2B，也會有地球的需求。主要是全球數位戰情室、航太科技、GIS畫面為主。

例如前端套件Cesium，就是以地球為主軸，提供快速建置視覺畫面的套件。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505p3Ak6pAbaQ.png

圖片來源

地球的應用：全球戰情室
我以為這都是非常中二的東西，現實生活中不會出現，沒想到是我的上班業務範圍之一。

是這樣的，全球有很多大企業在全球設廠。若要能在全球監控各地工廠的生產情形，則以地球作為儀表板的主畫面是再完美不過的排場。全球戰情室並不是只有地球，但它是很重要的元素。

全球戰情室是有市場的，如果要成為前端3D視覺特效工程師，那個地球將是再好不過的作品與應用。

地球的應用：這跟貼圖有什麼關聯？
地球需要很多貼圖要素，是絕佳的實戰對象。除了顏色以外，還有高度，水面與陸地的光澤等等。本篇將透過地球來介紹貼圖的原理，以及實際運用。也會在日後的Shader介紹中留下基礎。

本篇會介紹貼圖原理，下一篇介紹地球實作，再下一篇將介紹前端互動。

理解貼圖的運作模式
貼圖在WebGL中，由vertexShader與fragmentShader共同打造。我這邊不講很多，留著之後WebGL再提，但我嘗試解釋three.js之下的底層原理。

有先，要有一張材質圖跟貼圖的模型。

https://ithelp.ithome.com.tw/upload/images/20220926/20142505Jv4ITMgfrm.png

模型有錨點。

https://ithelp.ithome.com.tw/upload/images/20220925/201425059zK2EuhWc9.png

假設世界地圖是一張大型貼紙，那我們應該如何剪裁這張貼紙並貼到模型呢？最簡單粗暴的方式就是展開模型，對應到貼紙上，接著剪裁貼紙。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505LFYmmQx1IV.png

那這就表示，我們要先「記住」每一個錨點，應該對應到貼紙的哪裡。要如何「記住」這件事情呢？那就是把錨點的位置存在RAM中，而這個位置資訊是一個(X,Y)的座標。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505veCaOYUozi.png

所以說，錨點在3D空間中，除了有一個(X,Y,Z)座標以外，還有貼圖位置的(X,Y)座標了。早期的工程師發現有兩種(X,Y)系統會讓人搞混。

例如你同事告訴你X位置不對，到底是(X,Y,Z)中的X位置不對，還是(X,Y)中的X不對啊？為了分清楚這兩個東西，早期的工程師就稱貼圖的(X,Y)為(U,V)了，其實就是二維座標位置的意思。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505YURtoOx2FZ.png

總之，webGL得展開錨點，記住了所有錨點的UV位置。

你有很多方法可以展開錨點，這個動作就是拆UV，通常是在3D建模軟體拆，例如Maya, 3Ds Max, Blender等等，這是另一門學問。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505TJxZFWLUS7.png

附圖為Maya的UV Editor

順帶一提：展開錨點的方式很多，這都看拆UV的人是怎麼拆的。

https://ithelp.ithome.com.tw/upload/images/20220925/201425058CLiXrl6jc.png

WebGL現在知道錨點的UV位置，我們把焦點放回3D空間中。錨點既然知道自己對應到貼圖的哪個位置，接下來該怎麼辦呢？

https://ithelp.ithome.com.tw/upload/images/20220925/20142505boJqYkd6UQ.png

先退回來補充：WebGL有兩種渲染器，一種是vertexShader，每一個錨點會執行一次，另一種是fragmentShader，每一個像素會執行一次。前面這些對應UV的步驟都由vertexShader處理，接下來計算像素顏色的工作，由fragmentShader處理。

附圖是fragmentShader依據vertexShader的錨點資料產生顏色的示意圖。

Untitled

圖片來源

fragmentShader每一個像素執行一次，一幀大約執行兩百萬次（1920x1280螢幕的話），當執行時，它可以找出該像素在錨點中的對應位置。假如說好了，現在執行的是側面中央偏下的像素，如下圖：

https://ithelp.ithome.com.tw/upload/images/20220926/20142505p6DRbWAlZq.png

我們換這張圖表示：

https://ithelp.ithome.com.tw/upload/images/20220926/201425050cWQZdoe0A.png

那個就可以對應到UV座標的某處。

https://ithelp.ithome.com.tw/upload/images/20220926/20142505dOZsIkPVHk.png

接著，「採樣」貼圖，計算出自己應該要呈現的顏色，呈現在螢幕中。

https://ithelp.ithome.com.tw/upload/images/20220926/20142505sfaCNxwh5K.png

我們得到藍色，所以得知該像素應該呈現藍色。

https://ithelp.ithome.com.tw/upload/images/20220926/201425052oPo5E2c74.png

依照這個邏輯，就可以把貼圖成現在模型上了。

https://ithelp.ithome.com.tw/upload/images/20220926/20142505rHw2kXa2t5.png

數不清的貼圖
數不清的貼圖：變本加厲的工程師
由於以上的過程都經由GPU計算。早期的工程師，透過GPU，很輕鬆的就實現貼圖。

由於GPU實在太香了。我們上一次提到：錨點的運算很消耗計算資源，如果能減少錨點，並且用貼圖來取代建模的工作，就可以減少很多計算資源。

所以又衍生了各種除了RGBA顏色以外的貼圖，以下介紹：

數不清的貼圖：貼圖的種類
一個3D模型有哪塊區域的陰影要更深？——環境光遮蔽(Ambient Occlusion簡稱AO)貼圖
用在哪裡？

上一篇提到，所有光源對物體的投影原理。然而在這個概念模型下，仍然不夠美術去控制光的細節。例如說：為了美術需要，3D場景中人物角色的「事業線」應該要再深一點（舉例啦）。透過這個貼圖，可以讓事業線不要那麼吸光，看起來就比較暗。

舉例說明

或是像下圖一樣減少臉頰的吸光。下圖是取自unity對AO Map的描述。實際上AO Map出現在很多地方，不是three.js專屬。每家的實際演算法也許不同，但道理是相同的。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505hS1pu9TKcf.png

圖片來源

參考連結

又或者看下面的例子。物件的陰影被加深了。左邊是加上AO，右邊是沒有AO的成果。
https://ithelp.ithome.com.tw/upload/images/20220926/201425050FEXVtDx8M.png

圖片來源

參考連結

一個3D模型有多麼明亮？——光線映射(lightMap)貼圖
概念
為通常「Light Backing」技術的貼圖。概念是：把光亮度儲存在材質圖上面。於是不用打光，也可以知道物體應該要多亮。

這是遊戲開發過程中很重要的用途，而three.js也有這樣的map操作。只可惜GLTF檔不支援lightmap，所以lightmap這部分需要額外處理。

下圖的完全沒有光源，一切都是光線映射貼圖踢出來的亮度。

https://ithelp.ithome.com.tw/upload/images/20220926/20142505irPwZv9tKo.png

圖片來源

參考資料：AO與lightmap比較、無法用GLTF攜帶lightmap

一個3D模型有多麼亮晶晶？——高光(Specular)貼圖
原理

上一篇提到，點光反射時，會依照其內積的結果，作為光的強度。如果可以拿一個計算方式，去強化亮度的對比，那就可以呈現個亮晶晶的效果。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505ZYDFSjEM0O.png

參考來源

一個3D模型有哪塊區域像金屬一樣反射？——金屬(metalness)貼圖
通常跟光滑貼圖合併運用。

一個3D模型有哪塊區域很光滑？——光滑(roughness)貼圖
金屬跟光滑搭配會有不同效果，下圖為three.js的金屬、光滑材質球分佈圖。最左邊那欄光滑程度是0，最右邊那欄光滑程度是1。最上面那列金屬程度是1，最下面那列金屬程度是0。這樣的分布能以下圖呈現：

https://ithelp.ithome.com.tw/upload/images/20220925/20142505VAgDS9mlPu.png

圖片來源

一個3D模型有哪塊區域可以反射環境的樣貌？——環境(environment)貼圖
基本上就是拿環境的畫面，將畫面貼在自己身上，形成反射的效果。這個效果對於視覺特效非常好用，在後續也會有專題介紹。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505mdJ8FmBycM.png

圖片來源

一個3D模型有哪塊區域隆起？——灰階高度(displacement map or height map)貼圖
拿一張黑白圖片來使物件隆起。錨點會去採樣顏色——採樣到白色代表錨點應該隆起，採樣到黑色代表錨點不該隆起。如此一來，不需要自己建模，也可以讓貼圖幫你建模。

用途通常是製作地形的時候居多。

這種貼圖跟其他貼圖不太一樣的地方是：其他貼圖可以節省錨點的運用，但這種貼圖是基於錨點的。也就是說，如果錨點密度不夠，則高度的解析度也會不夠。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505ZOoWT7Xli2.png

圖片來源

一個3D模型所有區域的法線(Normal)？——Bump貼圖與Normal貼圖
這貼圖修改了每一個像素反射光的法線。

分兩種：Bump貼圖與Normal貼圖。

https://ithelp.ithome.com.tw/upload/images/20220926/20142505QkeylUPgKr.png

圖片來源

Bump用黑白呈現視覺上隆起的程度，Normal用RGB傾斜法線。Bump如果套用在地球上，就會像這樣：

https://ithelp.ithome.com.tw/upload/images/20220925/201425050wjEbAXklx.png

Bump Map比較好理解，至於Normal Map我用以下幾步驟來說明：

假設有一道平行光照在平面上

https://ithelp.ithome.com.tw/upload/images/20220925/20142505ihntMAUy14.png

我們從中間用剖面圖來觀察平面。平面有光，它跟法線的內積結果假設都是0.6好了。

https://ithelp.ithome.com.tw/upload/images/20220925/201425052luwhBuS3t.png

現在有一個normal貼圖長這樣：內含RGB通道，R越多代表法線向正X歪越多；G越多代表法線向正Y歪越多；B越多代表法線向正Z歪越多。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505qAM3SZ9YT5.png

圖片素材來源

它改變了法線的方向。

https://ithelp.ithome.com.tw/upload/images/20220926/20142505GKRS4dzk7R.png

法線方向改變了，它跟光方向的計算結果也改變了，最後造成亮度的計算結果呈現了變化。圖中，左邊兩塊因為法線接近光的方向，使得內積計算結果增加。右邊兩塊因為法線遠離光的方向，所以計算結果減少。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505nKecthbOMv.png

最後，我們看起來它就像是立體的，但實際上只是一個平面。

https://ithelp.ithome.com.tw/upload/images/20220925/20142505GZOoXhbmdN.png

圖片素材來源

Normal要小心使用。一旦鏡頭視角太傾斜，Normal貼圖還是會出現破綻的

https://ithelp.ithome.com.tw/upload/images/20220925/20142505rdcd2Irnz8.png
圖片來源

統整一下
我們釐清了貼圖的原理

貼圖有很多種，包含：

AO(Ambient Occlusion)貼圖
高光(Specular)貼圖
金屬(metalness)貼圖
光滑(roughness)貼圖
環境(environment)貼圖
高度(displacement)貼圖
凹凸貼圖(bump)或法線(normal)貼圖
下一篇
將上面的貼圖實作到地球上，並且review程式碼。屆時將能夠產出自己的地球，就像文章一開始的預覽圖一樣。

成品
Screen Recording 2022-09-25 at 3.27.28 PM.gif

Screen Recording 2022-09-25 at 3.28.01 PM.gif

看完這篇文章，你將能用three.js開發出地球。

如同前一篇所說，地球可以應用在很多場景上，例如：行銷網站、企業形象網站、活動網站、全球數位戰情室、航太科技、GIS畫面等等。這些對於前端視覺特效都非常重要。

製作地球也能讓我們釐清貼圖底層的運作模式，不僅討論到底層webGL、fragmentShader、vertexShader的渲染方式，也提到很多種貼圖，包含以下貼圖：

顏色(Color)貼圖 → 本篇實作
AO(Ambient Occlusion)貼圖
高光(Specular)貼圖 → 本篇實作
金屬(Metalness)貼圖 → 本篇實作
光滑(Roughness)貼圖 → 本篇實作
環境(Environment)貼圖
高度(Displacement)貼圖 → 本篇實作
凹凸貼圖(Bump)或法線(Normal)貼圖 → 本篇實作
詳情可以看前一篇文章。

在開發完後，仍需要讓用戶能夠跟地球互動，實作的方法可以參考下一篇文章。

讓我們來開始開發地球吧！

準備程式碼
我們從上上次的程式碼開始，以下是程式碼：

CodePen
https://codepen.io/umas-sunavan/pen/WNJEKZo

連結：https://codepen.io/umas-sunavan/pen/WNJEKZo

import * as THREE from 'three';
import { OrbitControls } from 'https://unpkg.com/three@latest/examples/jsm/controls/OrbitControls.js';

const scene = new THREE.Scene();

const camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 0.1, 1000);
// 已經存在的鏡頭位置設定
camera.position.set(0, 0, 90)

const renderer = new THREE.WebGLRenderer();
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild( renderer.domElement );

const geometry = new THREE.SphereGeometry(100,50,50)
console.log(geometry);
// 匯入材質
// image source: https://www.deviantart.com/kirriaa/art/Free-star-sky-HDRI-spherical-map-719281328
const texture = new THREE.TextureLoader().load('free_star_sky_hdri_spherical_map_by_kirriaa_dbw8p0w.jpg')
// 帶入材質，設定內外面
const material = new THREE.MeshBasicMaterial( { color: 0xffffff, map: texture, side: THREE.DoubleSide})
// 新增環境光
const light = new THREE.AmbientLight(0xffffff,0.1)
scene.add(light)

const sphere = new THREE.Mesh(geometry, material);
scene.add(sphere);

// 新增地球
const earthGeometry = new THREE.SphereGeometry(5,50,50)
const earthTexture = new THREE.TextureLoader().load('https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Solarsystemscope_texture_8k_earth_daymap.jpg/800px-Solarsystemscope_texture_8k_earth_daymap.jpg')
const earthMaterial = new THREE.MeshStandardMaterial( { map: earthTexture, side: THREE.DoubleSide})
const earth = new THREE.Mesh(earthGeometry, earthMaterial);
earth.position.set(20,0,0)
scene.add(earth);

// 新增太陽
const sunGeometry = new THREE.SphereGeometry(5,50,50)
const sunTexture = new THREE.TextureLoader().load('https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Map_of_the_full_sun.jpg/800px-Map_of_the_full_sun.jpg')
const sunMaterial = new THREE.MeshBasicMaterial( { map: sunTexture, side: THREE.DoubleSide})
const sun = new THREE.Mesh(sunGeometry, sunMaterial);
scene.add(sun);

// 新增點光
const pointLight = new THREE.PointLight(0xffffff, 1)
scene.add(pointLight);
// 新增Helper
const lightHelper = new THREE.PointLightHelper(pointLight, 20, 0xffff00)
scene.add(lightHelper);
// 更新Helper
lightHelper.update();

// 帶入鏡頭跟renderer.domElement實例化它即可
new OrbitControls( camera, renderer.domElement );

const axesHelper = new THREE.AxesHelper( 5 );
scene.add( axesHelper );

function animate() {
	requestAnimationFrame( animate );
	renderer.render( scene, camera );

}
animate();
準備程式碼：移除本篇用不到的程式碼
修改一下鏡頭與地球位置

- // 已經存在的鏡頭位置設定
- camera.position.set(0, 0, 90)
+ camera.position.set(0, 10, 15)
- earth.position.set(20,0,0)
把光源包成三個函式，純粹是為了好檢視。這些函式你可以在Day9: LightShowcase找到（非必要）

-   // 新增環境光
-   const light = new THREE.AmbientLight(0xffffff,0.1)
-   scene.add(light)

-   // 新增點光
-   const pointLight = new THREE.PointLight(0xffffff, 1)
-   scene.add(pointLight);
-   // 新增Helper
-   const lightHelper = new THREE.PointLightHelper(pointLight, 20, 0xffff00)
-   scene.add(lightHelper);
-   // 更新Helper
-   lightHelper.update();
    // 新增環境光
    const addAmbientLight = () => {
        const light = new THREE.AmbientLight(0xffffff, 0.5)
        scene.add(light)
    }
    // 新增點光
    const addPointLight = () => {
        const pointLight = new THREE.PointLight(0xffffff, 1)
        scene.add(pointLight);
        pointLight.position.set(10, 10, -10)
        pointLight.castShadow = true
        // 新增Helper
        const lightHelper = new THREE.PointLightHelper(pointLight, 20, 0xffff00)
        scene.add(lightHelper);
        // 更新Helper
        lightHelper.update();
    }

    // 新增平行光
    const addDirectionalLight = () => {
        const directionalLight = new THREE.DirectionalLight(0xffffff, 1)
        directionalLight.position.set(0, 0, 10)
        scene.add(directionalLight);
        directionalLight.castShadow = true
        const d = 10;

        directionalLight.shadow.camera.left = - d;
        directionalLight.shadow.camera.right = d;
        directionalLight.shadow.camera.top = d;
        directionalLight.shadow.camera.bottom = - d;

        // 新增Helper
        const lightHelper = new THREE.DirectionalLightHelper(directionalLight, 20, 0xffff00)
        scene.add(lightHelper);
        // 更新位置
        directionalLight.target.position.set(0, 0, 0);
        directionalLight.target.updateMatrixWorld();
        // 更新Helper
        lightHelper.update();
    }

    addPointLight()
    addAmbientLight()
    addDirectionalLight()
移除太陽

-    // 新增太陽
-    const sunGeometry = new THREE.SphereGeometry(5,50,50)
-    const sunTexture = new THREE.TextureLoader().load('https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Map_of_the_full_sun.jpg/800px-Map_of_the_full_sun.jpg')
-    const sunMaterial = new THREE.MeshBasicMaterial( { map: sunTexture, side: THREE.DoubleSide})
-    const sun = new THREE.Mesh(sunGeometry, sunMaterial);
-    scene.add(sun);
修改名字，把sphere改成skydome（非必要）

-   // 匯入材質
-   // image source: https://www.deviantart.com/kirriaa/art/Free-star-sky-HDRI-spherical-map-719281328
-   const texture = new THREE.TextureLoader().load('star_sky_hdri_spherical_map_with_galaxy2 (3).jpg')
-   // 帶入材質，設定內外面
-   const material = new THREE.MeshBasicMaterial( { map: texture, side: THREE.DoubleSide})
-   const geometry = new THREE.SphereGeometry(100,50,50)
-   const sphere = new THREE.Mesh(geometry, material);
-   scene.add(sphere);

    // 改名成skydome
    const skydomeTexture = new THREE.TextureLoader().load('star_sky_hdri_spherical_map_with_galaxy2 (3).jpg')
    const skydomeMaterial = new THREE.MeshBasicMaterial( { map: skydomeTexture, side: THREE.DoubleSide})
    const skydomeGeometry = new THREE.SphereGeometry(100,50,50)
    const skydome = new THREE.Mesh(skydomeGeometry, skydomeMaterial);
    scene.add(skydome);
準備程式碼：移除不必要程式碼後的成果
處理完後，就能方便後續加上材質了

https://ithelp.ithome.com.tw/upload/images/20220926/20142505v5PEGJQglY.png

目前看起來，地球扁扁的。

準備程式碼：為什麼要有點光跟平行光？這樣不就錯了嗎？
原因是這樣的：雖然說實際上光源就只有太陽這個平行光，但平行光的效果真的很單調。點光可以加上畫面的豐富度，我讓它在後續能夠產生反光，襯托出特效。我的大學素描老師教我：素描時未必要忠實的把畫面畫出來，「加上自己的創作也很重要」，我相信特效也是一樣，重點是畫面優美、客戶滿意。

加上貼圖
加上貼圖：灰階高度(displacement map a.k.a height map)
素材來源：http://planetpixelemporium.com/earth8081.html

https://ithelp.ithome.com.tw/upload/images/20220926/20142505kBm9UB8A2P.jpg

const earthGeometry = new THREE.SphereGeometry(5,50,50)
const earthTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/8081_earthmap2k.jpg')
// 新增灰階高度貼圖
const displacementTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/editedBump.jpg')

const earthMaterial = new THREE.MeshStandardMaterial( { 
	map: earthTexture, 
	side: THREE.DoubleSide,
	// 將貼圖貼到材質參數中
	displacementMap:displacementTexture,
})
畫面看起來非常奇怪，怎麼越弄越醜？

https://ithelp.ithome.com.tw/upload/images/20220926/2014250508FWa8zEYo.png

先別急。這是因為前一篇有提到，灰階高度貼圖跟其他貼圖最大的差別是：所有錨點取樣材質圖的顏色以隆起錨點位置。如果我們在地球的MeshStandardMaterial加上wireframe:true，就可以看出原因：

const earthMaterial = new THREE.MeshStandardMaterial( { 
	...
	wireframe:true,
})
https://ithelp.ithome.com.tw/upload/images/20220926/20142505HwWD0CgEYc.png

看起來很醜是因為錨點密度不夠。若是我們將地球的錨點密度增加，那麼高度的解析度也會增加。

- const earthGeometry = new THREE.SphereGeometry(5,50,50)
+ const earthGeometry = new THREE.SphereGeometry(5,600,600)
https://ithelp.ithome.com.tw/upload/images/20220926/20142505UBlfF99xzV.png

你會看到高度解析度增加。但我們也不能太密集。錨點很消耗計算資源，如果開太多錨點，勢必會使GPU不夠的裝置卡頓。

接著我們把wireframe關掉，就可以看到地形已經出來了。

現在地形非常明顯，但有點太明顯了……。為了控制錨點隆起的幅度，我們透過displacementScale 加以處理。

Untitled

const earthMaterial = new THREE.MeshStandardMaterial( { 
	...
	displacementScale:0.5,
})
加上貼圖：金屬(metalness)貼圖
https://ithelp.ithome.com.tw/upload/images/20220926/201425058LvYEunnCK.png

素材來源：http://planetpixelemporium.com/earth8081.html

圖中，白色代表有金屬，黑色代表沒有金屬。這張圖分離了陸地與海洋。我要讓海洋「金屬」一點，所以加入白色。我要讓陸地不金屬一點，所以使用黑色。

const speculatMapTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/8081_earthspec2k.jpg')
const earthMaterial = new THREE.MeshStandardMaterial( { 
	...
	// 加上金屬貼圖
	metalnessMap: speculatMapTexture,
	// 由於預設金屬為0，所以必須調成1，才使得我們的貼圖可以呈現0~1的金屬範圍。黑代表0，白代表1
	metalness:1,
})
加上之後，可以見到海洋因為材質像是金屬的關係，所以變暗很多。

Untitled

為什麼會變黑？

下圖為three.js的金屬、光滑材質球分佈圖。最左邊那欄光滑程度是0，最右邊那欄光滑程度是1。最上面那列金屬程度是1，最下面那列金屬程度是0。這樣的分布能以下圖呈現：

https://ithelp.ithome.com.tw/upload/images/20220926/20142505pCgCpkWBvn.png

圖片來源

金屬材質球普遍顏色較深，這又要回到「向光向量」跟「法線向量」的關係。當向光向量跟法線向量相似時，亮度會較高；當向光向量跟法線向量不相似時，亮度會較低。如果調整線性落差，將可以做出差異。金屬跟光滑是調整線性落差所取得的結果。
加上貼圖：Bump貼圖
https://ithelp.ithome.com.tw/upload/images/20220926/20142505jkJo3JpaYN.jpg

素材來源：http://planetpixelemporium.com/earth8081.html

這張圖是我透過金屬貼圖跟灰階高度貼圖所合成的貼圖。由此，我可以更突出陸地，並且讓山脈更精緻。你會發現，加上了bump，地球就已經相當精緻了。

Untitled

如果你仔細看落磯山山脈，你將能看到很明顯的區別：

https://ithelp.ithome.com.tw/upload/images/20220926/20142505FI96hqSdwH.png

加上貼圖：光滑(roughness)貼圖
素材來源：http://planetpixelemporium.com/earth8081.html

https://ithelp.ithome.com.tw/upload/images/20220926/20142505J4yUqLOwrJ.png

這也是我合成的貼圖，透過這個貼圖，我讓海洋更光滑，讓陸地保持粗糙。這使得海洋會反射光現。凸顯材質的差異感。

const roughtnessTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/8081_earthspec2kReversedLighten.png')
const earthMaterial = new THREE.MeshStandardMaterial( { 
	...
	roughnessMap:roughtnessTexture,
	roughness:0.9,
})
Untitled

加上雲圖
https://ithelp.ithome.com.tw/upload/images/20220926/20142505OFJvRTdmlk.jpg

素材來源：http://planetpixelemporium.com/earth8081.html

一樣從網路上下載雲圖。我們先建立一個新的球體，設定它可為透明。

// 雲的球比地球大一點
const cloudGeometry = new THREE.SphereGeometry(5.4,60,60)
const cloudMaterial = new THREE.MeshStandardMaterial( { 
// 開啟透明功能
	transparent: true, 
})
const cloud = new THREE.Mesh(cloudGeometry, cloudMaterial);
scene.add(cloud);
https://ithelp.ithome.com.tw/upload/images/20220926/20142505Qz8O0FYhUu.png

並且將雲圖的材質、雲圖的透明材質加上去，這使得球體貼上雲的貼圖，並且可以穿透看到地球陸地的模樣。

很多人會忘記加上transparent:true，如果沒有加上，那就沒辦法呈現透明。

// texture source: http://planetpixelemporium.com/earth8081.html
const cloudTransparency = new THREE.TextureLoader().load('8081_earthhiresclouds4K.jpg')
const cloudMaterial = new THREE.MeshStandardMaterial( { 
// 開啟透明功能
	transparent: true, 
// 加上透明貼圖
	opacity: 1,
	alphaMap: cloudTransparency
})
const cloud = new THREE.Mesh(cloudGeometry, cloudMaterial);
scene.add(cloud);
https://ithelp.ithome.com.tw/upload/images/20220926/20142505QS32kr27TB.png

設定雲圖：這個雲不是錯的嗎？
雲嚴格來說不會一致的往同一個方向旋轉，但為了快速製作雲，我使用一張雲的貼圖處理。

能不能用即時的雲圖資料呈現畫面呢？其實是可以的，過去我有一個side project就是在抓取氣象局的雲圖，以渲染成3D畫面，如果有興趣的話可以查看開源原始碼作研究。而網路上也有提供全球雲圖資訊的服務，都可以拿來發揮。

https://ithelp.ithome.com.tw/upload/images/20220927/201425050UCBwcbrZp.png
網站連結
開源程式碼

有興趣的工程師可以深入研究。

設定旋轉
地球要旋轉，雲也要轉，背景的星星也是。這三個如果速度不同，也能增加層次感，使得我們的地球更生動。

雲的真實度依照專案而定。網路上有些服務是可以提供實際上的雲圖資料，但我們這次從簡——直接讓全部的雲往同一個方向旋轉。

function animate() {
	...
	earth.rotation.y +=0.005
	cloud.rotation.y +=0.004
	sphere.rotation.y += 0.001
}
成品
Untitled

如此一來，地球就完成了。

CodePen
這邊附上codepen連結。

https://ithelp.ithome.com.tw/upload/images/20220926/20142505TuJ3vJR4fG.png

https://codepen.io/umas-sunavan/pen/eYreGpa

跨入修圖領域
以上你會發現，好像只要找到圖，要做多酷的特效都可以。

是的，有圖就可以，但圖從哪裡來？這會是一個重點。以上有幾張圖是依據本專案需求網路上合成出來，如果要做出其他特效，勢必就要透過一些修圖軟體去製作貼圖。當跨到貼圖領域時，這就是一種必備技能。有些公司有專門出的美術當你同事，然而一旦沒有美術幫忙，這就會是前端視覺特效的業務。

而這又是另一個領域了。我們點到為止，聚焦在前端開發與底層概念即可。

下篇
雖然我們做出很漂亮的地球，但這對前端視覺特效工程師來說只是一開始。要能夠跟用戶互動才是重點。為了製作出互動，必須有一些UI介面輔助操作。包含快速跳轉到各處的廠房，並且在地球上顯示廠房的名稱。

下篇將實作這段開發，使得我們的地球不只是地球，而是有商業價值的前端產品。

成品
globe created from three.js coordinate converted longitude and latitude

為什麼要做地球？
回顧原因，它可以應用在很多場景上，例如：行銷網站、企業形象網站、活動網站、全球數位戰情室、航太科技、GIS畫面等等。這些對於前端視覺特效都非常重要。

製作地球也能讓我們釐清貼圖底層的運作模式，不僅討論到底層webGL、fragmentShader、vertexShader的渲染方式，也提到很多種貼圖。

但除了一顆地球在畫面還不夠，仍然需要一點互動，使得地球具有體驗的價值，以及商業上的價值。

實作互動功能
目前為止，我們雖然完成了地球的視覺畫面，但很顯然的，光地球不夠。我們是網頁設計師，用戶應該可以在畫面中互動，才算得上是網頁。否則，一切都只是螢幕保護程式而已。

繼上一篇實作地球之後，我們將提供用戶在各大城市位置中放置圖釘。

使用技術
漸變位移——lerp
單位向量轉換——normalize
用三角函數實作座標轉換——llarToEcef
客戶情境
很多國際設廠的公司會有中控台，以快速釐清各家廠房的運作情況。當然也可能會綜合參數模擬、生產線效率監控、災害告警等。而地球正是中控台印入眼簾的畫面，作為B2B數位孿生的公司，地球的地位相當重要。

而前端的需求大概就是開發類似NASA中控中心的系統，或是全球的子公司/廠房儀表板畫面，使得所有人可以看清楚各地工廠在全球的最新動態。很中二吧？

現今，越來越多中控台從Unity應用程式搖身一變成為網頁的需求。而前端首當其衝就是要把畫面弄得最好，同時還能提供用戶CRUD跟RWD的工具。

以下開發我將聚焦在跳轉畫面，我盡量使用最單純的JS（Vanilla Javascript）示例。

開發鏡頭跳躍功能
開發功能：準備程式碼
我這邊準備好了上一篇的程式碼，我們將沿用。

import * as THREE from 'three';
import { OrbitControls } from 'https://unpkg.com/three@latest/examples/jsm/controls/OrbitControls.js';

const scene = new THREE.Scene();

const camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.set(0, 10, 15)

const renderer = new THREE.WebGLRenderer({ antialias: true });
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild(renderer.domElement);

// 匯入材質
// image source: https://www.deviantart.com/kirriaa/art/Free-star-sky-HDRI-spherical-map-719281328
const skydomeTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/free_star_sky_hdri_spherical_map_by_kirriaa_dbw8p0w%20(1).jpg')
// 帶入材質，設定內外面
const skydomeMaterial = new THREE.MeshBasicMaterial({ map: skydomeTexture, side: THREE.DoubleSide })
const skydomeGeometry = new THREE.SphereGeometry(100, 50, 50)
const skydome = new THREE.Mesh(skydomeGeometry, skydomeMaterial);
scene.add(skydome);

// 新增環境光
const addAmbientLight = () => {
	const light = new THREE.AmbientLight(0xffffff, 0.5)
	scene.add(light)
}

// 新增點光
const addPointLight = () => {
	const pointLight = new THREE.PointLight(0xffffff, 1)
	scene.add(pointLight);
	pointLight.position.set(10, 10, -10)
	pointLight.castShadow = true
	// 新增Helper
	const lightHelper = new THREE.PointLightHelper(pointLight, 5, 0xffff00)
	// scene.add(lightHelper);
	// 更新Helper
	lightHelper.update();
}

// 新增平行光
const addDirectionalLight = () => {
	const directionalLight = new THREE.DirectionalLight(0xffffff, 1)
	directionalLight.position.set(0, 0, 10)
	scene.add(directionalLight);
	directionalLight.castShadow = true
	const d = 10;

	directionalLight.shadow.camera.left = - d;
	directionalLight.shadow.camera.right = d;
	directionalLight.shadow.camera.top = d;
	directionalLight.shadow.camera.bottom = - d;

	// 新增Helper
	const lightHelper = new THREE.DirectionalLightHelper(directionalLight, 5, 0xffff00)
	// scene.add(lightHelper);
	// 更新位置
	directionalLight.target.position.set(0, 0, 0);
	directionalLight.target.updateMatrixWorld();
	// 更新Helper
	lightHelper.update();
}

addPointLight()
addAmbientLight()
addDirectionalLight()

const earthGeometry = new THREE.SphereGeometry(5, 600, 600)
const earthTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/8081_earthmap2k.jpg')
// 灰階高度貼圖
const displacementTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/editedBump.jpg')
const roughtnessTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/8081_earthspec2kReversedLighten.png')
const speculatMapTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/8081_earthspec2k.jpg')
const bumpTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/8081_earthbump2k.jpg')

const earthMaterial = new THREE.MeshStandardMaterial({
	map: earthTexture,
	side: THREE.DoubleSide,
	roughnessMap: roughtnessTexture,
	roughness: 0.9,
	// 將貼圖貼到材質參數中
	metalnessMap: speculatMapTexture,
	metalness: 1,
	displacementMap: displacementTexture,
	displacementScale: 0.5,
	bumpMap: bumpTexture,
	bumpScale: 0.1,
})
const earth = new THREE.Mesh(earthGeometry, earthMaterial);
scene.add(earth);

const cloudGeometry = new THREE.SphereGeometry(5.4, 60, 60)
// 匯入材質
// texture source: http://planetpixelemporium.com/earth8081.html
const cloudTransparency = new THREE.TextureLoader().load('8081_earthhiresclouds4K.jpg')
// 帶入材質，設定內外面
const cloudMaterial = new THREE.MeshStandardMaterial({
	transparent: true,
	opacity: 1,
	alphaMap: cloudTransparency
})
const cloud = new THREE.Mesh(cloudGeometry, cloudMaterial);
scene.add(cloud);

// 帶入鏡頭跟renderer.domElement實例化它即可
new OrbitControls(camera, renderer.domElement);

const axesHelper = new THREE.AxesHelper(5);
scene.add(axesHelper);

function animate() {
	requestAnimationFrame(animate);
	renderer.render(scene, camera);
	earth.rotation.y += 0.005
	cloud.rotation.y += 0.004
	skydome.rotation.y += 0.001

}
animate();
這是我們上一篇的結果：

Untitled-2.gif

我們先把地球自轉的效果移除掉，方便接下來的開發：

function animate() {
	requestAnimationFrame(animate);
	renderer.render(scene, camera);
-	earth.rotation.y += 0.005
	cloud.rotation.y += 0.004
	skydome.rotation.y += 0.001
}
開發功能：準備城市位置
我們假裝正在幫一家公司的海外廠房製作全球中控台好了，廠房位於幾個城市。我就在網路上找到一些城市的經緯度做示範。

我找到這個網站提供很多城市經緯度資料。

https://ithelp.ithome.com.tw/upload/images/20220927/20142505AnCwF4QqSa.png

網站連結與資料來源

授權方式：Attribution 4.0 International

有了這些資料後，我整理成一份物件清單，作為本次範例中的客戶廠房位址，並放在程式碼中。

const cities = [
	{ name: "Mumbai", id: 1356226629, lat: 19.0758, lon: 72.8775, country: "India" },
	{ name: "Moscow", id: 1643318494, lat: 55.7558, lon: 37.6178, country: "Russia" },
	{ name: "Xiamen", id: 1156212809, lat: 24.4797, lon: 118.0819, country: "China" },
	{ name: "Phnom Penh", id: 1116260534, lat: 11.5696, lon: 104.9210, country: "Cambodia" },
	{ name: "Chicago", id: 1840000494, lat: 41.8373, lon: -87.6862, country: "United States" },
	{ name: "Bridgeport", id: 1840004836, lat: 41.1918, lon: -73.1953, country: "United States" },
	{ name: "Mexico City", id: 1484247881, lat:19.4333, lon: -99.1333 , country: "Mexico" },
	{ name: "Karachi", id: 1586129469, lat:24.8600, lon: 67.0100 , country: "Pakistan" },
	{ name: "London", id: 1826645935, lat:51.5072, lon: -0.1275 , country: "United Kingdom" },
	{ name: "Boston", id: 1840000455, lat:42.3188, lon: -71.0846 , country: "United States" },
	{ name: "Taichung", id: 1158689622, lat:24.1500, lon: 120.6667 , country: "Taiwan" },
]
開發功能：製作圖釘
釘在地球上面的圖釘，我以甜甜圈形狀的物件當作圖釘，目的是避免遮住廠房確切位置。

const geo = new THREE.RingGeometry( 0.1, 0.13, 32 );
const mat = new THREE.MeshBasicMaterial( { color: 0xffff00, side: THREE.DoubleSide } );
const ring = new THREE.Mesh( geo, mat );
scene.add( ring );
它位置會在(0,0,0)，也就是地球裡面，我們暫時看不到它。這是我把地球拿掉時看到的圖釘畫面：

https://ithelp.ithome.com.tw/upload/images/20220927/20142505x8qVK0AVZe.png

開發功能：製作下拉式選單
我們加上標籤<select> ，設定簡單的樣式跟class name。

<body>
    <main>
			<select style="position:absolute; margin: 10%" class="city-select">       
			</select>
    </main>
</body>
接下來，單向綁定標籤元件，並且渲染選項<option>

// 前面提到的城市資料清單
const cities = [
	// 我們加一個「請選擇」option避免誤導用戶
	{ name: "--- select city ---", id: 0, lat: 0, lon: 0, country: "None" },
	{ name: "Mumbai", id: 1356226629, lat: 19.0758, lon: 72.8775, country: "India" },
	{ name: "Moscow", id: 1643318494, lat: 55.7558, lon: 37.6178, country: "Russia" },
	...
] 
const citySelect = document.getElementsByClassName('city-select')[0]
// 渲染option
citySelect.innerHTML = cities.map( city => `<option value="${city.id}">${city.name}</option>`)
加入傾聽事件，找出城市經緯度：

citySelect.addEventListener( 'change', (event) => {
	const cityId = event.target.value
	const seletedCity = cities.find(city => city.id+'' === cityId)
	console.log(seletedCity)
})

// {name: 'Phnom Penh', id: 1116260534, lat: 11.5696, lon: 104.921, country: 'Cambodia'}
開發功能：經緯度轉換成世界座標
由於我們只知道經緯度座標（Latitude, Longitude, and Altitude，又稱LLA Coordinates），但我們應該要如何將經緯度轉換成世界座標（Earth-centered Earth-fixed，又稱ECEF Coordinates）呢？

https://ithelp.ithome.com.tw/upload/images/20220927/20142505YMqLZrnRtY.png

實際上，兩種座標可以透過座標轉換公式求得：

https://ithelp.ithome.com.tw/upload/images/20220927/20142505dNOvCqVwi8.png

將公式應用在本專案即成為函式：

// 將LLA轉換成ECEF座標
const llaToEcef = (lat, lon, alt, rad) => {
	let f = 0
	let ls = Math.atan((1 - f) ** 2 * Math.tan(lat))
	let x = rad * Math.cos(ls) * Math.cos(lon) + alt * Math.cos(lat) * Math.cos(lon)
	let y = rad * Math.cos(ls) * Math.sin(lon) + alt * Math.cos(lat) * Math.sin(lon)
	let z = rad * Math.sin(ls) + alt * Math.sin(lat)
	return new THREE.Vector3(x, y, z)
}
這個公式是怎麼來的？我們稍候介紹。我們先完成功能。

開發功能：經緯度轉換成弧度
這個函式的帶入參數為弧度，尚不是座標。我們必須要把經緯度轉成弧度，而這又需要另外一個函式幫忙：

const lonLauToRadian = (lon, lat, rad) => llaToEcef(Math.PI * (0 - lat) / 180, Math.PI * (lon / 180), 1, rad)
由於弧度範圍是0~2π，但對於緯度來說範圍是90~-90，也對於經度來說是-180~180的範圍，所以必須將經緯度轉換成弧度。這就是該函式的作用。

開發功能：移動圖釘位置到城市
我們將用戶所選取的城市經緯度帶入上面的函式，即可取得城市在世界座標的位置。

將圖釘位置改成城市位置，並且校正圖釘角度即可。

citySelect.addEventListener( 'change', (event) => {
	const cityId = event.target.value
	const seletedCity = cities.find(city => city.id+'' === cityId)
	// 用前面的函式所取得的座標
	const cityEciPosition = lonLauToRadian(seletedCity.lon, seletedCity.lat, 4.4)
	// 指定位置給圖釘
	ring.position.set(cityEciPosition.x, -cityEciPosition.z, -cityEciPosition.y)	
	// 圖釘永遠都看像世界中心，所以不會歪斜。
	ring.lookAt(center)
})
補充一下：在介紹OrbitControl時，有提到不要用lookAt()控制鏡頭。這是因為OrbitControl是鏡頭方向的代理人，如果直接透過lookAt()控制鏡頭將使得控制鏡頭方向的代理人OrbitControl與lookAt()的操作衝突。然而lookAt()仍然是控制物件（鏡頭以外的物件）其角度很好的函式，我們在這裡使用它控制圖釘的角度。
完成品
我們看看目前的成品：

Untitled

可以看到，圖釘已經定位在城市位置了。

接下來，無論用戶如何切換，我們都可以找出城市的位置，這還多虧了LLA轉換成ECEF座標的函式。

這樣就完成了！

經緯度轉三維空間座標
在進入下一篇之前，我們需要先釐清一下LLA轉換成ECEF座標的函式。

https://ithelp.ithome.com.tw/upload/images/20220927/20142505dfudcYJ9xT.png

這個函式看似複雜，其就跟矩陣那篇所提到的旋轉函式有異曲同工之妙。

// 給定旋轉之前的座標
let x
let y
// 給定旋轉角度
let θ
// ax,ay為旋轉的結果
const ax = x * cos(θ) + y * sin(θ)
const ay = x * -sin(θ) + y * cos(θ)
座標：經緯度轉三維空間座標原理
球座標的轉換到底是怎麼來？我從MathWorks找到這個函式。下面介紹原理：

https://ithelp.ithome.com.tw/upload/images/20220927/20142505J5mKl4bOGI.png

圖片來源

座標：球座標轉換
首先，我們的任務就是將經緯度座標變成三維空間座標。

經緯度就是以地圖中心(0,0)水平旋轉、垂直旋轉的位置描述方式。

例如桃園外海座標(東經121 ,北緯25)即是經度0度向東移動121度，北緯25即是赤道向北移動25度。我們可以得知——一切都是角度。

也就是說，可以把經度跟緯度想像成旋轉角度。如果我們有水平旋轉角度跟垂直旋轉角度，再加上地球半徑，就可以用公式求得三維座標了。

下面是一個三維空間，如果p是地球半徑，則我們可以透過上面的概念，旋轉φ以及θ來求得(x,y,z)座標。而這就如同我們從經緯度找到桃園外海座標在三維空間的座標位置一樣。

https://ithelp.ithome.com.tw/upload/images/20220927/201425058QSZNoo1PK.png

在這張圖可以看到，z垂直於xy平面。

為了更好理解，我們把畫面切到線段z跟r的剖面好了：

https://ithelp.ithome.com.tw/upload/images/20220927/20142505q5gQ0TpKc5.png

根據三角函數，我們得知：

// 下面這行z算出來是自己
z = p*(z/p)
// z/p乃φ斜邊分之鄰邊，以cos(φ)代替z/p
z = ρ*cos(φ)
// 下面這行r算出來是自己
r = ρ*(r/p)
// r/p乃φ斜邊分之對邊，以sin(φ)代替r/p
r = ρ*sin(φ)
我們先記住這個結果，現在先繼續把視角轉到XY的平面看這個座標：

https://ithelp.ithome.com.tw/upload/images/20220927/20142505ED1N3wrX3N.png

為求方便，我加兩條輔助線：

https://ithelp.ithome.com.tw/upload/images/20220927/20142505Zllxw2bVBK.png

同樣用三角函數，可以推算(x,y,z)中x,y的位置：

// 下面這行x算出來是自己
x = r*(x/r)
// x/r乃θ斜邊分之鄰邊，以cos(θ)代替x/r
x = r*cos(θ)
// 下面這行r算出來是自己
y = r*(y/r)
// y/r乃θ斜邊分之對邊，以sin(θ)代替y/r
y = r*sin(θ)
現在，我們有兩個等式

x = r*cos(θ)
y = r*sin(θ)
還記得剛剛我們所記住的結果嗎？r 我們早就算出來了，我們把r放在等式裡面

x = ρ*sin(φ)*cos(θ)
y = ρ*sin(φ)*sin(θ)
然後再加上我們也早就求出來的z，就變成：

x = ρ*sin(φ)*cos(θ)
y = ρ*sin(φ)*sin(θ)
z = ρ*cos(φ)
於是，只要我們知道從z軸到p的角度φ，以及x到p的角度θ，就可以得到(x,y,z)座標。

座標：經緯度與地球座標轉換
使用上面這個概念，我們就能找到經緯度在笛卡兒三維座標的位置。因為經緯度也像φ、θ一樣，是表達角度的方式。

但困難的是：

地球不是完整的圓，而是橢圓形的
地表有海拔高度，這使得計算起來沒辦法把(x,y,z)位置完美的落在地表。
但沒關係，數學家仍然算得出來，並克服了上面這兩個難題，使得我們有公式可以用。

https://ithelp.ithome.com.tw/upload/images/20220927/20142505dfudcYJ9xT.png

這個公式裡面，h就代表海拔高度的計算，使得問題二有了解套方式。

至於橢圓形的問題，也有了公式帶入。你如果仔細看可以看見：圖中的公式怎麼三角函數順序，跟我剛才推導的結果不一樣。

這是因為橢圓形的計算比較複雜不好解釋，這個網站提供了公式給大家參考。

https://www.mathworks.com/help/aeroblks/llatoecefposition.html

有興趣了可以深入理解，我這邊不多作解釋，因為會太離題。總之用球座標的概念，再考量到橢圓形、高度之後，就能取得剛剛開發時所用的函式：

// 將LLA轉換成ECEF座標
const llaToEcef = (lat, lon, alt, rad) => {
	let f = 0
	let ls = Math.atan((1 - f) ** 2 * Math.tan(lat))
	// alt主要為海拔高度以上的位置計算。本專案需求帶入0即可。但仍保留程式碼示例。
	let x = rad * Math.cos(ls) * Math.cos(lon) + alt * Math.cos(lat) * Math.cos(lon)
	let y = rad * Math.cos(ls) * Math.sin(lon) + alt * Math.cos(lat) * Math.sin(lon)
	let z = rad * Math.sin(ls) + alt * Math.sin(lat)
	return new THREE.Vector3(x, y, z)
}
你會發現：有些開發上我們會引用很多公式，然後小小修改一下。如果不懂得常用的數學，那麼小小修改也會很花功夫。我這邊還是先聚焦在比較簡單的推導上，而這已經滿足很大的開發需求了。

CodePen
https://ithelp.ithome.com.tw/upload/images/20220927/201425053qCKqgzSsr.png
https://codepen.io/umas-sunavan/pen/NWMXYwZ

下篇
本篇我們建立了圖釘，並且讓圖釘透過座標轉換的公式被放在正確的位置上。

下篇我將介紹透過投影/反投影，藉此讓我們可以在地球上看到各個城市的名稱。

除此之外，我們也需要讓鏡頭移動到城市的位置，而這個會需要用到lerp，跟normalize去調整鏡頭移動的方式，而這兩個也算是當時在討論向量時提到的有用函式，下篇將實際應用它。

下一篇我們將介紹鏡頭在各大城市之間的移動

Untitled

參考資料
LLA to ECEF Position

球座標計算

球座標計算問題討論

球座標問題討論2

球座標轉換的python函式



成品
Untitled

「飛雷神之術！」鏡頭跳轉的重要性
https://ithelp.ithome.com.tw/upload/images/20220928/20142505WEIAV2cpYj.jpg

圖片來源

上一篇我們實作城市的定位，但用戶仍必須手動轉動地球。手動轉動地球體驗不是很好，而這對簡報、展示來說是一大傷害。事實上，地球並不僅只是給客戶用而已。它除了當作畫面第一個登場的物件以外，公司業務拿畫面出來賣產品時，你所設計的畫面體驗也留給了客戶第一印象。客戶可能在第一時間就評分了整個產品。

所以說，地球不僅只是好用好看而已，對於商業價值有相當的影響。

為什麼要做地球？
回顧原因，它可以應用在很多場景上，例如：行銷網站、企業形象網站、活動網站、全球數位戰情室、航太科技、GIS畫面等等。這些對於前端視覺特效都非常重要。

製作地球也能讓我們釐清貼圖底層的運作模式，不僅討論到底層webGL、fragmentShader、vertexShader的渲染方式，也提到很多種貼圖。

本篇技術
使用Vector3.lerp()轉動鏡頭位置
使用normalize()、mutiplyScalar() 鎖定鏡頭與地球的高度
使用Math.cos()、Math.pow() 控制鏡頭位移的軌道
使用TextGeometry()建立浮動的3D文字物件
準備程式碼
上一篇的成果
Untitled (12).gif

CodePen
這裡也有codepen：

https://codepen.io/umas-sunavan/pen/NWMXYwZ

改善程式碼可讀性（非必要）
由於已經留下不少技術債。為了增加閱讀效率，我把部分的程式碼用函式包住：

const skydome = sreateSkydome()
const earth = createEarth()
const cloud = createCloud()
const ring = createRing()
這四個函式將一些變數留在函式作用域，並且減少全域的複雜度。

以下是整理過的程式碼，我們從這裡繼續。當然，如果沒有整理仍然可以繼續向下開發。

改善過後已準備好的程式碼
直接複製貼上就可以使用了。

import * as THREE from 'three';
import { OrbitControls } from 'https://unpkg.com/three@latest/examples/jsm/controls/OrbitControls.js';

const scene = new THREE.Scene();

const camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.set(0, 10, 15)

const renderer = new THREE.WebGLRenderer({ antialias: true });
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild(renderer.domElement);

const sreateSkydome = () => {
	// 匯入材質
	// image source: https://www.deviantart.com/kirriaa/art/Free-star-sky-HDRI-spherical-map-719281328
	const skydomeTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/free_star_sky_hdri_spherical_map_by_kirriaa_dbw8p0w%20(1).jpg')
	// 帶入材質，設定內外面
	const skydomeMaterial = new THREE.MeshBasicMaterial({ map: skydomeTexture, side: THREE.DoubleSide })
	const skydomeGeometry = new THREE.SphereGeometry(100, 50, 50)
	const skydome = new THREE.Mesh(skydomeGeometry, skydomeMaterial);
	scene.add(skydome);
	return skydome
}

// 新增環境光
const addAmbientLight = () => {
	const light = new THREE.AmbientLight(0xffffff, 0.5)
	scene.add(light)
}

// 新增點光
const addPointLight = () => {
	const pointLight = new THREE.PointLight(0xffffff, 1)
	scene.add(pointLight);
	pointLight.position.set(10, 10, -10)
	pointLight.castShadow = true
	// 新增Helper
	const lightHelper = new THREE.PointLightHelper(pointLight, 5, 0xffff00)
	// scene.add(lightHelper);
	// 更新Helper
	lightHelper.update();
}

// 新增平行光
const addDirectionalLight = () => {
	const directionalLight = new THREE.DirectionalLight(0xffffff, 1)
	directionalLight.position.set(0, 0, 10)
	scene.add(directionalLight);
	directionalLight.castShadow = true
	const d = 10;

	directionalLight.shadow.camera.left = - d;
	directionalLight.shadow.camera.right = d;
	directionalLight.shadow.camera.top = d;
	directionalLight.shadow.camera.bottom = - d;

	// 新增Helper
	const lightHelper = new THREE.DirectionalLightHelper(directionalLight, 5, 0xffff00)
	// scene.add(lightHelper);
	// 更新位置
	directionalLight.target.position.set(0, 0, 0);
	directionalLight.target.updateMatrixWorld();
	// 更新Helper
	lightHelper.update();
}

addPointLight()
addAmbientLight()
addDirectionalLight()

const createEarth = () => {
	const earthGeometry = new THREE.SphereGeometry(5, 600, 600)
	const earthTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/8081_earthmap2k.jpg')
	// 灰階高度貼圖
	const displacementTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/editedBump.jpg')
	const roughtnessTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/8081_earthspec2kReversedLighten.png')
	const speculatMapTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/8081_earthspec2k.jpg')
	const bumpTexture = new THREE.TextureLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/day10/8081_earthbump2k.jpg')
	
	
	const earthMaterial = new THREE.MeshStandardMaterial({
		map: earthTexture,
		side: THREE.DoubleSide,
		roughnessMap: roughtnessTexture,
		roughness: 0.9,
		// 將貼圖貼到材質參數中
		metalnessMap: speculatMapTexture,
		metalness: 1,
		displacementMap: displacementTexture,
		displacementScale: 0.5,
		bumpMap: bumpTexture,
		bumpScale: 0.1,
	})
	const earth = new THREE.Mesh(earthGeometry, earthMaterial);
	scene.add(earth);
	return earth
}

const createCloud = () => {
	const cloudGeometry = new THREE.SphereGeometry(5.4, 60, 60)
	// 匯入材質
	// texture source: http://planetpixelemporium.com/earth8081.html
	const cloudTransparency = new THREE.TextureLoader().load('8081_earthhiresclouds4K.jpg')
	// 帶入材質，設定內外面
	const cloudMaterial = new THREE.MeshStandardMaterial({
		transparent: true,
		opacity: 1,
		alphaMap: cloudTransparency
	})
	const cloud = new THREE.Mesh(cloudGeometry, cloudMaterial);
	scene.add(cloud);
	return cloud
}

const createRing = () => {
	const geo = new THREE.RingGeometry( 0.1, 0.13, 32 );
	const mat = new THREE.MeshBasicMaterial( { color: 0xffff00, side: THREE.DoubleSide } );
	const ring = new THREE.Mesh( geo, mat );
	scene.add( ring );
	return ring
}

const control = new OrbitControls(camera, renderer.domElement);

const cities = [
	{ name: "--- select city ---", id: 0, lat: 0, lon: 0, country: "None" },
	{ name: "Mumbai", id: 1356226629, lat: 19.0758, lon: 72.8775, country: "India" },
	{ name: "Moscow", id: 1643318494, lat: 55.7558, lon: 37.6178, country: "Russia" },
	{ name: "Xiamen", id: 1156212809, lat: 24.4797, lon: 118.0819, country: "China" },
	{ name: "Phnom Penh", id: 1116260534, lat: 11.5696, lon: 104.9210, country: "Cambodia" },
	{ name: "Chicago", id: 1840000494, lat: 41.8373, lon: -87.6862, country: "United States" },
	{ name: "Bridgeport", id: 1840004836, lat: 41.1918, lon: -73.1953, country: "United States" },
	{ name: "Mexico City", id: 1484247881, lat:19.4333, lon: -99.1333 , country: "Mexico" },
	{ name: "Karachi", id: 1586129469, lat:24.8600, lon: 67.0100 , country: "Pakistan" },
	{ name: "London", id: 1826645935, lat:51.5072, lon: -0.1275 , country: "United Kingdom" },
	{ name: "Boston", id: 1840000455, lat:42.3188, lon: -71.0846 , country: "United States" },
	{ name: "Taichung", id: 1158689622, lat:24.1500, lon: 120.6667 , country: "Taiwan" },
]

let lerpTarget
let lerpPropical = new THREE.Vector3(0,0,0)
let tropical

const citySelect = document.getElementsByClassName('citySelect')[0]
citySelect.innerHTML = cities.map( city => `<option value="${city.id}">${city.name}</option>`)
citySelect.addEventListener( 'change', (event) => {
	const cityId = event.target.value
	const seletedCity = cities.find(city => city.id+'' === cityId)
	const cityEciPosition = lonLauToRadian(seletedCity.lon, seletedCity.lat, 4.4)
	ring.position.set(cityEciPosition.x, -cityEciPosition.z, -cityEciPosition.y)
	const center = new THREE.Vector3(0,0,0)
	ring.lookAt(center)
	tropical = 1
	lerpTarget = new THREE.Vector3(0,0,0).set(...ring.position.toArray()).multiplyScalar(3)
	lerpPropical.set(...camera.position.toArray())
	// camera.position.set(...ring.position.toArray()).multiplyScalar(3)
	control.update()
})

const skydome = sreateSkydome()
const earth = createEarth()
const cloud = createCloud()
const ring = createRing()

function animate() {
	requestAnimationFrame(animate);
	renderer.render(scene, camera);
	cloud.rotation.y += 0.0005
	skydome.rotation.y += 0.001
	if (lerpTarget) {
		lerpPropical.lerp(lerpTarget, 0.05).normalize().multiplyScalar(20)
		let value = Math.pow(tropical*2-1, 4.)
		camera.position.set(lerpPropical.x, lerpPropical.y*(value), lerpPropical.z).normalize().multiplyScalar(20)
		control.update()
	}
	tropical*=0.97
}
animate();

// 經緯度轉換成弧度
const lonLauToRadian = (lon, lat, rad) => llaToEcef(Math.PI * (0 - lat) / 180, Math.PI * (lon / 180), 1, rad)
// 城市弧度轉換成世界座標
const llaToEcef = (lat, lon, alt, rad) => {
	let f = 0
	let ls = Math.atan((1 - f) ** 2 * Math.tan(lat))
	let x = rad * Math.cos(ls) * Math.cos(lon) + alt * Math.cos(lat) * Math.cos(lon)
	let y = rad * Math.cos(ls) * Math.sin(lon) + alt * Math.cos(lat) * Math.sin(lon)
	let z = rad * Math.sin(ls) + alt * Math.sin(lat)
	return new THREE.Vector3(x, y, z)
}
開發功能：飛雷神之術！—鏡頭追蹤
設定鏡頭定位在城市位置正上方的外太空即可。

如何取得城市位置正上方的外太空位置？將城市position向量放大三倍即可。（透過multiplyScalar()，就在之前的必備的向量函式時都有提及）

// 用戶更新下拉選單後的回呼
citySelect.addEventListener( 'change', (event) => {
	...
	// 修改鏡頭位置，multiplyScalar可以縮放向量
	camera.position.set(...ring.position.toArray()).multiplyScalar(3)
	// 由OrbitControl幫我們更新鏡頭角度
	control.update()
})
Untitled

可以看到用戶已經可以切換位置了

開發功能：鏡頭移動
開發功能：鏡頭位移動畫
在討論必備的向量函式時，有提到lerp。現在它派上用場了。如果一個向量使用它，得提供兩個參數：結果參數跟alpha參數，向量將移動alpha倍的距離向結果參數（另一個向量）移動。

所以比方說，我要讓向量(0,0,0)向結果參數(10,10,0)移動0.5倍距離（alpha參數），則結果就是(5,5,0)。再執行一次就變成(7.5, 7.5, 0)，再一次就是(0.875, 0.875, 0)，以此類推。

把這個函式放在animate裡面，就可以做出像是Ease-out的動畫效果，連動畫套件都不用裝，讚。

https://ithelp.ithome.com.tw/upload/images/20220928/20142505qQPt6cEskX.png

// 作為lerp移動的結果參數
let lerpTarget
citySelect.addEventListener( 'change', (event) => {
	...
	// 當用戶選城市時，更新lerp移動的結果參數
	lerpTarget = new THREE.Vector3(0,0,0)
		// 設定移動結果位置為圖釘位置
		.set(...ring.position.toArray())
		// 乘以三倍，使得位置位在城市正上方的外太空
		.multiplyScalar(3)
	// 不在此直接設定鏡頭位置了
	camera.position.set(...ring.position.toArray()).multiplyScalar(3)
	control.update()
})
接著，我們在animate()加上函式，使得鏡頭不斷的位移，實現動畫：

function animate() {
	...
	// 用戶有選取城市才會執行下面
	if (lerpTarget) {
		// 鏡頭位置向城市上方的外太空移動
		camera.position.lerp(lerpTarget, 0.05)
		// 使得OrbitControl不斷幫我們更新鏡頭
		control.update()
	}
}
接著就能做出效果：

Untitled

畫面看起來非常好，但事情還沒有結束。

開發功能：曲線移動鏡頭
你玩一玩會發現，怎麼怪怪的？

Untitled

你會發現，鏡頭移動的路徑是直線的。

https://ithelp.ithome.com.tw/upload/images/20220928/20142505t8wP3XTqC9.png

我們需要把路徑改成曲線。

https://ithelp.ithome.com.tw/upload/images/20220928/20142505wZvO1MYEEE.png

為什麼會產生這個問題？

鏡頭在位移時，其位置距離地球的遠近不一樣。當鏡頭在起點跟終點時，鏡頭距離地球的距離一致，然而在位移的過程中，其距離地球過近。
而解決方法，就是在鏡頭移動的過程中，持續固定鏡頭對地球的距離。固定距離的方法有很多種，而我的作法有三個步驟：

先記住鏡頭一開始位於地球中心（也就是座標中心）的向量有多長。
將向量改成一單位
再縮放向量到的距離
我們看圖理解：

步驟一：一開始離世界中心距離假設為20。（世界中心也是地球中心）

https://ithelp.ithome.com.tw/upload/images/20220928/201425056Aae87p6c8.png

步驟二：現在將該向量縮小到長度為1，但方向不變。這個可以透過Vector3.normalize()完成

https://ithelp.ithome.com.tw/upload/images/20220928/20142505ympxZYrJXv.png

步驟三：一開始我們知道長度為20，所以只要再乘上20即可。

https://ithelp.ithome.com.tw/upload/images/20220928/20142505nzC6QTjOvI.png

如果每一幀鏡頭移動時都做同樣的事情，那麼就可以形成一個完美的弧度

https://ithelp.ithome.com.tw/upload/images/20220928/20142505G377QQeCOq.png

Vector3.normalize()可以把向量轉成單位向量，以此固定距離成一單位；Vector3.multiplyScalar()則能夠縮放向量到正確的距離。有這兩個函式，就可以開始把邏輯寫在程式了。

這兩個都在我們介紹必備的向量函式時都有提及，可以參考：Day7: three.js的一方通行：矢量操作——全面釐清向量與底層特性

套用在我們專案，就是：

- camera.position.lerp(lerpTarget, 0.1)
+ // 固定長度為一單位，然後放大長度
+ camera.position.lerp(lerpTarget, 0.1).normalize().multiplyScalar(15)
結果就自然多了：

Untitled

開發功能：OrbitControl自動轉正的特性以及解法
當鏡頭靠近北極時，會有奇怪的旋轉。

Untitled

為什麼會有奇怪的旋轉？

這跟OrbitControl的特性有關。OrbitControl 一個很大的特性在Day6: three.js 圓弧的藝術家！弧線的教授！——軌道控制器有提到：當用戶把鏡頭繞過最頂端之後，OrbitControls會自動校正頭頂方向。

https://ithelp.ithome.com.tw/upload/images/20220928/20142505IH5vi0Jzb5.png

也是因為這個特性，讓鏡頭在繞過北極的時候，有不自然的旋轉。

為了解決這個方法，我加上了一個函式，來讓鏡頭沿著赤道旋轉，避免這個問題。

開發功能：沿著赤道位移鏡頭
因為鏡頭往北極時都要轉正，為了避免這個問題，我改從赤道旋轉鏡頭。但要如何開發呢？

目前為止，我們有lerpTarget，它每一幀都移動一個距離，並讓鏡頭綁定給它lerpTarget 。

https://ithelp.ithome.com.tw/upload/images/20220928/20142505Ih8GX2y541.png

現在，我們多出一個變數，先頂替camera的路徑移動，我們稱這個變數作moveAlongTropical好了。我們接著修改moveAlongTropical 的數值，使得它沿著赤道移動，再綁定移動軌跡給鏡頭。

https://ithelp.ithome.com.tw/upload/images/20220928/20142505kCib7qEvpe.png

要如何修改moveAlongTropical 的數值來讓鏡頭沿著赤道移動？從下圖可見紅字，假設紅字代表是一個變數，它將lerpTargt的Y軸數值乘成比較小的數值，就可以改變鏡頭的位置了。

https://ithelp.ithome.com.tw/upload/images/20220928/201425057x3NExPvdg.png

如圖中紅字那樣，只要lerpTarget座標中的高度Y乘上一個變數，即可將鏡頭偏向赤道移動。我將該變數命名為moveVolume，待會解釋。

在程式碼實作是這樣：

let lerpTarget
// 加上兩個變數
let moveAlongTropical = new THREE.Vector3(0,0,0)
// moveAlongTropical的移動進度
let moveProgress
在此我們宣告兩個變數。當用戶點選新的城市，設moveProgress為1，將由1走到0，做為moveAlongTropical移動的進度。

citySelect.addEventListener( 'change', (event) => {
	...
	// 給定moveAlongTropical於移動的起點
	moveAlongTropical.set(...camera.position.toArray())
	// pregress將由1走到0，控制稍候的變數「moveVolume」以做變化
	moveProgress = 1
})
每一幀，moveAlongTropical都會頂替鏡頭原先的位置。moveVolume使得鏡頭的Y座標保持在赤道。

moveVolume為什麼能使鏡頭在赤道？因為moveVolume範圍是1~0，它乘給了Y，導致Y值減少了，也因此使得鏡頭靠近赤道。

https://ithelp.ithome.com.tw/upload/images/20220928/20142505Y6ZViq6ykd.png

function animate() {
	...
	// 建立一個函式，使得鏡頭的航向可以往赤道移動
	let moveVolume = Math.pow(moveProgress*2-1, 4.)
	// 用戶有選取城市才會執行下面
	if (lerpTarget) {
		// 綁定數值給moveAlongTropical
		moveAlongTropical.lerp(lerpTarget, 0.05).normalize().multiplyScalar(15)
		// 現在，將camera位置綁定到moveAlongTropical上。其中由於moveVolume範圍是1~0，其減少了Y值的輸出
		camera.position.set(moveAlongTropical.x, moveAlongTropical.y*moveVolume, moveAlongTropical.z).normalize().multiplyScalar(20)
		// 使得OrbitControl不斷幫我們更新鏡頭
		control.update()
	}
	// 不斷更新progress，使得moveVolume不斷更新數值
	moveProgress*=0.97
}
如此一來，地球就可以沿著赤道移動，解決鏡頭繞過北極時的問題了。

Untitled

開發功能：浮動文字開發
有兩種開發方式，一種是將文字當作一個Mesh，一種是將文字當作是一個html DOM，這兩種都可以。前者提供多元的文字渲染，後者提供用戶複製文字並作後續操作。我介紹前者為主。

浮動文字開發：建立文字Mesh
首先加上一個函式以新增文字Mesh。身為一個Mesh，它就跟前幾篇介紹的物件一樣，需要形狀(geometry)跟材質(material)，文字可用TextGeometry。只是textGeometry的參數較多。儘管如此，這些參數仍然很好理解。

const addText = text => {
	const textGeometry = new TextGeometry( text, {
		font: font,
		size: 0.2,
		height: 0.01,
		curveSegments: 2,
		bevelEnabled: false,
		bevelThickness: 10,
		bevelSize: 0,
		bevelOffset: 0,
		bevelSegments: 1
	} );
	const textMaterial = new THREE.MeshBasicMaterial({color: 0xffff00})
	const textMesh = new THREE.Mesh(textGeometry, textMaterial)
	scene.add(textMesh)
	return textMesh
}
// 初始化物件
let text = addText('')
接著，每當用戶選擇城市時，就更新文字Mesh，如下：

citySelect.addEventListener( 'change', (event) => {
	// 移除上一個城市的文字mesh
	text.removeFromParent()
	// 新增文字mesh
	text = addText(seletedCity.name)
	// 設定文字位置於圖釘上
	text.position.set(ring.position.toArray())
})
浮動文字開發：使文字Mesh面朝鏡頭
你會看到文字的方向怪怪的，這是因為它面向的方向並不是鏡頭。

Untitled

我們只要文字面向鏡頭即可。

function animate() {
	...
	text.lookAt(...camera.position.toArray())
}
浮動文字開發：文字Mesh不重疊圖釘
修完之後，我們由圖可見文字擋到圖釘了。

Untitled

這個時候只要應用我們在Day3: Three.js空間座標！讓世界繞著我旋轉！討論到的translate()即可。我更新了文字的位置，使得文字不會遮住圖釘：

// 0.2是我們在建立TextGeometry時的文字寬度
textMesh.geometry.translate(text.length*-0.2,0.2,0)
成品
Untitled

CodePen
https://ithelp.ithome.com.tw/upload/images/20220928/201425051VhYsC1phY.png

https://codepen.io/umas-sunavan/pen/RwyQGZm

以上就是透過3D地球特效開發所做的成果。歷經三篇實戰跟一篇原理，我們已經吸收了非常非常多東西，而且多數的技術，都從過去文章介紹的原理疊加而來。

這四篇的總整理
經過這四篇，我們學到的東西包含：

貼圖在底層的原理
WebGL取樣貼圖的過程
最常用的七種貼圖
應用其中六種貼圖實作地球
製作地球的雲層
經緯度座標轉成世界座標
由經緯度標記大城市位置
座標轉換的數學原理與推導
更新鏡頭位置於城市正上方
使用Lerp打造位置移動的Ease效果
使用特定函式修改鏡頭位移的路徑
新增城市文字於地球上
設定文字面向鏡頭
地球的潛力
事實上，我們只做到冰山一角，地球能做的功能真的太多了，沒辦法在預計的篇幅中介紹完。地球能做到的包含：

應用衛星圖資，將街道、衛星影像、交通等圖磚放到地球上面，並且依照鏡頭縮放更換合適解析度的圖磚
使用HTML DOM元件製作文字，而非使用Mesh製作文字（Vector3.project/ Vector3.unproject）
在各大城市或國家加上一個圓柱。圓柱高度代表各國差異，變成一種資料視覺化。（CylinderGeometry）
加上飛機模型，模擬飛機或是船從A地飛到B地的畫面，以提供貨運資訊（Vector3.Lerp, Curve）
隨機產生地形圖，自製星球
諸如此類，這些都能由你發揮。如果有興趣，都可以複製我Codepen的程式碼來玩！

下篇
接下來我將以3D圓餅圖為示例，從中介紹線段、曲線、轉成Mesh、製作3D，其過程也將相當有趣。


https://ithelp.ithome.com.tw/upload/images/20220929/20142505uCSmBjPUjO.jpg
圖片來源

線段是什麼？
點線面構成一切，而目前為止，我們都在花時間在點(Vector)跟面(Mesh)上。

線段由點產生，它也組成面，這之間需要轉換API。除此之外，還要透過多種的方法「繪製」線段，例如貝滋曲線、弧線、橢圓等等各式各樣，這也需要API。

佐為不碰棋也可以下棋。而你不用碰像素你也可以在像素中繪製形狀。你就像佐為一樣，指揮進藤光繪製你的畫面！

三個重要的線段物件：Shape、Path、Curve
Shape形狀，可以拿它的API畫畫。可以用來產生Mesh物體，如ShapeGeometry、ExtrueGeometry。
Path路徑：單純描述一條線，也可以用它的API畫畫。
Curve曲線：可以用它的API，產生幾何的曲線，例如橢圓形。
這三個就衍生很多東西：

曲線可以變成線段嗎？可以——ShapePath
線段可以變形狀嗎？可以——Shape
線段可以變成點嗎？可以——.getPoints()
曲線可以變成面嗎？可以——.getPoints()成為vector3之後建立Shape再建立ShapeGeometry
…
整個API主要就是關於線段的繪製，以及這三個東西的轉來轉去。我們先介紹繪製（Path跟Curve 為主），再介紹轉形。

線段物件：線Path
如果有用Canvas畫線，或是用P5.js畫線，那應該會對這個工具相當熟悉，因為Canvas跟P5.js也有用到類似的東西。如果對Canvas繪製有興趣可以看這裡，對P5.js有興趣可以看這裡。基本上three.js有Path就是在解決類似的事情。也就是畫線段。

這些繪畫的API概念是這樣的：

先想像你是棋靈王裡面的佐為。

https://ithelp.ithome.com.tw/upload/images/20220929/20142505yxIsg3RnEF.png

圖片來源

你是一千年前精通Canvas畫線的鬼魂，在那年鐵人賽當中敗給某個日本Canvas大名，然後被封印起來。一千年後，你終於可以出來繪製Canvas了！然而你卻沒辦法碰到Canvas。

然後你碰到了叫「進藤three」的男孩，你必須透過進藤three才可以下棋。

https://ithelp.ithome.com.tw/upload/images/20220929/20142505Krji65B2du.png

圖片來源

如果你是佐為，你要怎麼告訴進藤three要怎麼下棋？

https://ithelp.ithome.com.tw/upload/images/20220929/20142505MWq6l4Qj93.png

圖片來源

「13E」，你肯定是這樣說的。你佐為要把棋下在13E，而對進藤three來說，就是 Path.moveTo(13,E)

https://ithelp.ithome.com.tw/upload/images/20220929/20142505U1gQfamFBH.png

圖片來源

好的，接下來就用這個概念去思考以下的函式：
當前位置：Path.currentPoint

這是變數。進藤three幫你作畫時會一直移動他的手指頭，手指頭叫做.currentPoint，預設在原點。

https://ithelp.ithome.com.tw/upload/images/20220929/20142505DBpVY7VIjj.png

位移位置：Path.moveTo(x,y)

「進藤three，移動你的手到(a,b)！」

https://ithelp.ithome.com.tw/upload/images/20220929/20142505R1dEnlNXuQ.png

畫直線：Path.lineTo(j,k)

「進藤three，現在畫直線到位置(j,k)！」

https://ithelp.ithome.com.tw/upload/images/20220929/20142505RDMbEtLAE4.png

畫弧線：Path.arc(x, y, radius, aStartAngle, aEndAngle, aClockwise)

「進藤three，現在以(x,y)為中心，以radius半徑，以aStartAngle為起始的弧度，以aEndAngle為結束的弧度，以aClockwise為繪製的方向預設以逆時針，繪製一個圓弧！」（進藤three要昏倒了）

https://ithelp.ithome.com.tw/upload/images/20220929/201425051ZjX4tsWJx.png

也是畫弧線：Path.absarc(x, y, radius, aStartAngle, aEndAngle, aClockwise)

跟前一個Path.arc一模一樣，只是在名稱上多加了abs。abs是什麼呢？就是絕對值absolute的縮寫。意思是：原本相對於當前原點currentPoint 繪圖的弧線，變成以物件原點繪圖的弧線。

畫橢圓弧線：Path.ellipse(x, y, xRadius, yRadius, startAngle, endAngle, clockwise, rotation)

「進藤three，跟Path.abs差不多，但這次是橢圓，所以有xRadous做為水平半徑，yRadius為垂直半徑，以rotation為偏移，繪製一個圓弧！」

https://ithelp.ithome.com.tw/upload/images/20220929/20142505aktoOnjhgn.png

也是畫橢圓弧線：Path.absellipse(x, y, xRadius, yRadius, startAngle, endAngle, clockwise, rotation)

跟前一個Path.ellipse一模一樣，只是多加了abs，意思就是：這裡繪製絕對位置，而不是跟上一個一樣以currentPoint 做為相對位置來畫線。

繪製貝滋曲線：Path.bezierCurveTo(v0, v1, v2, v3)

「進藤three，以v0為第一個控制點，以v1為第二個控制點，以v2為目的地，繪製一條線段！」

https://ithelp.ithome.com.tw/upload/images/20220929/20142505A2AiZ4meKK.png

繪製二次方貝滋曲線：Path.quadraticCurveTo()

「進藤three，以v0為第一個控制點，以v1為目的地，繪製一條線段！」

https://ithelp.ithome.com.tw/upload/images/20220929/20142505FOuPMZOxWX.png

.getPoint() / getPointAt()

這個是用在一個線段取點。帶入點的位置，起點是0終點是1，就可以回傳一個錨點，代表該點的位置。

參考資料：https://threejs.org/docs/?q=curve#api/en/extras/core/Curve

.getPoints()

在一個線段取多個點，帶入10就會回傳10個點代表0.1, 0.2, 0.3。回傳一組錨點

setFromPoints()

由一組點來產生線段。

線段物件：曲線Curve
上面提到的線，其實就有使用到曲線了。

事實上，當我們使用arc, absarc, ellipse, absellipse 時，就是將曲線加入到Path中。然而這只處理曲線部分的弧線而已。除了弧線以外，曲線還有很多API可以使用。

Three.js裡面Curve分很多種物件，包含

QuadraticBezierCurve ⇒ 二次貝滋曲線

Quadratic有平方的意思。為一個控制點所形成的曲線。不僅在three.js，在SVG也常見。下圖可以見到與虛擬的控制點相連的兩條虛線，沿著進度繪製的話，可以繪製出曲線。

https://ithelp.ithome.com.tw/upload/images/20220929/201425058A8OjoIMct.png

Bézier_2_big.gif

圖片來源

實例化方式

const curve = new THREE.QuadraticBezierCurve(
	new THREE.Vector2( 0, 0 ),
	new THREE.Vector2( 30, 15 ),
	new THREE.Vector2( 20, 0 )
);
相當於：

https://ithelp.ithome.com.tw/upload/images/20220929/20142505pOZ7QjiUmf.png

相當於SVG的指令Q （取Quadratic首字）：

<svg width="30" height="30" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg">
	<path d="M0,30 Q30,15 20,30" stroke="black"/>
</svg>
CubicBezierCurve ⇒ 三次貝滋曲線

Cubic有代表三次元的意思。為一個控制點所形成的曲線。不僅在three.js，在SVG也常見。下圖可以見到與兩個虛擬的控制點相連的三條虛線，沿著進度繪製出兩條虛線，用那兩條虛線做二次貝滋曲線，可以繪製出曲線。

https://ithelp.ithome.com.tw/upload/images/20220929/20142505KWr1a4nqY1.png

實例化方式

const curve = new THREE.CubicBezierCurve(
	new THREE.Vector2( 0, 0 ),
	new THREE.Vector2( 5, 15 ),
	new THREE.Vector2( 30, 15 ),
	new THREE.Vector2( 20, 0 )
);
相當於：

https://ithelp.ithome.com.tw/upload/images/20220929/20142505zI7Vem1mNp.png

這就等同於Illustrator的鋼筆工具（有兩個控制點時）的狀態：

https://ithelp.ithome.com.tw/upload/images/20220929/20142505tmgVW0C4DS.png

等同figma的（有兩個控制點時的）線段工具：

https://ithelp.ithome.com.tw/upload/images/20220929/2014250514D2aR7xhi.png

相當於SVG的指令C （取Cubic首字）：

<svg width="30" height="30" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M0,30 C5,15 30,15 20,30" stroke="black"/>
</svg>
LineCurve ⇒ 直線，等同一次貝滋曲線

實例化方式

const curve = new THREE.LineCurve(
	new THREE.Vector2( 0, 0 ),
	new THREE.Vector2( 5, 15 ),
);
相當於：

https://ithelp.ithome.com.tw/upload/images/20220929/20142505IfYPbjYIgG.png

相當於SVG的指令L （取Line首字）：

<svg width="30" height="30" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg">
<!-- 
    path標籤裡面有屬性d，d裡面有數字跟英文。英文就代表指令。這裡含有指令L。 
-->
<path d="M0,30 L5,15" stroke="black"/>
</svg>
EllipseCurve ⇒ 橢圓弧線

實例化方式

const curve = new THREE.EllipseCurve(
	10,  10,            // ax, aY
	5, 3,           // xRadius, yRadius
	0,  2 * Math.PI,  // aStartAngle, aEndAngle
	false,            // aClockwise
	0                 // aRotation
);
相當於：

https://ithelp.ithome.com.tw/upload/images/20220929/20142505TfhenVv0Z9.png

相當於SVG的ellipse ：

<svg width="30" height="30" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M0,30 L5,15" stroke="black"/>
</svg>
ArcCurve ⇒ 弧線 ⇒ 即是EllipseCurve

CatmullRomCurve ⇒基於Catmull-Rom（樣條）而生成的曲線

SplineCurve

我需要精通這些東西嗎？
如果要設計線條，才需要精通線段。但如果真的要設計線條，可以直接在Figma, Adobe Illustrator上面設計即可。對於2D線段來說，還有更多更有趣函式庫可以運用，例如P5.js。

除非線段是raw data產生的，不然用其他工具繪製即可。那如果線段是raw data呢？那在開發時會更注重物件之間的轉換。例如：將SVG經由線段轉換成面。

轉換物件對應用來說相當重要
所以說，我們不用精通線段，只要能夠拿來應用即可。但麻煩的是，當我們要轉換線段物件時，容易被搞得很複雜。下圖是我製作的關係圖，可供參考有關線段的物件之間的關係。有了這張表對我自己的幫助很大：

https://ithelp.ithome.com.tw/upload/images/20220929/20142505x7zB9FdCqH.png

以這張圖表我們就可以很清楚的看到Three.js 各種元件的轉換關係。

比如說，如果我要從SVG匯入線段資料，並且製作成面，那該怎麼辦？

https://ithelp.ithome.com.tw/upload/images/20220929/20142505DpnfmczO75.png

走這個轉換的路線即可。

那麼如果說要把流體力學的三維錨點資料轉呈線段該怎麼處理呢？

https://ithelp.ithome.com.tw/upload/images/20220929/201425057C1UwsfW03.png

將點轉成Line物件即可。

那麼如果要在場景中的地球加上一個拋物線以相連兩座城市呢？

https://ithelp.ithome.com.tw/upload/images/20220929/201425050fWLW9wY0y.png

製作一個曲線，再轉成點，再轉成線即可。

線段的工作流程
從上面的圖可以理解：通常工程師通常不用自己畫線，我們只要使用某個原始資料（rawdata）的線段，然後呈現在畫面上就好。舉例來說：

將SVG的線段繪製成面，SVG為rawdata
將流體力學的計算結果（例如火災的二氧化碳飄逸情況）以線段呈現方向
用戶在3D場景選擇建築物的起訖點，網頁得找到最佳路徑，並以線段標記路徑
將定時回傳的飛機位置資訊連成線段，呈現在地球上
場景有地球，地球有兩個座標要用拋物線相連
火車模型得沿著軌道移動，其軌道為資料庫物抓來的一組(x,y)資料。
給定高架橋的橫切面還有高架橋的路徑，工程師用這兩個資料製作3D高架橋
下篇
我將實戰線段。使用線段去產生3D的圓餅圖。圖表跟線段關聯很大，如果要製作一個數位中控台儀表板，圖表是不可或缺的元素，而圓餅圖不僅是常見的圖表，將其做成3D也能夠讓畫面更為絢麗、獨有。使得產品能在競爭對手之間脫穎而出。

結語：塔矢亮看完這篇一定感到震驚。

https://ithelp.ithome.com.tw/upload/images/20220929/20142505TWJd61q5uE.png

圖片來源

好好當sai就好了當three幹嘛

https://ithelp.ithome.com.tw/upload/images/20220929/20142505CzNXfT5Nwm.png

圖片來源

參考資料
一次搞懂SVG中的d屬性中的指令

Paths

d

EllipseCurve

準備程式碼
首先，我們先透過three.js範本開一個新的專案。我們直接沿用Day3時的範本即可：

CodePen
https://ithelp.ithome.com.tw/upload/images/20220930/20142505oosaPKRSEA.png

https://codepen.io/umas-sunavan/pen/YzLZvpM

原始碼
複製貼上的index.js，然後開一個html來引用即可。可以參考Codepen。

import * as THREE from 'three';

const scene = new THREE.Scene();

const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.set(0, 3, 15)

const renderer = new THREE.WebGLRenderer();
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild( renderer.domElement );

const geometry = new THREE.BoxGeometry(1,1,1)
const material = new THREE.MeshNormalMaterial({color: 0x0000ff})
const parent = new THREE.Mesh(geometry, material);
const child = new THREE.Mesh(geometry, material);
scene.add(parent);
parent.add(child);
parent.position.x = 10
child.position.x = 5

function animate() {
  parent.rotation.y += 0.01;
	requestAnimationFrame( animate );
	renderer.render( scene, camera );
}
animate();
我刪除掉上次parent跟child的物件，這次用不到。


    // 我把parent跟child相關程式刪除
-   const geometry = new THREE.BoxGeometry(1,1,1)
-   const material = new THREE.MeshNormalMaterial({color: 0x0000ff})
-   const parent = new THREE.Mesh(geometry, material);
-   const child = new THREE.Mesh(geometry, material);
-   scene.add(parent);
-   parent.add(child);
-   parent.position.x = 10
-   child.position.x = 5

    function animate() {
    // 我把parent跟child相關程式刪除
-     parent.rotation.y += 0.01;
    }
    animate();
我新增燈光，燈光的函式從Day9的程式碼而來

CodePen

https://codepen.io/umas-sunavan/pen/xxjXggj

所新增的程式碼：

// 新增環境光
const addAmbientLight = () => {
	const light = new THREE.AmbientLight(0xffffff, 0.5)
	scene.add(light)
}

// 新增點光
const addPointLight = () => {
	const pointLight = new THREE.PointLight(0xffffff, 1)
	scene.add(pointLight);
	pointLight.position.set(3, 3, 0)
	pointLight.castShadow = true
	// 新增Helper
	const lightHelper = new THREE.PointLightHelper(pointLight, 20, 0xffff00)
	scene.add(lightHelper);
	// 更新Helper
	lightHelper.update();
}

// 新增平行光
const addDirectionalLight = () => {
	const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8)
	directionalLight.position.set(20, 20, 0)
	scene.add(directionalLight);
	directionalLight.castShadow = true
	const d = 10;

	directionalLight.shadow.camera.left = - d;
	directionalLight.shadow.camera.right = d;
	directionalLight.shadow.camera.top = d;
	directionalLight.shadow.camera.bottom = - d;

	// 新增Helper
	const lightHelper = new THREE.DirectionalLightHelper(directionalLight, 20, 0xffff00)
	scene.add(lightHelper);
	// 更新位置
	directionalLight.target.position.set(0, 0, 0);
	directionalLight.target.updateMatrixWorld();
	// 更新Helper
	lightHelper.update();
}

addAmbientLight()
addDirectionalLight()
addPointLight()
新增OrbitControl ，方便我們控制鏡頭（非必要）

import { OrbitControls } from 'https://unpkg.com/three@latest/examples/jsm/controls/OrbitControls.js';

// 在camera, renderer宣後之後加上這行
new OrbitControls(camera, renderer.domElement);
把背景改成白色（非必要）

scene.background = new THREE.Color(0xffffff)
目前的畫面：

https://ithelp.ithome.com.tw/upload/images/20220930/201425055gufi5yaSo.png

只看得到空白的畫面以及幾條黃線，那是輔助開發者釐清鏡頭位置的PointLightHelper、DirectionalLightHelper。

開發線段
圓餅圖的構成
由弧形產生「餅」
需要有直線
餅的實作
埋一次餵公子吃餅的梗圖

準備原始資料

// 假設圖表拿到這筆資料
const data = [
	{rate: 14.2, name: '動力控制IC'},
	{rate: 32.5, name: '電源管理IC'},
	{rate: 9.6, name: '智慧型功率IC'},
	{rate: 18.7, name: '二極體Diode'},
	{rate: 21.6, name: '功率電晶體Power Transistor'},
	{rate: 3.4, name: '閘流體Thyristor'},
]

// 我準備了簡單的色票，作為圓餅圖顯示用的顏色
const colorSet = [
	0x729ECB,
	0xA9ECD5,
	0xA881CB,
	0xF3A39E,
	0xFFD2A1,
	0xBBB5AE,
	0xE659AB,
	0x88D9E2,
	0xA77968,
]
實作弧形。

const curve = new THREE.EllipseCurve(
	0,0, // 橢圓形的原點
	5,5, // X軸的邊長、Y軸的邊長
	0, Math.PI * 0.5, // 起始的角度、結束的角度（90度）
	false,// 是否以順時鐘旋轉
	0//旋轉橢圓
)
你會發現：弧形怎麼不是三維的？

弧形不是三維的，但在待會轉成形狀時，就可以從二維變成三維的。在three.js裡面，橢圓形並不提供三維，然而CubicBezierCurve、QuadraticBezierCurve則提供三維的曲線物件。只要有提供三維的曲線物件，就以3結尾；如果是二維的，就沒有後綴詞。舉例來說，二維的有：

CubicBezierCurve
LineCurve
QuadraticBezierCurve
EllipseCurve
ArcCurve ⇒ 乃EllipseCurve的別名
三維的以3結尾：

CubicBezierCurve3
LineCurve3
QuadraticBezierCurve3
CatmullRomCurve3
起始的角度跟結束得角度分別要填入什麼？

起始的角度以正X軸為起始點，以逆時針方向繪製。

https://ithelp.ithome.com.tw/upload/images/20220930/20142505TtxlNtgJoy.png

我們知道圓形的周長的2PI，所以只要填入0~2PI的數值，就能表達起始/結束的角度了

https://ithelp.ithome.com.tw/upload/images/20220930/2014250503EVfCjLFd.png

轉成二維座標點

getPoints會在線段中取樣。比如我帶入50，它就會將線段點出50個點。

const curvePoints = curve.getPoints(50)
建立一個形狀

const shape = new THREE.Shape(curvePoints)
將形狀當成Geometry

const shapeGeometry = new THREE.ShapeGeometry(shape)
const shapeMaterial = new THREE.MeshBasicMaterial({color: colorSet[0]})
const mesh = new THREE.Mesh(shapeGeometry, shapeMaterial)
scene.add(mesh)
為什麼要將曲線轉成點，再由點轉成形狀？

如果要將物件渲染到畫面上，它必須要有形狀Geometry。從上一篇的圖表可以看到，如果要製作成ExdtrudeGeometry或是ShapeGeometry，都必須由Shape而來，而要製作Shaper，可從點而來，這樣是為什麼我們在上一個步驟必須先轉成點。

https://ithelp.ithome.com.tw/upload/images/20220930/201425059pnpPQcorc.png

以上都完成之後，一個弧形就完成了！

https://ithelp.ithome.com.tw/upload/images/20220930/20142505Unm9dk9Chr.png

你會發現怪怪的地方：我們只會繪製出了弧線。但作為圓餅圖，必須應該從將弧線連到原點才行。

https://ithelp.ithome.com.tw/upload/images/20220930/20142505PQBvipWjqk.png

所以我們可以在繪製弧線之後，畫一條線段到原點，然後只用closePath()來封閉整個路徑。

所以，我們需要兩個函式完成：lineTo(x,y)以及closePath()

const shape = new THREE.Shape(curvePoints)
// 新增下面兩行
// 從當前的.currentPoint劃線到原點
shape.lineTo(0,0)
// 將整個線段的頭尾相連
shape.closePath()
const shapeGeometry = new THREE.ShapeGeometry(shape)
https://ithelp.ithome.com.tw/upload/images/20220930/20142505wzcSVmPtAG.png

我們將建構餅的程式碼包成函式，方便製作多個餅。函式有三個參數：startAngle, endAngle, color 分別代表起始與結束的弧度，以及顏色。

const createPie = (startAngle, endAngle, color) => {
	const curve = new THREE.EllipseCurve(
	0,0, // 橢圓形的原點
	5,5, // X軸的邊長、Y軸的邊長
	0, Math.PI * 0.5, // 起始的角度、結束的角度（90度）
	false,// 是否以順時鐘旋轉
	0//旋轉橢圓
	)
	const curvePoints = curve.getPoints(50)
	const shape = new THREE.Shape(curvePoints)
	shape.lineTo(0,0)
	shape.closePath()
	const shapeGeometry = new THREE.ShapeGeometry(shape)
	const shapeMaterial = new THREE.MeshBasicMaterial({color: colorSet[0]})
	const mesh = new THREE.Mesh(shapeGeometry, shapeMaterial)
	scene.add(mesh)
	return mesh
}

createPie()
我們由變數data來生成圓餅。

const dataToPie = (data) => {
	// 我用sum來記憶上一個餅的結束位置，使得每個餅都從上一個結束位置開始繪製。
	let sum = 0
	data.forEach( (datium,i) => {
		// 將百分比轉換成0~2PI的弧度
		const radian = datium.rate/100 * (Math.PI * 2)
		createPie(sum, radian+sum, colorSet[i])
		sum+=radian
	})
}

dataToPie(data)
我嫌光源的輔助線段有點醜，我把它關掉（非必要）

    // 新增點光
    const addPointLight = () => {
        ...
-       scene.add(lightHelper);
        ...
    }

    // 新增平行光
    const addDirectionalLight = () => {
        ...
-       scene.add(lightHelper);
        ...
    }
https://ithelp.ithome.com.tw/upload/images/20220930/201425059oUaKqH63r.png

還是有一個問題：圓餅圖是扭曲的。當我們斜斜的看著圓餅圖，你看得出來扭曲。

Untitled

這個問題對於圖表視覺化造成很大的問題。光看這張圖，你會覺得紫色比藍色還要大塊，但其實藍色比紫色還大塊。

這個問題會造成誤判，使得圖表出現瑕疵。那如何解決問題呢？

使用OrthographicCamera 取代PerspectiveCamera

+   const windowRatio = window.innerWidth / window.innerHeight
+   const camera = new THREE.OrthographicCamera(-windowRatio * 10, windowRatio * 10, 10, -10, 0.1,1000)
-   const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
由於OrthographicCamera不像PerspectiveCamera一樣具有透視，所以它的參數也不太一樣。

https://ithelp.ithome.com.tw/upload/images/20220930/20142505aVQmcEXwtJ.png

OrthographicCamera提供幾個參數，這些都由鏡頭的中心點(0,0)開始計算：

left: number
right: number
top: number
bottom: number
從結果可以看到：即使將鏡頭轉到側面，紫色與藍色的比例一致。

Untitled

我們的圓餅圖就完成了！

小結
目前我們只是用手工的方式製作2D圓餅圖，但當我們extrude它之後，它就可以成為3D，也能成為它最大的亮點。

CodePen
https://ithelp.ithome.com.tw/upload/images/20220930/20142505KEFXruMdOZ.png

https://codepen.io/umas-sunavan/pen/xxjWJbx?editors=1010

下篇我將介紹如何實作Extrude，並且加上動畫，使得用戶在操作時，都可以看到比一般圖表更立體的效果。

而這種圖表事實上還可以加上文字，而這個技術在「Day13: three.js 3D地球特效開發實戰：飛雷神之術走跳地球！—鏡頭追蹤與浮動文字」就有提到，有興趣的話可以深入研究。

下篇完成品
Untitled

為什麼要製作圓餅圖？
對於嘗試開發3D特效來說，圓餅圖的製作可以由數值產生弧度，由弧度產生線段，由線段產生面，再由面產生3D物件。整條流程使得我們接觸每一個層面的製作。對於實戰線段來說再適合不過。不僅如詞，其所用到的弧度、三角函數、Extrude等製作方法，都能夠深度的解釋。

不僅如此，在實際應用上，圓餅圖不僅能夠增加高級感、獨特性，其增加的第三個維度「高度」也能呈現另一個維度的資料，使得圓餅圖不再只是呈現比例，還能有其他用途。

本篇內容
本篇，我將示例如何將平面的圓餅圖轉成立體，並寫加上文字。事實上，除了立體化以外，圓餅圖還能點擊、Hover以及更多的互動。但我這邊就先聚焦在立體化以及文字上。

完成品
Untitled

加上貼圖、光影、旋轉後的圓餅圖
Untitled

Untitled

準備開發
我們由上一篇開發完的程式碼繼續，這邊附上CodePen可以直接複製程式碼。

CodePen
https://codepen.io/umas-sunavan/pen/xxjWJbx

我們也可以使用下面的程式碼開始：

import * as THREE from 'three';
import { OrbitControls } from 'https://unpkg.com/three@latest/examples/jsm/controls/OrbitControls.js';

const scene = new THREE.Scene();

const windowRatio = window.innerWidth / window.innerHeight
const camera = new THREE.OrthographicCamera(-windowRatio * 10, windowRatio * 10, 10, -10, 0.1,1000)
camera.position.set(0, 3, 15)

// 假設圖表拿到這筆資料
const data = [
	{rate: 14.2, name: '動力控制IC'},
	{rate: 32.5, name: '電源管理IC'},
	{rate: 9.6, name: '智慧型功率IC'},
	{rate: 18.7, name: '二極體Diode'},
	{rate: 21.6, name: '功率電晶體Power Transistor'},
	{rate: 3.4, name: '閘流體Thyristor'},
]

// 我準備了簡單的色票，作為圓餅圖顯示用的顏色
const colorSet = [
	0x729ECB,
	0xA9ECD5,
	0xA881CB,
	0xF3A39E,
	0xFFD2A1,
	0xBBB5AE,
	0xE659AB,
	0x88D9E2,
	0xA77968,
]

const createPie = (startAngle, endAngle, color, depth) => {
	const curve = new THREE.EllipseCurve(
		0,0,
		5,5,
		startAngle, endAngle,
		false,
		0
	)
	console.log(startAngle, endAngle);
	const curvePoints = curve.getPoints(50)
	const shape = new THREE.Shape(curvePoints)
	shape.lineTo(0,0)
	shape.closePath()
	const shapeGeometry = new THREE.ShapeGeometry(shape)
	const shapeMaterial = new THREE.MeshBasicMaterial({color: color})
	const mesh = new THREE.Mesh(shapeGeometry, shapeMaterial)
	scene.add(mesh)
	return mesh
}

const dataToPie = (data) => {
	let sum = 0
	data.forEach( (datium,i) => {
		const radian = datium.rate/100 * (Math.PI * 2)
		createPie(sum, radian+sum, colorSet[i], radian)
		sum+=radian
	})
}

dataToPie(data)

// 新增環境光
const addAmbientLight = () => {
	const light = new THREE.AmbientLight(0xffffff, 0.6)
	scene.add(light)
}

// 新增點光
const addPointLight = () => {
	const pointLight = new THREE.PointLight(0xffffff, 0.2)
	scene.add(pointLight);
	pointLight.position.set(3, 3, 3)
	pointLight.castShadow = true
	// 新增Helper
	const lightHelper = new THREE.PointLightHelper(pointLight, 20, 0xffff00)
	// scene.add(lightHelper);
	// 更新Helper
	lightHelper.update();
}

// 新增平行光
const addDirectionalLight = () => {
	const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8)
	directionalLight.position.set(20, 20, 20)
	scene.add(directionalLight);
	directionalLight.castShadow = true
	const d = 10;

	directionalLight.shadow.camera.left = - d;
	directionalLight.shadow.camera.right = d;
	directionalLight.shadow.camera.top = d;
	directionalLight.shadow.camera.bottom = - d;

	// 新增Helper
	const lightHelper = new THREE.DirectionalLightHelper(directionalLight, 20, 0xffff00)
	// scene.add(lightHelper);
	// 更新位置
	directionalLight.target.position.set(0, 0, 0);
	directionalLight.target.updateMatrixWorld();
	// 更新Helper
	lightHelper.update();
}

addAmbientLight()
addDirectionalLight()
addPointLight()

const renderer = new THREE.WebGLRenderer();
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild( renderer.domElement );

// 在camera, renderer宣後之後加上這行
new OrbitControls(camera, renderer.domElement);

scene.background = new THREE.Color(0xffffff)
function animate() {
	requestAnimationFrame( animate );
	renderer.render( scene, camera );
}
animate();
開發立體圓餅圖
Extrude圓餅圖的方法
上一篇我們提到，線段本身並沒有Mesh。

渲染的底層原理說起
我這邊再重新補充一次：我們之所以可以在畫面中看到一個物件，是因為我們在渲染一個物件時，給定three.js一個Geometry以及一個Material來得到一個Mesh。那為什麼three.js可以透過這兩個東西去渲染物件？那是因為在底層的WebGL由vertexShader以及fragmentShader所組成。前者透過Geometry抓到錨點在螢幕上的位置，後者得到前者的錨點位置再指定每一個像素的顏色。

https://ithelp.ithome.com.tw/upload/images/20221001/20142505CG2Dwkpbc0.png

所以說，如果沒有錨點資料能夠提供給three.js作為Geometry，那three.js就沒辦法把錨點資料傳送給WebGL裡面的vertexShader，那麼fragmentShader也沒辦法依據錨點給定顏色。

線段要渲染的方式
由上面可以得知，線段終究要組成Geometry才能渲染在像素上。而要組成Geometry有很多種方式，下面是一張我整理的圖表，箭頭代表物件可以轉換的對象。

https://ithelp.ithome.com.tw/upload/images/20221001/20142505dH7owappor.png

藍色表示線段可以轉成的Geometry。你可以看到主要有四個：ShapeGeometry、ExtrudeGeometry、BufferGeometry、TubeGeometry 四種。

這四個Geometry 的差異如下：

ShapeGeometry ：產生一個具有面的形狀
ExtrudeGeometry：產生一個具有體積的物體
BufferGeometry：由用戶帶入錨點位置而不指定任何作用。所以它有可能是三角面位置資訊，也可能是三角面Normal資訊，有可能是其他資訊。
TubeGeometry：沿著線段產生一條「水管」
以目前圓餅圖專案來說：
在上一篇，由於只需要做出平面的圓餅圖，所以我們使用ShapeGeometry。而今要做出3D的圓餅圖，那麼是用ExtrudeGeometry最為合適。

-   const shapeGeometry = new THREE.ShapeGeometry(shape)
+   const shapeGeometry = new THREE.ExtrudeGeometry(shape, {
+       depth: depth*2, // 隆起高度
+       steps: 1, // 在隆起的3D物件中間要切幾刀線
+       bevelEnabled: false, // 倒角（隆起向外擴展）
+     })
ExtrudeGeometry 提供很多參數，先講三個：

Depth：隆起高度
Step：在隆起的3D物件中間要切幾刀線
bevelEnabled：在隆起的Extrude面上是否要再向外擴展
可見下圖：

https://ithelp.ithome.com.tw/upload/images/20221001/20142505bmTEPPFfcP.png

最後完成會長這樣：

https://ithelp.ithome.com.tw/upload/images/20221001/20142505DHCZiJNrGF.png

我們的形狀長出來了，然而沒有陰影使人看不清楚圖表。

為什麼會沒有陰影？那是因為我們所選用的材質為MeshBasicMaterial。

Material可以比擬為物件所穿著的衣服，MeshBasicMaterial 使得顏色都一致。但如果要製作一個有亮暗面的材質，使用其它種Material即可。我都使用MeshStandardMaterial，原因是因為在3D建模軟體輸出時（例如在Maya使用Verge3D輸出GLTF格式模型），MeshStandardMaterial為常見的材質輸出結果。由此可以獲得GLTF格式的最大相容性。

修改材質
-    const shapeMaterial = new THREE.MeshBasicMaterial({color: color})
+    const shapeMaterial = new THREE.MeshStandardMaterial({color: color})
修改後，就可以看到效果：

https://ithelp.ithome.com.tw/upload/images/20221001/20142505JWm5bH01v7.png

高度不一致問題
雖然有了立體感，但看到去不是那麼清楚。主要問題是高度不一。高高低低的，很難讓人比較各個餅之間的差異。

為了解決這個問題，我們幫餅排序即可。

// 在data進入forEach之前加上sort即可
data = data.sort((a,b) => b.rate - a.rate)
https://ithelp.ithome.com.tw/upload/images/20221001/20142505u28Nrr4D7M.png

可以看到餅已經清楚很多。

邊界銳利問題
接著你會發現，邊緣太銳利了，很沒有質感。

要做到最好看的特效，當然不能放著這個不管，畢竟銳利的邊緣使人感到東西廉價。

前面我們在extrude時，有一個參數叫做bevel，打開它即可。

const shapeGeometry = new THREE.ExtrudeGeometry(shape, {
    ...
	bevelEnabled: false, // 倒角（隆起向外擴展）
  })
https://ithelp.ithome.com.tw/upload/images/20221001/201425053PYM7op46O.png

在以前學校的Maya老師稱它倒角。倒角有四個參數，下面我用圖片解釋：

bevelThickness: 倒角的高度
bevelSize: 倒角的厚度
bevelOffset: 製作倒角之前的位移
bevelSegments: 倒角的細緻度
https://ithelp.ithome.com.tw/upload/images/20221001/20142505SJ6zQcQE4d.png

必須注意跟Maya的不同

在Maya使用Bevel時，並沒有新增度厚度，而是直接向內切出倒角，這個概念跟three.js非常不同。如果是建模師在認識three.js的Bevel時，必須注意。

Untitled

我們釐清原理之後，參數設定上更加方便。直接加上參數就能夠完成Bevel，使得我們的模型更有高級感。

https://ithelp.ithome.com.tw/upload/images/20221001/20142505LOdqGaiYvt.png

Bevel重疊問題
可以發覺不預期的顏色跑出來了。

https://ithelp.ithome.com.tw/upload/images/20221001/20142505AqAcnU5Jo9.png

這是因為Bevel互相重疊導致。

https://ithelp.ithome.com.tw/upload/images/20221001/20142505Tziuv03c7O.png

為了解決這個問題，我們只要把餅從原點向外位移即可。

https://ithelp.ithome.com.tw/upload/images/20221001/201425055aUwOUCCKe.png

要做這樣的，首先需要知道箭頭方向。

箭頭的方向，就使弧線的起始角度與終點角度的中間值。

https://ithelp.ithome.com.tw/upload/images/20221002/2014250507qwj5W6Wf.png

const middleAngle = (startAngle + endAngle) / 2
取得中間的角度之後，我們透過三角函數，算出其角度所指的單位向量，並乘上倒角的大小（0.2）

https://ithelp.ithome.com.tw/upload/images/20221001/20142505gtBy3wEQOr.png

由上圖可知，中間的角度可以拆成X,Y兩軸的長度，而X數值為向量的斜邊分之對邊，Y數值為向量的斜邊分之鄰邊。

const x = Math.cos(middleAngle)
const y = Math.sin(middleAngle)
接著只要再乘上倒角大小即可。

shapeGeometry.translate(x*0.2, y*0.2, 0)
https://ithelp.ithome.com.tw/upload/images/20221001/20142505iZGAW0dfU4.png

這樣就完成了。

你看得到還是有一點瑕疵，那是因為我們向外移動的不夠多。然而一旦我們向外，圓餅圖的中心又會中空。

https://ithelp.ithome.com.tw/upload/images/20221001/20142505vJqZnu1Zuu.png

要解決這個問題，就是在實例化餅之前，先預留Bevel的角度。但由於篇幅關係我就暫時不討論這個問題的解決解法，我先繼續專注在餅的開發。因為我們的餅目前為止只有顏色跟比例，如果沒有加上圖例（Legend）的話，沒有人知道這些餅的意義。

加上圖例
匯入粉圓體：FontLoader
如同在「Day13: three.js 3D地球特效開發實戰：飛雷神之術走跳地球！—鏡頭追蹤與浮動文字」所提到的浮動文字製作方法一樣，我們需要準備字體。字體選用開源字體粉圓體。

import { FontLoader } from 'https://unpkg.com/three@latest/examples/jsm/loaders/FontLoader.js';
import { TextGeometry } from 'https://unpkg.com/three@latest/examples/jsm/geometries/TextGeometry.js';

const loader = new FontLoader();
loader.load( 'https://storage.googleapis.com/umas_public_assets/michaelBay/day13/jf-openhuninn-1.1_Regular_cities.json', function ( font ) {
	//所有網頁邏輯
})
我們所有的邏輯都等到字體載入之後才會執行。

字體方面使用粉圓體，下載之後透過facetype.js將字體檔轉成json格式，再匯入到專案中即可。

https://ithelp.ithome.com.tw/upload/images/20221001/20142505vAljLuwIgQ.png

建立字體函式
文字Mesh如同其它種類的3D物件一樣，都需要形狀跟材質才能實例化。這邊使用TextGeometry以由字體產生錨點，最終能夠做成形狀。

// 該函式新增文字Mesh
const addText = (text, color) => {
	// 文字geometry
	const textGeometry = new TextGeometry( text, {
		font: font, //字體
		size: 2,//大小
		height: 0.01,//文字厚度
		curveSegments: 2, // 文字中曲線解析度
		bevelEnabled: false, // 是否用bevel
	} );
	const textMaterial = new THREE.MeshBasicMaterial({color: color})
	const textMesh = new THREE.Mesh(textGeometry, textMaterial)
	scene.add(textMesh)
	return textMesh
}
// 執行函式測試一下
const text =addText('openhuninn', 0xfff000)
// 防止文字被圓餅圖擋住
text.position.z = 8
新增後可以看到文字照常呈現。

Untitled

每個餅都加上文字
在createPie()裡面執行addText()，使得每個餅都可以加上文字

const createPie = (startAngle, endAngle, color, depth) => {
	...
	const text = addText('openhuninn', color)
	...
}
雖然每個餅都有文字了，但還有兩個問題：

文字內容不正確，必須得知每個圓餅圖的內容標題才能生成文字。解決方法：目前文字內容在函式createPie()外層，只要傳入內層即可。
文字得位在餅旁邊，目前所有文字的位置都是原點。解決方法：我們得知道餅的角度及邊長，才可以透過三角函數產生文字位置。幸虧前面已經有透過三角函數來將餅向外移動了，我們只要拿來用就好。
先處理文字問題。將文字傳入函式中：

// 加上參數legned
+   const createPie = (startAngle, endAngle, color, depth, legend) => {
-   const createPie = (startAngle, endAngle, color, depth) => {
        ...
    // 使用legend作為文字內容
+       const text = addText(legend, color)
-       const text = addText('openhuninn', color)
        ...
    })
    // 執行函式的地方也必須把參數補齊
    createPie(..., ..., ..., ..., datium.name)
https://ithelp.ithome.com.tw/upload/images/20221001/20142505Kml6dFL2mZ.png

接下來安排文字的位置。透過已經算好的三角函數，再乘上半徑即可。

const middleAngle = (startAngle + endAngle) / 2
const x = Math.cos(middleAngle)
const y = Math.sin(middleAngle)
// 由於圓餅圖半徑為，所以我設成8.5
const textDistance = 8.5
text.geometry.translate(x*textDistance,y*textDistance,0)
// 修正文字置左時的偏移
text.geometry.translate(x-([...legend].length)*0.2,y,0)
我順便修改了文字大小

const textGeometry = new TextGeometry( text, {
		...
		// 我修改了文字大小
-		size: 2,
+		size: 0.5,
		...
	} );
https://ithelp.ithome.com.tw/upload/images/20221001/20142505EBnjr0HDuF.png

使文字面向鏡頭
這招我們也有在「Day13: three.js 3D地球特效開發實戰：飛雷神之術走跳地球！—鏡頭追蹤與浮動文字」使用過，我這邊就不詳述細節。

function animate() {
	// 遞回每一個3D文字物件
	texts.forEach( text => {
		// 使3D文字「幾乎」看向鏡頭，同時仍被方向影響，以增加視覺豐富度
		text.lookAt(...new THREE.Vector3(0,0,1).lerp(camera.position, 0.05).toArray())
	})
	...
}
完成品
Untitled

CodePen
https://codepen.io/umas-sunavan/pen/LYmmbZM

小結
事實上，圓餅圖特效還可以加上貼圖、動畫等等先前介紹過的元素，使得畫面更加豐富。

圓餅圖可以運用的特效非常多，而且不只圓餅圖，其他種類的圖表也能加以發揮。

Untitled

Untitled

圓餅圖界介紹到這邊，希望可以藉此使更多人熟悉線段的開發。

前言
網頁視覺特效有一大塊領域在於GIS。GIS以視覺呈現地理資訊，視覺是不可或缺的元素。透過視覺特效，能夠更快速的釐清地理環境狀況。

例如Districgraphic.tw，就使用鄉鎮市區為最小單位，去呈現資料。

Untitled

https://ithelp.ithome.com.tw/upload/images/20221002/20142505curEM77KeS.png

而對於GIS類型的專案來說，最重要的工作，不外乎來源資料的格式轉換。來源資料可能有幾種：

多個座標的資料：

例如：例如青少年犯罪地點分佈圖。
常用格式：GeoJson、SHP and SHX。
交通資料：

例如：物流公司最佳路線規劃。

常用格式：GeoJson

https://ithelp.ithome.com.tw/upload/images/20221002/20142505O7q2oZJtxe.png

圖磚：使用地圖圖資（靜態圖磚Static Tile）

例如：鐵路工程地層下陷分析。
常用格式：png或是geoJson
Untitled

Untitled

模型資料：

例如：預載好的建築物、地形
常用格式：gltf檔、svg、json、png等多種。
https://ithelp.ithome.com.tw/upload/images/20221002/20142505wfeLT6VByk.png

時間、位置跟角度：

例如：空拍機固定路線可以掃到的區域，大樓阻擋的投影範圍
常用格式：時間、三維座標
點陣資料：

例如：氣象雲圖、降雨量圖
常用格式：jpg或png等
https://ithelp.ithome.com.tw/upload/images/20221002/20142505gypVGIi1LK.jpg

下圖使用上圖作為來源，渲染立體效果。

Untitled

錨點資料：

例如：呈現特定交通路徑
常用格式：座標、GeoJson
以及非常多應用方式。

以上這些，three.js都辦得到。我這邊以SVG來生成模型，由於SVG為標籤語言，我們可以看到錨點資料，而且SVG為廣用的格式。雖然如此，SVG在匯入到three.js時仍然有很多眉角需要注意。

我將介紹以下內容：

SVG渲染成3D物件的流程說明
SVGLoader的使用方法
three.js的Loader其異步讀入方法說明
shapePath說明
Path轉成3D Mesh時的效能問題
SVG的方位問題
從SVG讀入CSS樣式，並在3D物件中填色
從SVG讀入ID值
處理extrude時的normal問題
由SVG渲染模型
流程說明
前一篇提到extrude，本篇亦同，然而實作的方向不太相同。

製作圓餅圖時，我們從原始資料轉成角度，再轉成弧度。有了弧度之後，製作出EllipseCurve，再轉成Vector2，再轉成Shape，再轉成ExtrudeGeometry。見圖：

https://ithelp.ithome.com.tw/upload/images/20221002/20142505rlViHQqkxb.png

本次實作中，我們由SVG出發，由SVGLoader讀入之後，會是一個ShapePath格式。透過SVGLoader.createShpes()後，就能夠得到shape物件，最終Extrude成物件。

https://ithelp.ithome.com.tw/upload/images/20221002/20142505jNrXph0auY.png

不管是怎樣的讀入方式，如果要渲染到畫面上，就得要挑一個geometry來產生3D物件，在這之前，一切都只是描述形狀資料而已。

準備程式碼
首先，我們先透過three.js範本開一個新的專案。我們直接沿用這個空的three.js範本即可：

CodePen
https://ithelp.ithome.com.tw/upload/images/20221002/20142505csLkXUG4O0.png

https://codepen.io/umas-sunavan/pen/WNJJXXK?editors=0010

原始碼
複製貼上的index.js，然後開一個html來引用即可。可以參考Codepen。

import * as THREE from 'three';
import { OrbitControls } from 'https://unpkg.com/three@latest/examples/jsm/controls/OrbitControls.js';

const renderer = new THREE.WebGLRenderer();
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild( renderer.domElement );

const scene = new THREE.Scene();
scene.background = new THREE.Color(0xf2f2f2)
const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
camera.position.set(0, -500, 900)
// 在camera, renderer宣後之後加上這行
const control = new OrbitControls(camera, renderer.domElement);

control.target.set(250,-250,0)
control.update()

// 新增環境光
const addAmbientLight = () => {
	const light = new THREE.AmbientLight(0xffffff, 0.6)
	scene.add(light)
}

// 新增平行光
const addDirectionalLight = () => {
	const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8)
	directionalLight.position.set(20, 20, 20)
	scene.add(directionalLight);
	directionalLight.castShadow = true
	const d = 10;

	directionalLight.shadow.camera.left = - d;
	directionalLight.shadow.camera.right = d;
	directionalLight.shadow.camera.top = d;
	directionalLight.shadow.camera.bottom = - d;

	// 新增Helper
	const lightHelper = new THREE.DirectionalLightHelper(directionalLight, 20, 0xffff00)
	scene.add(lightHelper);
	// 更新位置
	directionalLight.target.position.set(0, 0, 0);
	directionalLight.target.updateMatrixWorld();
	// 更新Helper
	lightHelper.update();
}

addAmbientLight()
addDirectionalLight()

function animate() {
	requestAnimationFrame( animate );
	renderer.render( scene, camera );
}
animate();
加上原始資料，用來呈現不同區域的高度

// 假設GIS來源資料如下
const data = [
	{ rate: 14.2, name: '雲嘉' },
	{ rate: 32.5, name: '中彰投' },
	{ rate: 9.6, name: '南高屏' },
	{ rate: 9.7, name: '宜花東' },
	{ rate: 21.6, name: '北北基' },
	{ rate: 3.4, name: '桃竹苗' },
	{ rate: 9.0, name: '澎湖' },
]
讀取SVG
讀取SVG：讀取物件
加入SVGLoader()，使用函式.load() 或.loadAsync()匯入模型檔。

import { SVGLoader } from 'https://unpkg.com/three@latest/examples/jsm/loaders/SVGLoader.js';

const loadPathsFromSvg = () => {
	const loader = new SVGLoader();
	loader.load('taiwan.svg', svgData => {
		console.log(svgData);
	})
}

loadPathsFromSvg()
https://ithelp.ithome.com.tw/upload/images/20221002/20142505q4ERCaKepA.png

補充說明：.loadAsync()與.load()差異
到目前為止，我們使用了TextrueLoader, SVGLoader, FontLoader等各種loader。three.js存在各種loader，提供我們多種資料的匯入。

Loader必須手動處理異步嗎？

所有的Loader，提供函式：

Loader.load( path, callback)
其中，path 代表路徑，callback代表讀取完之後的回呼函式。事實上還有失敗的回呼函式、讀取中進度調的回呼函式等多種，依照Loader而定。

這代表如果我們需要讓異步變成同步，必須手動包Promise才行：

const loadPathsFromSvg = async () => {
	const loader = new SVGLoader();
	// 手動用Proise把異步包成同步
	return new Promise( (res, rej) => {
		loader.load('taiwan.svg', svgData => {
			res(svgData)
		})
	})
}
一些網路教學就使用這個方式開發。

你不需要自己包Promise
但事實上，所有的Loader也都提供loadAsync()：

Loader.loadAsync( path )
而回傳的即為一個Promise。所以說，可以loader的函式可以這樣撰寫：

const loadPathsFromSvg = async () => {
	const loader = new SVGLoader();
	const data = await loader.loadAsync('taiwan.svg')
}
甚至一行搞定：

const loadPathsFromSvg = async () => await new SVGLoader().loadAsync('taiwan.svg');
所以說，可以善用loadAsync()，使得異步程式碼更加簡潔

讀取SVG：改用loadAsync讀取
我將load()改成loadAsync()，並且讀取svg資料中的paths：

import { SVGLoader } from 'https://unpkg.com/three@latest/examples/jsm/loaders/SVGLoader.js';

const loadPathsFromSvg = async () => await new SVGLoader().loadAsync('taiwan.svg');

(async () => {
	const svgData = await loadPathsFromSvg()
	const paths = svgData.paths
	console.log(paths);
})()
可以看到，我們讀取很多的shapePath，而這些shapePath 是什麼？又是從哪來的？

https://ithelp.ithome.com.tw/upload/images/20221002/20142505cRK8VqMCJh.png

讀取SVG：shapePath是什麼？
shapePath 是一種能夠儲存多個shape的Path。能透過.toShape() 或是 SVGLoader.screateShapes() 來轉成Shape。

https://ithelp.ithome.com.tw/upload/images/20221002/20142505X9Pf8ORfeb.png

讀取SVG：shapePath 從哪裡來的？
如果我們打開taiwan.svg，會發現有幾個<path>：

<?xml version="1.0" encoding="utf-8"?>
<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 538 540" style="enable-background:new 0 0 538 540;" xml:space="preserve">
    <g id="澎湖">
        <path d="..."/>
        <path d="..."/>
        <path d="..."/>
        <path d="..."/>
        <path d="..."/>
        <path d="..."/>
        <path d="..."/>
        <path d="..."/>
        <path d="..."/>
        <path d="..."/>
    </g>
    <g id="宜花東">
        <path d="..."/>
        <path d="..."/>
    </g>
    <path id="南高屏" d="..."/>
    <path id="雲嘉" d="..."/>
    <path id="中彰投" d="..."/>
    <path id="桃竹苗" d="..."/>
    <path id="北北基" d="..."/>
</svg>
SVGLoader遍歷所有路徑，並且變成shapePath陣列。同時儲存顏色、Id、class等基本屬性，而這就夠我們使用了。

將Path轉成3D Mesh
https://ithelp.ithome.com.tw/upload/images/20221002/20142505eLuLyLQQVZ.png

依照流程圖，我們只要透過SVGLoader.createShape() 即可將ShapePath轉成Shape，然後放到extrudeGeometry 中。

我們遞迴每一個path，透過SVGLoader.createShapes(); 產生出shape，並轉成geometry，最終實例化Shape 成為Mesh，加到場景中


(async () => {
	const svgData = await loadPathsFromSvg()
	const paths = svgData.paths
	const group = new THREE.Group();
	// 遞迴paths
	paths.forEach( path => {
		const shapes = SVGLoader.createShapes(path);
		const material = new THREE.MeshStandardMaterial();	
		shapes.forEach( shape => {
			const geometry = new THREE.ExtrudeGeometry(shape);
			const mesh = new THREE.Mesh(geometry, material);
			// 將所有可渲染的Mesh加入成群組物件group
			group.add(mesh);
		})
	})
	// 顯示群組物件，就可以顯示群組底下的物件
	scene.add(group);
})()
https://ithelp.ithome.com.tw/upload/images/20221002/20142505Q5SpYh3cV3.png

可以看到台灣已經跑出來了。

但現在遇到幾個問題：

操作非常卡頓
台灣是倒過來的
各地區都是白色，看不出差異。
我們一個一個解決：

將Path轉成3D Mesh：效能問題
畫面相當卡頓，如果我們把material的wireframe打開，可以看到這個SVG由相當多的點所組成。

https://ithelp.ithome.com.tw/upload/images/20221002/20142505VPoBzthSGP.png

這造成很大的效能問題。為了解決這個問題，我們可以透過extrude的設定中，簡化路徑：

// const geometry = new THREE.ExtrudeGeometry(shape);
// 取消bevel、steps設成1
const geometry = new THREE.ExtrudeGeometry(shape, {
		steps: 1,
		bevelEnabled: false
});
將Path轉成3D Mesh：為什麼台灣是倒過來的？
之所以台灣是倒過來的，是因為SVG跟Three.js相容性問題，以下解釋：

Three.js的(0,0)原點為左下，而SVG的(0,0)原點為左上，導致在SVGLoader在匯入時，會顛倒。

https://ithelp.ithome.com.tw/upload/images/20221002/20142505aPE7KLkfT7.png

為了解決這個問題，我們只要用.rotateX(Math.PI)把整個畫面旋轉即可。又或者將Perspectiveamera.up設置成-1 ，使得鏡頭方向上下顛倒。

(async () => {
	const svgData = await loadPathsFromSvg()
	const paths = svgData.paths
	const group = new THREE.Group();
	// 遞回時，已經把台灣所有地區加入到group裡面
	paths.forEach( ... )
	// 旋轉3D物件即可
	group.rotateX(Math.PI)
	scene.add(group);
})()
https://ithelp.ithome.com.tw/upload/images/20221002/20142505vlz7Gtdcza.png

設定之後，顛倒問題即解決。

將Path轉成3D Mesh：用顏色區分地區
每一個path，除了儲存id值、class值、路徑資料以外，還有它所儲存的CSS資料。如果我們看到SVG，可以發現它存有顏色，並統一在<style/>裡面管理了。

<?xml version="1.0" encoding="utf-8"?>
<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 538 540" style="enable-background:new 0 0 538 540;" xml:space="preserve">
    <style type="text/css">
        .st0{fill:#D6DE23;}
        .st1{fill:#D0E299;}
        .st2{fill:#C6E9FA;}
        .st3{fill:#FFF100;}
        .st4{fill:#CE8A2D;}
        .st5{fill:#CCDDE6;}
    </style>
    <g id="澎湖">
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st1" d="..."/>
    </g>
    <g id="宜花東">
        <path class="st1" d="..."/>
        <path class="st1" d="..."/>
    </g>
    <path id="南高屏" class="st2" d="..."/>
    <path id="雲嘉" class="st0" d="..."/>
    <path id="中彰投" class="st3" d="..."/>
    <path id="桃竹苗" class="st4" d="..."/>
    <path id="北北基" class="st5" d="..."/>
</svg>
樣式可能存在style，也可能存在行內屬性。無論如何，SVGLoader都可以輕易抓到樣式資料，相當方便，我們只要將顏色放到material即可。

// const material = new THREE.MeshStandardMaterial();
const color = path.color
const material = new THREE.MeshStandardMaterial({color});
https://ithelp.ithome.com.tw/upload/images/20221002/20142505vaq5D98rcG.png

將數值轉成物件高度
這個作法已經有在上一篇「Day16: three.js 前端3D視覺特效開發實戰——3D儀表板：立體圓餅圖、extrude在three獨特差異」已經有提到。

將數值轉成物件高度：抓取SVG中的ID
然而不同的是，我們得在SVG裡面抓到ID值，然後對照在數據資料，藉此找到對應3D物件，調整其高度。

// 既有的數據資料
const data = [
	{ rate: 14.2, name: '雲嘉' },
	{ rate: 32.5, name: '中彰投' },
	{ rate: 9.6, name: '南高屏' },
	{ rate: 9.7, name: '宜花東' },
	{ rate: 21.6, name: '北北基' },
	{ rate: 3.4, name: '桃竹苗' },
	{ rate: 9.0, name: '澎湖' },
]

...

const color = path.color
// 除了顏色以外，我們還可以抓到id值
const name = path.userData.node.id
// 抓到ID值之後，對照數據資料
const dataRaw = data.find(row => row.name === name)
將數值轉成物件高度：抓取Group中的ID
這個作法會有一個問題：如果path位在群組，那麼將抓不到群組ID

回顧我們的svg檔案，由於澎湖、宜花東有離島，導至它透過群組來命名

<?xml version="1.0" encoding="utf-8"?>
<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 538 540" style="enable-background:new 0 0 538 540;" xml:space="preserve">
    <g id="澎湖">
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st0" d="..."/>
        <path class="st1" d="..."/>
    </g>
    <g id="宜花東">
        <path class="st1" d="..."/>
        <path class="st1" d="..."/>
    </g>
    <path id="南高屏" class="st2" d="..."/>
    <path id="雲嘉" class="st0" d="..."/>
    <path id="中彰投" class="st3" d="..."/>
    <path id="桃竹苗" class="st4" d="..."/>
    <path id="北北基" class="st5" d="..."/>
</svg>
舉例來說，澎湖有很多離島，每一個離島都是一個Path。我們該怎麼確定哪些path是澎湖呢？

如果沒有額外處理，那麼這些存在群組內的path是抓不到id值的。而我處理的方式，就是抓取parent的ID值。

- const name = path.userData.node.id
+ const parentName = path.userData.node.parentNode.id;
+ const name = path.userData.node.id || parentName
如此一來，就可以替每一個mesh抓到正確的名字，進而賦予高度的數值。

https://ithelp.ithome.com.tw/upload/images/20221002/20142505FQiClvoK24.png

將數值轉成物件高度：賦予高度值
修改ExtrudeGeometry的參數即可。

-   const geometry = new THREE.ExtrudeGeometry(shape, {
-   		steps: 1,
-   		bevelEnabled: false
-   });
+   // 由ID抓取對應的數據資料，作為高度
+   const dataRaw = data.find(row => row.name === name)
+   const geometry = new THREE.ExtrudeGeometry(shape, {
+       depth: dataRaw.rate,
+       steps: 1,
+       bevelEnabled: false
+   });
修改後，我們的模型就有了高度：

https://ithelp.ithome.com.tw/upload/images/20221002/20142505o89Vl0qGdf.png

https://ithelp.ithome.com.tw/upload/images/20221002/20142505K4OtoyfYdk.png

你會看到，它Extrude的方向跟我們想像的不同。

將數值轉成物件高度：修改Extrude方向
由於我們把模型用group.rotateX(Math.PI)翻到了背面，雖然這麼做使得台灣是面向鏡頭的，但實際上extrude是往背面長出來的。

為了解決問題，將depth改成負值即可：


const geometry = new THREE.ExtrudeGeometry(shape, {
-	depth: dataRaw.rate,
+	depth: -dataRaw.rate,
	steps: 1,
	bevelEnabled: false
});
但又出現一個問題：雖然extrude方向雖然面對了鏡頭，但normal方向仍然錯誤。

https://ithelp.ithome.com.tw/upload/images/20221002/20142505tyw5aTlCEw.png

https://ithelp.ithome.com.tw/upload/images/20221002/201425050PQMgyWIWU.png

由圖可知，由於normal方向往內，導至畫面怪怪的。

為什麼normal跟這個有關？

一般來說，我們只看得到normal的正面，它的背面是不會自動渲染的。這個在Maya, 3ds Max, Blender, babylon.js都一樣，是普遍的預設渲染方式。畢竟我們看不到

polygon-drawing-order.gif

圖片來源

此這個動畫來看，你會發現，在「F」內側的面根本不沒要渲染，因為用戶根本就不會看到那面。（這張圖僅作為示意圖，實際上渲染順序不會是這樣）

為了節省渲染效能，3D引擎往往就得判斷該面是否為normal的正面。如果是背面就不用渲染。

因此，我們可以設定物件只渲染背面，如此一來就能夠正常顯示畫面。

  const color = path.color
- const material = new THREE.MeshStandardMaterial({color});
+ const material = new THREE.MeshStandardMaterial({color,side: THREE.BackSide,});
一個台灣的高度圖就做出來了。

完成品
https://ithelp.ithome.com.tw/upload/images/20221002/20142505sl6m1tyXUo.png

Untitled

CodePen
https://ithelp.ithome.com.tw/upload/images/20221002/201425057ccJlUa2wa.png

https://codepen.io/umas-sunavan/pen/eYrrVvy?editors=0010

小結
多虧先前圓餅圖的練習，我們能夠很快速的建立3D物件。有了SVG讀入的功能，不僅可以自己透過SVG製作模型，也可以透過three.js製作3D的GIS網站。

如果有興趣認識更多這類GIS地圖的開發，可以到Districgraphic.tw，或是geostat.tw觀察原始碼。

Untitled

Untitled

參考資料
SVG顛倒時的討論

渲染順序

地理資訊地圖

台灣雲圖



本篇透過3D模型介紹陰影。如此一來，我們可以得到3D模型的作品，也能同時釐清陰影的實作以及其原理。

本篇介紹：

陰影的實作
陰影的本質
渲染問題解決方法
Self-Shadow Aliasing問題
Bias修正
各種光源所產生的陰影差異
陰影的實作
陰影的實作：準備程式碼
import * as THREE from 'three';
import { OrbitControls } from 'https://unpkg.com/three@latest/examples/jsm/controls/OrbitControls.js';
import { GLTFLoader } from 'https://unpkg.com/three@latest/examples/jsm/loaders/GLTFLoader';
import { RectAreaLightHelper } from 'https://unpkg.com/three@latest/examples/jsm/helpers/RectAreaLightHelper.js';
import { RectAreaLightUniformsLib } from 'https://unpkg.com/three@latest/examples/jsm/lights/RectAreaLightUniformsLib.js';

const scene = new THREE.Scene();

const camera = new THREE.PerspectiveCamera(20, window.innerWidth / window.innerHeight, 0.1, 100);
camera.zoom = 0.4
camera.updateProjectionMatrix();
camera.position.set(5, 5, 10)

const renderer = new THREE.WebGLRenderer({ antialias: true });
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild(renderer.domElement);
renderer.toneMapping = THREE.ACESFilmicToneMapping

const sphereGeometry = new THREE.SphereGeometry(50, 30, 30)
const planeMaterial = new THREE.MeshStandardMaterial({ side: THREE.BackSide, color: 0xcceeff })
const sphere = new THREE.Mesh(sphereGeometry, planeMaterial)
sphere.position.set(0, 0, 0)
scene.add(sphere)

new GLTFLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/file.gltf', gltf => {
	gltf.scene.traverse(object => {
		if (object.isMesh) {
			object.material.roughness = 1
			object.material.metalness = 0
			object.material.transparent = false
		}
	})
	scene.add(gltf.scene)
})

// 聚光燈
const addSpotLight = () => {
	const spotLight = new THREE.SpotLight(0xffffff, 1);
	spotLight.position.set(3, 3, 0);
	scene.add(spotLight);
}

// 新增環境光
const addAmbientLight = () => {
	const light = new THREE.AmbientLight(0xffffff, 1)
	scene.add(light)
}

const control = new OrbitControls(camera, renderer.domElement);
control.target.set(0, 2, 3)
control.update()

addSpotLight()
addAmbientLight()

function animate() {
	requestAnimationFrame(animate);
	renderer.render(scene, camera);
}
animate();
CodePen
https://ithelp.ithome.com.tw/upload/images/20221003/20142505opA3i3mVbA.png

https://codepen.io/umas-sunavan/pen/ZEoRWov?editors=1010

陰影的實作：開啟Shader渲染
基本上，整個陰影的實作只要做三件事即可：

在renderer開啟shadow功能。
光能在物件上蒙上陰影
物體可以產生陰影（且同時還能在物件上蒙上陰影）
這三個缺一不可。我們從第一個「在renderer開啟shadow功能。」開始：

const renderer = new THREE.WebGLRenderer({ antialias: true });
// 加上這行程式碼
renderer.shadowMap.enabled = true
陰影的實作：光能蒙上陰影到物件
先找到光，然後將其屬性castShadow 設定成true，即可蒙上陰影到物件

// 聚光燈
const addSpotLight = () => {
	const spotLight = new THREE.SpotLight(0xffffff, 1);
	// 加上這行程式碼來蒙上陰影到物件
	spotLight.castShadow = true;
}
為什麼蒙上了陰影卻沒有任何陰影跑出來？因為我們還需要設定物件能產生陰影。繼續看：

陰影的實作：物體可以產生陰影，同時也能蒙上陰影到物件
receiveShadow 可以產生陰影，加它在你要的Mesh上面，即可生效。

// 載入的物件
new GLTFLoader().load('https://storage.googleapis.com/umas_public_assets/michaelBay/file.gltf', gltf => {
	// 遞迴模型場景中每一個3D的物件
	gltf.scene.traverse(object => {
		if (object.isMesh) {
			object.material.roughness = 1
			object.material.metalness = 0
			object.material.transparent = false
			// 加上這行程式碼能蒙上陰影到物件
			object.castShadow = true
			// 加上這行程式碼產生陰影
			object.receiveShadow = true
		}
	})
	scene.add(gltf.scene)
})
由於物體本身可能產生陰影，蒙在自己本身，所以也需要加上castShadow 。

陰影的實作：完成品
https://ithelp.ithome.com.tw/upload/images/20221003/201425052NvHuAhI6o.png

這樣就完成了！原來那麼簡單嗎？

https://codepen.io/umas-sunavan/pen/ExLRKLp?editors=1010

依照經驗，陰影其實相當麻煩，很容易出現各式各樣「怪怪的東西」，如果不熟悉陰影的底層，那很難找到問題。身為前端視覺特效工程師，熟悉底層的運作邏輯就變得相當重要。

陰影的實作：渲染問題
舉例來說：

為什麼高度差不多的Mesh會有髒髒的表面？

https://ithelp.ithome.com.tw/upload/images/20221003/20142505HBCM395pDZ.png

為什麼騎樓的柱子有奇怪的鋸齒狀？

https://ithelp.ithome.com.tw/upload/images/20221003/20142505cvATuFPkto.png

為什麼地板破圖（shadow acne）？

https://ithelp.ithome.com.tw/upload/images/20221003/20142505elxAq3MBSm.png

圖片來源

為什麼會Mesh跟陰影相黏的地方會漏光？

https://ithelp.ithome.com.tw/upload/images/20221004/20142505L9gvRuaSjT.png

為什麼陰影會一格一格的？而且那麼粗糙？（Shadows Leaks或稱Light Leak，目前所查稱呼不明確）

https://ithelp.ithome.com.tw/upload/images/20221003/20142505G7a8xfOKKG.png

為什麼陰影呈現鋸齒狀？（陰影渲染演算法問題）

https://ithelp.ithome.com.tw/upload/images/20221003/20142505RCll9bRTXL.png

以上情況相當頻繁，如果我們只會開關陰影的話，會很難解決這些問題。

以下我從原理解釋陰影，然後帶到這些問題的解決方法。

陰影的本質
如果從未有人實作過陰影，而你就是要在發明陰影技術的人，你該怎麼找出影子呢？

如果你回顧光那篇，你可能還會記得之所以會有亮度，是因為每一個面都在計算自己的法線單位向量跟其向光的單位向量是否多接近。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505OhOoWmtI7j.png

光會投射在物體上，物體上的面都有法線
就等同於物體上有「向光向量」投向光源
向光向量跟法線向量若都轉成單位向量（長度為一單位的向量）的話
就可以計算每一個面的其兩向量的相近度。以內積計算，落在1~-1範圍內。截1~0區間作為亮度
陰影的本質：深度材質
在這個過程中，在物體上的每一個面都會跑一遍。你會想說：既然面都會找光源向量了，那就看它向光的過程中，檢查是否有遇到其他物件就好了！

https://ithelp.ithome.com.tw/upload/images/20221003/20142505pnkl6E4bR3.png

圖片中，我們的物體被熊熊擋住了，所以向量光沒有到達光源，那麼沒到達光的面，就是陰影。這樣的方式就邏輯就可以把陰影找出來。

但是，我要怎麼知道熊熊擋在途中？如果熊熊前面還有一個猴猴，那到底要先算猴猴還是先算熊熊？

這樣的順序是個很大的議題。而發明陰影技術的人很聰明，他直接在光源的位置，幫受光的範圍拍一張照片。

https://ithelp.ithome.com.tw/upload/images/20221004/20142505uCCNo3agFR.png

拍了一張照之後，就可以知道光源打到的第一層「表面」在哪些地方。以上面的圖來說，熊熊就被光源打到，熊熊背後的物體就沒有被光源打到。

光打到「表面」之後，就計算它跟表面的距離有多遠。在0~1的範圍計算數值。離光源越接近的表面其數值越小，越遠的表面其數值最大。

https://ithelp.ithome.com.tw/upload/images/20221004/20142505wLVXZ7ryxw.png

就像下圖，如果把0~1範圍變成0~255的灰階時，就可以得到一張照片。我們可以看到，最接近的方塊最黑，數值大約在0.1，最遠的天空，數值大約為1。

https://ithelp.ithome.com.tw/upload/images/20221004/201425053sSknlwddK.png
圖片來源

這張材質圖看起來像起霧一樣，只有畫面深度的差別。所以就被命名為深度材質（depth texture），每一個像素上的灰階數值，就被稱作「深度（depth）」了。這張照片將以材質圖存起來給下一步使用。

陰影的本質：深度的上下界範圍
剛剛提到，雖然最遠的是天空，數值為1，但不會是無限遠。回顧camera種類，主要有兩種：PerspectiveCamera、OrthographicCamera，都有near跟far，而這成為了0~1的上下界範圍。near為0，far為1。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505nkb8REtsfq.png

陰影的本質：計算陰影
拍了一張材質圖之後，就是shader的工作。我們再提一次：WebGL有program，program包含vertexShader以及fragmentShader，前者每一個錨點執行一次（單純的立方體就執行八次），將所需要的資料傳送給fragmentShader。fragmentShader每一個像素執行一次，將RGB資料傳送到螢幕上，一幀可能會執行兩百萬次（1920*1280的話）。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505wxU93XSytv.png

在fragmentShader每一個像素執行一次時，WebGL就一手捧著這張我們先前拍到的深度材質圖，一手檢查每一個要渲染的像素位在哪一個物體上。

我們以下圖來說好了，假設熊熊的背後有一個像素要確認自己是不是一個陰影，像素要渲染的位置在紫色的箭頭指的地方。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505wgUPqDdWoM.png

我們先暫時把材質圖放著不管，我們需要先計算該像素的「深度」。深度的計算方法，就是計算它離光源有多遠。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505OdRSaMkdnF.png

假設他離光源的距離是0.5好了。接下來我們打開另一隻手捧的深度材質，觀察該像素的位置在材質圖上的深度有多少。

前面我們提到深度材質，就是光打下來照到的第一層表面。下圖是深度材質圖示意：

https://ithelp.ithome.com.tw/upload/images/20221004/20142505Ft0V7jGIAs.png
圖片來源

以我們舉例的像素來說，就是熊熊的皮膚表面，也就是0.1。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505b8CpPktsWz.png

於是fragmentShader察覺到該像素數值是0.5，而深度材質的數值是0.1。相比之下，就知道0.5比0.1還要遠，那麼它就是陰影。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505HrEnVmdIhg.png

這就是陰影產生的原理。有了這個原理，WebGL目前為止不必去搞清楚物件的順序也可以產生陰影，渲染的效率也可以非常快速。

陰影的本質：castShadow跟receiveShadow由來
這也是為什麼，three.js會提供每一個Mesh物件兩個屬性：castShadow跟receiveShadow ，因為castShadow用來確定該物件要渲染在深度材質上。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505vJo8oY31y1.png

而receiveShadow代表所有位於物件上的像素是否要比對深度材質中的深度，確定自己為陰影之後透過陰影公式計算是否要蒙上陰影。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505Rxl7TbGeRO.png

所以，以後當有人問你問題，你就很好回答了：

拿掉熊熊但保留後面的形狀的receiveShadow，效能會不會增加？
幾乎不會，因為鏡頭還是要照一張材質圖，一手比對深度材質圖的數值，一手計算像素的深度。不會因為把熊熊關掉，就會省一個步驟。
如果receiveShadow不開，效能會不會增加？
會，雖然一手比對深度材質圖，但像素深度不用計算，所以效率會增加。
渲染問題解決方法
雖然釐清了原理，但我們還沒有破解渲染問題。

我們先切入一個問題點來帶出原理：為什麼高度差不多的Mesh會有髒髒的表面？

https://ithelp.ithome.com.tw/upload/images/20221003/20142505eD7CRmCq5f.png

那些髒髒的東西是陰影。但為什麼會有髒髒的東西呢？

我們回顧一下剛剛所說的，WebGL一手捧著深度材質圖，一手計算像素的深度。一個是材質圖，一個是像素。

身為材質圖，它是有大小的，以下面這張圖來說，它可能256x256，也可能512x512，也可能2048x2048。

https://ithelp.ithome.com.tw/upload/images/20221003/201425055iTI3ZCBiP.png

它一旦拍攝下來，投影到物件上面，往往都會比fragmentShader的解析度還要差。

深度材質圖很少比fragmentShader計算的解析度好的，因為fragmentShader是螢幕像素一顆一顆渲染，但它深度材質圖它有固定大小。下圖你就可以依稀看到該陰影身為材質圖，陰影會出現的鋸齒狀。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505Jq5jLCnavy.png

所以說：webGL一手捧的深度材質圖解析度很差，另一手計算的像素解析度好。這兩種合在一起計算，就一定會有誤差。

以下圖來說，假設一顆球照在平面上。而且陰影的材質圖奇低，只有十像素寬。這時照下來的陰影解析度就非常低。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505N7NSa6v3ZL.png

圖中有一個紅色的深度材質，如果在這個平面下包含10個像素，那麼這十個像素所用的材質深度都是同一個數值。髒髒的就是因為這個問題造成的。

Self-Shadow Aliasing問題
延伸上一個問題，它不僅出現在兩個物體上，還可能出現在同一個物體上，甚至同一個平面上。

用前一張圖，把球拿掉之後，用力放大看。假設黑白點點為像素大小，而有一個深度材質（綠色）照在平面。這時候，有些黑白點（代表螢幕上所呈現的每顆像素）位在材質圖比較前面的位置，計算深度之後比深度材質的0.5還要小，有些則比較大。這時候就會產生黑白黑白的狀況。

換句話說，一個像素的材質圖區域範圍內（綠色箭頭所指），可能有六個像素要渲染到顯示器，其中有三個像素比較深度之後，被誤認成是陰影了。

https://ithelp.ithome.com.tw/upload/images/20221003/20142505PPGRAeYmtH.png

這也解釋為什麼柱子有奇怪的鋸齒狀，地板會破圖。

https://ithelp.ithome.com.tw/upload/images/20221003/201425057V1WjWzv9T.png

https://ithelp.ithome.com.tw/upload/images/20221003/20142505CXioO2CJtZ.png

而這個現象有一個名稱，那就是Shadow Acne。

Bias修正
為了解決上述問題，出現了Bias修正功能，只要減去一點點數值，就可以修正上述問題。

// light可以是PointLightShadow、DirectionalLightShadow或SpotLightShadow
light.shadow.bias = -0.0001
下面是內縮的效果：

Untitled

它使用特別的公式，使得材質圖可以用特別的方式內縮。

https://ithelp.ithome.com.tw/upload/images/20221003/2014250502llVOWQJL.png

圖片來源

這個方法雖然可以解決問題，然而如果Bias數值給太多，會導致陰影跟物體相連的地方分離，使得畫面上看起來被裁減了一樣。而這也導致下圖陰影出現漏光的現象。

https://ithelp.ithome.com.tw/upload/images/20221004/20142505737KS9uGTN.png

由於篇幅問題，我們不討論公式推導，如果有興趣可以查看這篇文章。

延伸的陰影技術：Shadow Map, PCF, PCSS
Shadow Map
到目前為止，我們只解釋到最基本的陰影技術，人稱「Shadow Map」。

renderer.shadowMap.type = THREE.BasicShadowMap
https://ithelp.ithome.com.tw/upload/images/20221004/20142505cfmJ4QfxRg.png

事實上還有很多種陰影技術，例如PCF Shadow：

PCF Map(Percentage-Closer Filtering)
這是three.js預設的陰影渲染方式。簡單來說，就是取樣周圍的像素，得到一個平均值。藉此，陰影的邊界不會那麼模糊。

renderer.shadowMap.type = THREE.PCFShadowMap
https://ithelp.ithome.com.tw/upload/images/20221004/20142505YMJN4uMQXz.png

而這有特別的公式：

https://ithelp.ithome.com.tw/upload/images/20221016/20142505nSOQY0yaeq.png

圖片來源

因為篇幅關係，如果有興趣的人可以前往查看文章

PCF Map SoftShadow(Percentage-Closer Filtering)
基於PCF公式，所使用的更模糊版本。

renderer.shadowMap.type = THREE.PCFSoftShadowMap
https://ithelp.ithome.com.tw/upload/images/20221004/20142505yBcXXVx8zy.png

VSM(Variance Shadow Map)
基於PCF使用數學公式計算出來的另一種陰影處理。

renderer.shadowMap.type = THREE.VSMShadowMap
因為篇幅關係，如果有興趣的人可以前往查看文章

各種光源所產生的陰影差異
上面有提到，每一個光源都會拍一張照，代表深度材質圖。

事實上，重要的光源物件都會有光源陰影物件，裡面又有鏡頭專門拍照。

Light → LightShadow → Camera
而這架構存在於DirectionalLight、PointLight、SpotLight。

拍照這件事情可就複雜了。如果還記得「Day15: three.js 前端3D視覺特效開發實戰——3D儀表板：圓餅圖」那篇，你可能還記得我們還分成兩種主要的鏡頭：

https://ithelp.ithome.com.tw/upload/images/20221003/201425058OcxAZewfp.png

那到底不同的光是用什麼鏡頭呢？

DirectionalLightShadow

平行光的Shadow平行光需設定投影範圍，它是OrthographicCamera

SpotLightShadow

使用perspectiveCamera捕捉陰影

PointLightShadow

使用perspectiveCamera捕捉陰影

看上去點光跟聚光燈一樣都是用perspectiveCamera去處理。但問題是：身為一個點光，其照射的範圍是360度的。但是其內部的鏡頭如果要照射360度的深度材質，那麼解析度會相當差。

Untitled

圖片來源

為了解決這個問題，PointLightShadow使用了六個PerspectiveCamera，上下左右前後各照一張，當自己是google街景車一樣。

https://ithelp.ithome.com.tw/upload/images/20221004/20142505clisKoFQll.png

所以說，使用PointLight需要照射的材質圖，相當於可以抵上六個DirectionalLight。如果要考慮效能的話，那點光就是必須慎重使用的光源。

小結
本篇是我跌跌撞撞的開發經驗，加上參考其他文章彙整出來有關陰影的技術問題。

事實上，內容還不只這樣，我們還沒有提到渲染技術、不同的貼圖取樣方式影響材質圖以及Frustum的概念、Depth Buffer、Depth Testing等等相當多的內容。為了留接下來這幾天的篇幅給Shader，我就點到為止，如果有興趣的人可以繼續研究。

https://ithelp.ithome.com.tw/upload/images/20221005/20142505PF6Qo7Vjnc.png
圖片來源

七原罪中的梅利奧達斯有一招叫做「全反擊」，基本上可以把所有攻擊全部彈回去。招數有夠猛。而我們這次所做的特效也是相當兇猛，基本上用上，整個質感就不一樣了。不僅如此，原理還很簡單。以下就來介紹：

智慧工廠的特效應用
智慧工廠是我認為B2B當中最有趣的一部分，它需要很多領域互相合作。例如：

災害模擬、廠房氣體監測
在廠房空間中如果出現火災、有毒氣體外洩等，其二氧化碳飄逸速度為何？多久會遍布整個工廠？救援設備多久之後可以抵達？
自駕機具路徑與人工智慧
使用光學雷達偵測路徑以負責裝卸倉儲貨物的自駕機具，到添購多少台可以得到最佳效率？
檢查晶片瑕疵以確保產線良率
要多少鏡頭、用怎麼的演算法可以抓出產線中零件的瑕疵，以提高生產線良率？
廠房倉儲、設備檢視與遠端操作
如何控制遠端的廠房機具，使得新增、刪除、修改零件得以自動或人工處理？
等相當多領域的應用。

本篇我們將以設備檢視作為主軸，並以此為切入點實作反射特效。

成品
rotate.gif

設備檢視是視覺特效相當能發揮的領域。基本上有了模型，我們可以幫它加上貼圖，使得它不僅只是設備的檢視器，還能增加產品質感、用戶體驗，跟競爭對手做出很大的區隔。

準備程式碼
我已經準備好程式碼。直接在CodePen上面複製即可。

CodePen
https://ithelp.ithome.com.tw/upload/images/20221005/20142505dTK8YNXbVM.png

https://codepen.io/umas-sunavan/pen/dyeKKJw

除了three.js必備的物件以外，我還準備了、平行光、環境光、OrbitControls，以及一顆看得到內部但看不到外部的球體當作背景。都在程式碼裡面。

鏡面反射原理
為什麼鏡面會反射？
如果以現實世界來思考這件事情，這是因為光照在物體上，物體反射在鏡面上，鏡面捕捉光之後再反射回到眼中裡面。

https://ithelp.ithome.com.tw/upload/images/20221005/20142505NAhDErYtV8.png

如果有多個物件同時照在物體上，不就需要計算很多反射嗎？

https://ithelp.ithome.com.tw/upload/images/20221005/201425050VFpsTWVn6.png

但其實不然，發明鏡面反射效果的人很聰明：他讓相機放在物體裡面去捕捉周遭的畫面，來當作材質圖，貼在自己身上。

https://ithelp.ithome.com.tw/upload/images/20221005/20142505qOwArdfbfL.png

這個作法有點像是上一篇的陰影。「Day18: three.js 前端3D視覺特效開發實戰——鄉鎮市區GIS系統：陰影製作」我們提到陰影的製作方法。陰影也是把相機先放在光源的位置，然後拍一張照代表深度材質圖：

https://ithelp.ithome.com.tw/upload/images/20221005/20142505QRV6o4GQIW.png

鏡面反射原理跟陰影類似：把相機先放在光源的位置，拍一張照。但不同的是，相機是藏在物體裡面的，而不是在光裡面。而相機產生的貼圖要貼在物體上，而不是拿來計算陰影。

鏡面反射的四大步驟：
簡單來說，流程是這樣的：

準備一個照相機（CubeCamera） 跟渲染對象WebGLCubeRenderTarget
渲染對象具有材質（.texture），用來儲存拍出來的照片。
照相機藏在物體中
使用Mesh.add()函式
每幀拍一次照片，捕捉四周畫面成材質圖WebGLCubeRenderTarget.texture（但不照到所藏的物體本身）
材質圖貼在你想要的物體上形成鏡面反射
貼的方法，就是把texutre指定給物理材質的環境貼圖（Material.envMap）
https://ithelp.ithome.com.tw/upload/images/20221005/20142505crNE6bVdMJ.png

開發鏡面特效
開發鏡面特效：讀取3D模型。
// 使用閉包，以利程式碼同步
(async ()=>{
	// 模型檔案，拜託不要亂call我
	const path = 'https://storage.googleapis.com/umas_public_assets/michaelBay/day19/model/hard_disk_iron.gltf'
	// 實例化3D模型
	const gltf = await new GLTFLoader().loadAsync(path);
	// 將模型加到場景裡面
	scene.add(gltf.scene)
})()

這張圖是我在網路上找的硬碟圖片，我先將它建模成3D。

https://ithelp.ithome.com.tw/upload/images/20221005/20142505LFKNpYZyRg.jpg

圖片來源

https://ithelp.ithome.com.tw/upload/images/20221005/20142505i7McXtJec5.png

開發鏡面特效：準備一個照相機（CubeCamera） 跟渲染對象WebGLCubeRenderTarget
// 宣告照相機
let cubeCamera;
(async ()=>{
	const path = 'https://storage.googleapis.com/umas_public_assets/michaelBay/day19/model/hard_disk_iron.gltf'
	const gltf = await new GLTFLoader().loadAsync(path);
	// 用traverse巢狀遞迴子元件
	gltf.scene.traverse(object => {
		// 撇除非Mesh的物件
		if (!object.isMesh) return
		// 材質圖（嚴格來說是渲染對象）
		const cubeRenderTarget = new THREE.WebGLCubeRenderTarget(256, {
			// 渲染對象縮放設定
			generateMipmaps: true,
			// 渲染對象縮放設定
			minFilter: THREE.LinearMipmapLinearFilter,
		})
		// 實例化照相機，給定near, far，以及材質圖
		cubeCamera = new THREE.CubeCamera(0.1, 1000, cubeRenderTarget)
	})
	scene.add(gltf.scene)
})()
你可以看到有near、far。這兩個在介紹鏡頭時也介紹到，它就是鏡頭遠方跟近方的上下界。

https://ithelp.ithome.com.tw/upload/images/20221005/20142505rafZNIkaFV.png

開發鏡面特效：照相機藏在物體中
把camera裝在物體裡面即可。

(async ()=>{
	...
	gltf.scene.traverse(object => {
		...
		// 把camera裝在物體裡面即可
		object.add(cubeCamera)
	})
...
})()
每幀拍一次照片，捕捉四周畫面成材質圖
如果cubeCamera已經實例化，就每幀更新鏡頭。


function animate() {
	requestAnimationFrame(animate);
	renderer.render(scene, camera);
	// 如果cubeCamera已經實例化，就每幀更新鏡頭
+	if (cubeCamera) {
+		cubeCamera.update( renderer, scene );
+	}
}
材質圖貼在你想要的物體上形成鏡面反射
將材質圖貼在物件材質的envMap身上。何謂envMap？將在文末解釋。

(async ()=>{
	...
	gltf.scene.traverse(object => {
		...
		object.add(cubeCamera)
		// 將材質圖貼在物件材質的envMap身上
		object.material.envMap = cubeRenderTarget.texture
	})
...
})()

完成之後，就可以看到我們的模型。目看起來什麼反射都沒有。

https://ithelp.ithome.com.tw/upload/images/20221005/20142505V4Mx2hONug.png

這是因為，我們周遭只有白光。所以他只反射白光。為了解決這個問題，我們加上HDRI。

加上HDRI
HDRI我將在文末花時間解釋。簡單來說就是一個環境圖片。現在讀取材質圖，加到場景中。

    const sphereGeometry = new THREE.SphereGeometry(50, 30, 30)
    // 產生紋理
+    const texutre = await new THREE.TextureLoader().loadAsync('https://storage.googleapis.com/umas_public_assets/michaelBay/day19/model/Warehouse-with-lights.jpg')
    // 將紋理貼到材質圖中
+    const sphereMaterial = new THREE.MeshStandardMaterial({ side: THREE.BackSide, color: 0xcceeff , map: texutre})
-    const sphereMaterial = new THREE.MeshStandardMaterial({ side: THREE.BackSide, color: 0xcceeff})
    const sphere = new THREE.Mesh(sphereGeometry, sphereMaterial)
    sphere.position.set(0, 0, 0)
    scene.add(sphere);
Untitled

HDRI圖片來源

但還是沒有出現鏡面效果。為什麼？

去除光滑平面
是這樣的，理論上粗糙的平面（roughness為1的平面）並不會產生反射。反射必須是光滑的平面才行。也因此，需要再加上程式碼。這點是很多人經常忘記的步驟。


(async ()=>{
	...
	gltf.scene.traverse(object => {
		...
		// 設定粗糙度為0
		object.material.roughness = 0
		// 順手加的，非金屬反射效果比較好
		object.material.metalness = 0
	})
...
})()
		
這個步驟結束後，鏡面反射就完成了！

成果
Untitled

CodePen
https://codepen.io/umas-sunavan/pen/eYrKKKe?editors=0010

雖然作品剛剛完成，但重點是原理，以下介紹：

什麼是envMap？
CubeCamera怎麼照出360度照片的？
什麼是HDRI？
Cube是什麼意思？
envMap是什麼？
envMap就是處理反射的貼圖。

事情是這樣的：鏡頭拍了材質圖，物件要如何把材質圖渲染在自己身上呢？

我們再再再回顧WebGL的原理：WebGL內含program，program內含vertexShader以及fragmentShader，物體中有多少錨點vertexShader就會渲染幾遍。渲染完之後將重要的數值傳給fragmentShader，fragmentShader再運算每一粒像素的RGB顏色。

也就是說，材質圖在傳到fragmentShader之後，fragmentShader會想辦法計算每一粒像素應該要如何計算出鏡面反射效果的RBG顏色。

鏡面反射計算的過程我們可以不用管，它們已經做好了一套。但你需要傳入材質圖使得它們計算鏡面反射得出顏色值。

給定envMap，就是提供鏡面材質圖以利後續計算。同理，給定normalMap就是提供向量材質以利向量計算，給定roughness就是提供光滑程度計算。

envMap流程
事實上，envMap得傳入六張材質圖，分別代表上下左右前後。當六張圖片都再入完之後，就會計算出mipmap。

mipmap是一系列的不同大小的材質圖片，一旦物體接近螢幕，代表物體得渲染成比較大，就使用解析度較高的圖片。一旦物體遠離螢幕，代表物體得渲染成比較小的像素，就使用比較小的材質圖片。這使得底層能夠快速渲染畫面。

CubeCamera怎麼照出360度照片的？
回顧陰影那篇（Day18: three.js 前端3D視覺特效開發實戰——鄉鎮市區GIS系統：陰影製作），點光PointLightShadow 之所以可以四面八方照出陰影，這是因為它準備六個相機，相機前後左右上下各一面，拼接成360度全景的陰影。

https://ithelp.ithome.com.tw/upload/images/20221005/20142505irkz7drd06.png

而事實上，CubeCamera也是同樣的邏輯：它有六個相機，上下左右前後各拍一張，最後拼成材質貼圖，貼到物體上。

什麼是HDRI
全名為High Dynamic Range Image，全景為360度的圖片。只用這種圖片張作貼圖，可以貼出你所需要的環境。基本上，你只需要把它貼到3D場景中的球體，然後放大球體，就可以做出360視角檢視的能力。

但通常會出現魚眼的情況，這使得必須調整鏡頭角度。

https://ithelp.ithome.com.tw/upload/images/20221005/20142505CDhXTWYsqI.png

透過調整fov可以修正此問題。

// 第一個參數為fov，調低可以調整鏡頭焦距，使得畫面能夠減少形變
const camera = new THREE.PerspectiveCamera(10, window.innerWidth / window.innerHeight, 0.1, 10000);
Untitled

Cube是什麼意思？
基本上，Cube 一詞指的就是上下左右前後六面。六面剛好可以組成一個立方體，而立方體的英文可稱作Cube，CubeCamera因此得名。

以下物件都是同樣的邏輯：

CubeCamera：分別負責上下左右前後六面的鏡頭

這就是本文提到的。我們透過六個鏡頭，產生六張材質圖

CubeMap：分別貼出上下左右前後的UV

除了透過CubeCamera 拍攝以外，也可以預先準備好六面的材質圖。CubeMap就是指六面代表各方位的材質圖。基本上你可以將HDRI圖片轉成CubeMap再匯入到場景中。

這個網站提供HDRI轉成CubeMap的功能。

https://ithelp.ithome.com.tw/upload/images/20221005/20142505yJjT1SFd6w.png

圖片來源

CubeTexture：分別提供上下左右前後的材質圖

當我們具有CubeMap之後，可以轉成CubeTexture 材質圖，而這個流程就像我們將圖片轉成材質圖一樣。只是它需要六張圖片。

const loader = new THREE.CubeTextureLoader();
loader.setPath( 'textures/cube/pisa/' );

const textureCube = loader.load( [
	'CubeMap正軸x.png', 'CubeMap負軸x.png',
	'CubeMap正軸y.png', 'CubeMap負軸y.png',
	'CubeMap正軸z.png', 'CubeMap負軸z.png'
] );

const material = new THREE.MeshBasicMaterial( { color: 0xffffff, envMap: textureCube } );
當然，也可以透過本文所提及的CubeCamera 所產生的六面材質圖：


const cubeRenderTarget = new THREE.WebGLCubeRenderTarget(256, {...})
const cubeTexture = cubeRenderTarget.texture
const material = new THREE.MeshBasicMaterial( { color: 0xffffff, envMap: cubeTexture } );


鏡面特效能夠非常有效的讓畫面更加豐富。不僅讓物件更有真實感，也可以創造出空間感。

上一篇示範過如何做出鏡面反射。而本篇將介紹倒影特效。

上一篇提到鏡面反射的原理，就是在物理裡面藏一個照相機，不斷拍攝四周的畫面，並產生材質貼圖，貼到物體上。倒影特效更加簡單：它只需要一個鏡頭拍出材質，它甚至不用實例化鏡頭，就能直接在材質中透過Shader解決掉。

本篇將透過工廠的倒影模擬，產生更加現實、豐富的畫面。

成品
Untitled (49).gif

準備程式碼
https://ithelp.ithome.com.tw/upload/images/20221006/20142505bHedc8NizA.png

CodePen
https://codepen.io/umas-sunavan/pen/MWGBmwK?editors=0011

在範本中，我準備了球形Mesh，作為環境貼圖，並加上了基本的光、渲染器等three.js的基本初始化設定。

開發鏡面特效
開發鏡面特效：加入機櫃模型
我先製作了一個機櫃，機櫃貼圖來源為42U Rack Mount Cabinet Enclosure型號。

官方網站

https://ithelp.ithome.com.tw/upload/images/20221006/20142505MNazzFTbNw.png

將模型讀入場景內。

// device作為閉包外存取模型的變數
let device
(async () => {
	const path = 'https://storage.googleapis.com/umas_public_assets/michaelBay/day20/cabinet_mapping.gltf'
	const gltf = await new GLTFLoader().loadAsync(path);
	cabinet = gltf.scene
	cabinet.scale.set(0.5,0.5,0.5)
	scene.add(cabinet)
})()
...
function animate() {
	...
	// 幫機櫃加上旋轉
	if (cabinet) {
		cabinet.rotation.y +=0.01
	}

}
https://ithelp.ithome.com.tw/upload/images/20221006/20142505zdqHawACpq.png

加上去之後，因為機櫃顏色太深了，不適合示例。我把顏色材質貼圖拿掉。

(async () => {
	...
	// 巢狀遞迴所有子元件
	gltf.scene.traverse( object => {
		// 找尋Mesh物件（藉此捨棄掉鏡頭、光源等物件）
		if (object.isMesh) {
			// 將顏色材質圖拿掉
			object.material.map = null
			// 將法線材質圖拿掉
			object.material.normalMap = null
		}
	})
})()
https://ithelp.ithome.com.tw/upload/images/20221006/20142505ripX3Da7Di.png

看起來清晰多了。

開發鏡面特效：Reflector（鏡面物件）的資源位置
如果你在npm安裝three，或是直接用CDN抓取，都沒辦法直接抓取到Reflector。

因為Reflector 物件並不存在於three主程式中。事實上，它存在於three.js其中一個資料夾中：

如果是NPM則位在./node_modules/three/examples/jsm/objects/Reflector
如果是CDN則位在https://unpkg.com/three@latest/examples/jsm/objects/Reflector
為什麼會把元件放在examples 裡面呢？因為three.js 有很多社群擴充的元件。這些元件都會被放到examples資料夾裡面，雖然這些都不在three.js的核心中，也不會出現在官方文件說明當中，但仍十分受用，被應用在很多地方。

開發鏡面特效：加入Reflector（鏡面物件）
總而言之，將它加到專案中即可。

// 匯入module
import { Reflector } from 'https://unpkg.com/three@latest/examples/jsm/objects/Reflector';

const geometry = new THREE.PlaneGeometry(20, 20, 1, 1)
// 實例化Reflector
let mirror = new Reflector(geometry)
mirror.position.set(0,0,-20)
scene.add(mirror);
我們就可以看到鏡子了。

Untitled (50).gif

開發鏡面特效：參數設定與說明
Reflector提供很多參數給我們調整鏡面，以下說明：

// 參數物件
let options = {
	clipBias: 0.03, // 鏡射多遠的距離
	textureWidth: 1024, // 鏡射材質圖解析度
	textureHeight: 1024, // 鏡射材質圖解析度
	color: 0x889999, // 反射光的濾鏡
	recursion: 0 // 反射可以反彈幾次
};
const geometry = new THREE.PlaneGeometry(20, 20, 1, 1)
// 放到Reflector參數中。
let mirror = new Reflector(geometry, options)
// 刪除這行 -> mirror.position.set(0,0,-10)
// 調整其面向
mirror.rotation.x = Math.PI * -0.5
scene.add(mirror);
clipBias

鏡射多遠的距離，數值如果設置太高，會裁掉鏡子裡的機櫃

https://ithelp.ithome.com.tw/upload/images/20221006/20142505otbjjTomyX.png

textureWidth & textureHeight

材質圖解析度。我們從上一篇得知鏡面反射的原理是材質圖。而這裡也是。解析度越低，取樣的越粗糙。

https://ithelp.ithome.com.tw/upload/images/20221006/20142505I1bEdJ2Jxm.png

color

鏡子裡要帶有什麼顏色。你可以用這個參數來調整鏡子本身的顏色。除了調整顏色以外，也併用透明度與混合模式來達到鏡面物體的效果（如古人的銅鏡需保有顏色但又必須有鏡面效果）。

https://ithelp.ithome.com.tw/upload/images/20221006/20142505jmTUvsGSDm.png

recursion

鏡面反射鏡面時，可以反射多少次數
我特別喜歡這個效果。加上模型中的金屬材質跟粗糙材質，使得元件具有生命力。事實上，你可以看到鏡面中的反射光更加生動。

Untitled (51).gif

我們的鏡面就完成了。非常簡單。

當然，依照慣例我們還是會補充更多。

比如說好了，我們如果要把這種鏡面效果當作下圖中地板，那麼不能就像下圖那樣全部反射，這樣很假：

https://ithelp.ithome.com.tw/upload/images/20221006/20142505KWWCGjeaPC.png

進階鏡面特效
Reflector的效果非常適合運用在鏡子、反光玻璃等場景下。但如果要讓地板光滑到可以反射機房中的機櫃，那就會有問題了。因為光滑地板並不會完全反射地面上的東西。

Untitled (53).gif

如果要做到逼真的地板，那麼就至少需要「淡化」鏡面的效果。方法有兩種：

調整Reflector透明度，並再疊一個地板，使得地板可以比較「不反光」。

即使使用這個方法，鏡面仍然可以完整的反射物件，沒辦法漸淡。

疊兩個物件時，容易造成「Z Fighting」，必須再處理depth buffer問題。

https://ithelp.ithome.com.tw/upload/images/20221006/20142505k6pR7rptlj.png

圖片來源

使用MeshReflectorMaterial.js

MeshReflectorMaterial是three.js社群中的工程師開發的工具，並沒有列在官方文件，支援比較少。但如果你看完我接著即將撰寫的Shader系列文章，那麼其實你也改得了他做的元件，也不一定全都需要依賴社群。
它的生平很迴異。現在有一個基於three.js的函式庫叫做react-three-fiber，它用貼近react的寫法撰寫three.js，而社群上是有人基於react-three-fiber開發MeshReflectorMaterial，事後才有人開發純javascript版本（本次示例）。這也是為什麼它叫做MeshReflectorMaterial，因為這個是react-three-fiber擴充套件中的命名慣例。
由於第一點比較簡單粗暴好理解，我們就先跳過它來示例比較少見但好用的MeshReflectorMaterial

目前目前使用Reflector的效果：

Untitled (53).gif

這是接下來使用MeshReflectorMaterial的效果：

Untitled

進階鏡面特效：準備程式碼
需要準備三項東西：

CodePen工廠場景程式碼

MeshReflectorMaterial.js 腳本

安裝套件postprocessing

CodePen

https://ithelp.ithome.com.tw/upload/images/20221006/20142505mW2tnsQ0x9.png

https://codepen.io/umas-sunavan/pen/VwxBxKm?editors=1011

MeshReflectorMaterial.js 腳本

除此之外，還要準備一份人家寫好的類別，其連結如下：

https://gist.github.com/0beqz/e69378b278e5c336afe0c7ae9b4ed86c

https://ithelp.ithome.com.tw/upload/images/20221006/20142505iI34hoKUwP.png

安裝postprocessing

安裝套件即可。

npm i postprocessing
進階鏡面特效：淡化鏡面介紹
淡化鏡面的原理，就是加上一層漸層。這個漸層中，比較靠鏡面的畫面比較不透明，而比較遠離鏡面的畫面比較透明。

透過這個方式，就可以呈現淡化的鏡面效果。

這個技術的問題在於，當用戶放大畫面時，會看到漸層範圍比較小了。當用戶縮小畫面時，會看到漸層範圍比較大。

進階鏡面特效：安裝流程
重新確認一次，除了需要CodePen的程式碼以外，還需要MeshReflectorMaterial.js 腳本並安裝套件npm i postprocessing。

進階鏡面特效：修改機櫃數量
程式碼中，我已經新增了工廠的廠房模型room 、四跟柱子column1~4 、很多個機櫃Cabinet （以row跟column來排列）。

我這邊就不詳細解釋這物件實例化部份的實作，有興趣可以查看程式碼，我這邊就聚焦在漸淡倒影的實作。

進階鏡面特效：設定參數
這個最花時間，這個不得不說明。我這邊挑幾個重要的說明：

最重要的是minDepthThreshold以及maxDepthThreshold 。

簡單來說，maxDepthThreshold代表從多遠的地方開始淡出，而minDepthThreshold代表到多遠的地方會淡出到沒畫面。

想像有一個透明漸層，100%是不透明，0%是透明。在鏡子裡面，距離鏡子最接近物件其鏡中反射應該是100%不透明，距離鏡子最遠的物件其鏡中反射應該是0%最透明。

又假設如果鏡子最遠是0，最近是1，那麼，minDepthThreshold就代表鏡中反射最遠方的透明處，到底在0~1區間範圍的哪裡。

（附圖）

至於maxDepthThreshold 則控制最不透明處，從哪裡開始透明。其數值不限於0~1。

blur 鏡面是否需要高斯模糊，若是則高斯模糊的材質解析度為何。（[0,0]代表沒有高斯模糊）

resolution 由於反射的原理是透過材質圖，貼在物件上面。因此需要設定材質圖的解析度。解析度越高效能越差。

reflectorOffset 鏡面跟物體中間是否要留一段距離才開始反射。

// 添加到程式碼
let fadingReflectorOptions = {
	mixBlur: 2,
	mixStrength: 1.5,
	resolution: 2048, // 材質圖的解析度
	blur: [0, 0], // 高斯模糊的材質解析度為何
	minDepthThreshold: 0.7,// 從多遠的地方開始淡出
	maxDepthThreshold: 2, // 到多遠的地方會淡出到沒畫面
	depthScale: 2,
	depthToBlurRatioBias: 2,
	mirror: 0,
	distortion: 2,
	mixContrast: 2,
	reflectorOffset: 0, // 鏡面跟物理中間是否要留一段距離才開始反射
	bufferSamples: 8,
}
進階鏡面特效：加上淡化鏡面作為地面
就如同其他物件一樣，透過傳入形狀geometry跟材質material來建立Mesh物件。

不同的地方在於：Mesh的材質被置換掉了。

// 腳本可以參考：[https://gist.github.com/0beqz/e69378b278e5c336afe0c7ae9b4ed86c](https://gist.github.com/0beqz/e69378b278e5c336afe0c7ae9b4ed86c)
import MeshReflectorMaterial from './MeshReflectorMaterial.js';
// 透過geometry以及material來建立Mesh物件
const geometry = new THREE.PlaneGeometry(60, 60, 1, 1)
const material = new THREE.MeshBasicMaterial()
const mesh = new THREE.Mesh(geo, mat)
// 將材質至換成MeshReflectorMaterial
mesh.material = new MeshReflectorMaterial(renderer, camera, scene, mesh, fadingReflectorOptions);
scene.add(mesh);
// 旋轉mesh角度以作為地面
mesh.rotateX(Math.PI * -0.5)
要注意的是，必須先實例化一個材質，再置換成MeshReflectorMaterial。MeshReflectorMaterial它需要傳入mesh參數，如果沒有夠過一個材質來實例化物件，那就沒辦法順利傳入參數。

進階鏡面特效：每幀更新鏡面材質圖
由於鏡面是透過材質圖形成的，所以每幀必須不斷更新材質圖。

function animate() {
	requestAnimationFrame(animate);
	renderer.render(scene, camera);
// 每幀更新鏡面材質圖
	fadingGround.material.update()
}
做完之後，就可以看到鏡面的地面出來了。

Untitled (54).gif

進階鏡面特效：加上淡化鏡面作為牆壁
有了地面還不夠，我們可以加上牆壁。首先我們將前面新增地面的程式碼包成函式。

const addFadingMirror = () => {
	const geo = new THREE.PlaneGeometry(60, 60, 1, 1)
	const mat = new THREE.MeshBasicMaterial()
	const mesh = new THREE.Mesh(geo, mat)
	mesh.material = new MeshReflectorMaterial(renderer, camera, scene, mesh, fadingReflectorOptions);
	scene.add(mesh);
	return mesh;
}
const fadingGround = addFadingMirror()
fadingGround.rotateX(Math.PI * -0.5)
接著，製作前後左右的牆壁。

const fadingWallZN = addFadingMirror()
fadingWallZN.translateX(0)
fadingWallZN.translateZ(-29)

const fadingWallZP = addFadingMirror()
fadingWallZP.translateZ(29)
fadingWallZP.rotateY(Math.PI)

const fadingWallXN = addFadingMirror()
fadingWallXN.rotateY(Math.PI * 0.5)
fadingWallXN.translateZ(-29)

const fadingWallXP = addFadingMirror()
fadingWallXP.translateX(29)
fadingWallXP.rotateY(Math.PI * -0.5)

function animate() {
	...
	fadingWallZN.material.update()
	fadingWallZP.material.update()
	fadingWallXN.material.update()
	fadingWallXP.material.update()

}
這能夠創造出比較科幻的效果。

成品
Untitled (55).gif

小結
多虧three.js社群，才可以有這樣的reflector工具源源不絕的產出。事實上，我們是有辦法自作自己的鏡面特效了。過去的幾篇文章裡，我們不僅帶到向量計算、光的原理、陰影原理，這些都是製作特效的重要概念。

最後的九天我將會介紹WebGL的Shader，到時候我們可以釐清WebGL Shader的世界觀。到時候要製作自己的特效將輕而易舉。

參考資料
鏡面特效示例

機櫃素材

機櫃素材圖片來源

機櫃素材圖片來源

淡出特效鏡面討論

淡出鏡面特效社群討論

淡出鏡面特效原型鍊實作

淡出鏡面特效開發筆記


鏡頭追蹤與飄移基本上綜合前面好幾篇多種原理組成。

鏡頭是網頁特效中重要的戰場。網頁由於CRUD的操作很多，所以很重視操作體驗。而鏡頭的視角又能綜合滑鼠做出多種效果。本篇以「追蹤」以及「飄移」作主軸示例，並且以智慧工廠AGV作為主題進行開發。

什麼是AGV？
自動導引車(Automated guided vehicle)是智慧工廠常見領域。是這樣的：機器人如果能更有效率的在工廠執行任務（裝卸、災害應變、運送），將能增加工廠的效率。

目前已經有無人車的實際應用，其能夠判斷車輛四周環境判斷路徑與速度。而工廠的AGV也能夠透過光學雷達、內建的地圖來移動。不管路徑中有什麼障礙物，自動駕駛車仍能夠找到最佳路徑移動。

而在經過數位巒生之後，我們能夠透過網頁的儀表板觀察或模擬機具的狀況。而這樣的模擬，就需要前端網頁視覺特效的開發。而我們將專注在鏡頭開發中。

本篇使用網路資源引用機具模型，並且實作固定路線。這並不是AGV實際的模樣，但卻是很好的視覺化範本，同時也能提供給大家使用作為網頁作品。

本篇內容
準備程式碼
鏡頭追蹤
偵測鏡頭是否要追蹤物件
維持鏡頭最佳方向
透過Lerp提升滑鼠體驗
鏡頭看向車輛
鏡頭飄移
反投影原理
偵測滑鼠位置，「反投影」到世界空間
修改鏡頭目標位置（Camera.Target）
完成品
鏡頭追蹤

Untitled

滑鼠飄移

Untitled

準備程式碼
同樣是上個範例，不過我這次放大了工廠的場景。

直接複製程式碼即可使用。

CodePen
https://ithelp.ithome.com.tw/upload/images/20221007/20142505ykrnwhM1kh.png

https://codepen.io/umas-sunavan/pen/KKRxaKN?editors=0010

鏡頭追蹤
AGV完成之後，我們可以幫鏡頭加上追蹤效果。這使我們在檢查AGV移動狀態時能夠讓鏡頭保持聚焦。

偵測鏡頭是否要追蹤物件
邏輯是這樣的：

首先，每幀偵測鏡頭是否距離車輛過遠。

如果過遠，那找出鏡頭與車輛相減後的向量，也就是下圖中的黃色。

https://ithelp.ithome.com.tw/upload/images/20221007/20142505X8yh39lCMS.png

每次車輛移動時，都能夠加上該向量，就可以更新鏡頭位置。

https://ithelp.ithome.com.tw/upload/images/20221007/20142505yMKt0IbL5Q.png

以下為程式碼：

const cameraFollowAvg = () => {
	// 先判斷鏡頭跟AVG車輛是否過遠
	const length = agv.position.distanceTo(camera.position)
	if (length > 20) {
		// 接續接下來的程式碼...
	}
}
...
function animate() {
	...
	if (agv) {
		// 在animate中每幀執行一次
		cameraFollowAvg()
	}

}
如果距離過遠，我們就取得攝影機跟車輛的距離。

這距離就成為接下來機具跟攝影機的距離。我們透過該距離找到鏡頭的新位置。

程式碼可以這樣寫：

// 取得鏡頭到AVG車輛的距離
const distance = new THREE.Vector3(0,0,0).subVectors(camera.position, agv.position)
// 將其距離轉成單位向量，使得我們能取得方向
distance.normalize()
// 取得方向之後再乘以固定數值。這麼一來就可以取得固定距離。
distance.multiplyScalar(20)
// 固定距離加在車輛上，就等於鏡頭的距離
distance.add(agv.position)
// 更新鏡頭位置
camera.position.set(...distance.toArray())
// 接續接下來的程式碼...
Untitled

維持鏡頭最佳方向
你可能會察覺：為什麼鏡頭都會往車輛的屁股移動？

這是因為，我們的鏡頭就像「快艇衝浪」一樣，被快艇的繩子牽著走。這使得鏡頭永遠都在物體正後方。

https://ithelp.ithome.com.tw/upload/images/20221007/201425051QIhauJXQl.png

透過Lerp提升滑鼠體驗
為了避免這個狀況，我們可以平移鏡頭位置，並且固定鏡頭高度，如下：

// 固定鏡頭高度
distance.setY(15)
// 平移鏡頭位置，鏡頭永遠比車輛落差固定水平距離
distance.add(new THREE.Vector3(1,0,2))
// 用比較圓滑的方式位移
camera.position.lerp(distance, 0.1)
// 刪除這行 -> camera.position.set(...distance.toArray())
lerp()是什麼？我們在第七天「Day7: three.js的一方通行：矢量操作——全面釐清向量與底層特性」有提供解釋。

如此一來，鏡頭就不會貼在車輛的正後方，同時還能維持一定高度。

Untitled

鏡頭看向車輛
const cameraLookAtAgv = () => {
	// 設定鏡頭看向機具位置
	control.target.set(...agv.position.toArray())
	// 更新鏡頭控制
	control.update()
}

function animate() {
	...
	if (agv) {
		...
		cameraLookAtAgv()
	}

}
control.target為什麼能夠使鏡頭看向機具位置？為什麼要透過update更新鏡頭？我在第六天「Day6: three.js 圓弧的藝術家！弧線的教授！——軌道控制器」有提及，有興趣可以回顧。

Untitled

鏡頭飄移
反投影原理
反投影是什麼？

反投影unproject 是一個可以將NDC(Normalized Device Coordinate)轉換成three.js世界座標的函式。也就是說，它是用戶裝置螢幕上的位置，通常是滑鼠位置。而且長度為1，且原點在螢幕中心。

上圖中，上下界都是1，中心點在螢幕正中央。所以粉紅色的位置，就是中間正上方，座標為(0,1)。事實上，在Shader也是使用這個方法描述位置的。

無論你的螢幕是1920x1080，還是1024x768，NDC的(0,0)位置永遠代表螢幕正中央那顆像素，(0,1)永遠代表螢幕正中央上方的像素。

https://ithelp.ithome.com.tw/upload/images/20221007/20142505IuVIGdXbHC.png

總之，只要把滑鼠位置用上述的NDC座標系統來描述位置，那three.js就可以把這個位置轉換成場景世界座標的位置。

const x //滑鼠x位置，範圍為-1~1，中心點為螢幕中央
const y //滑鼠y位置，範圍為-1~1，中心點為螢幕中央
const z //深度，-1為camera的near切面，1為far切面
const dnc = THREE.Vector3(x,y,z)
const worldPosition = dnc.unproject(camera)
// 變數dnc已經轉換成世界座標了
// 同時將回傳dnc自己給worldPosition
Z值的深度是什麼？

Z值描述它與鏡頭的遠近。如果設-1，那就會落在鏡頭的near平面，如果設1，就會落在鏡頭的far平面。

https://ithelp.ithome.com.tw/upload/images/20221007/20142505PNGeKS5ARA.png

https://ithelp.ithome.com.tw/upload/images/20221007/20142505NpZ2Qv8cj7.png

如果x與y設置為(0,1)，也就是下圖中粉紅色位置。

https://ithelp.ithome.com.tw/upload/images/20221007/20142505zS3XOWd1uY.png

而若z設為-1，那麼投影出來的的位置，會在下圖中綠色的點上。

https://ithelp.ithome.com.tw/upload/images/20221007/20142505OKqsbNVRcu.png

相反的，如果我們把Z設定成1，那就會投影在藍色的點上。

偵測滑鼠位置，「反投影」到世界空間
將滑鼠位置轉成NDC

首先，我們透過mousemove 事件抓取到滑鼠位置，以及Canvas畫面大小。

// 宣告一個變數，儲存NDC資料
const mouseOnNdc = new THREE.Vector3(0,0,-1)
// renderer.domElement乃我們的canvas的DOM
renderer.domElement.addEventListener( 'mousemove' ,event => {
	// 滑鼠X位置
	const mouseX = event.offsetX
	// 螢幕寬度
	const w = renderer.domElement.width
	// 滑鼠Y位置
	const mouseY = event.offsetY
	// 螢幕高度
	const h = renderer.domElement.height
	// 給定X與Y，Z留0就好
	mouseOnNdc.setX(mouseX/w-0.5)
	mouseOnNdc.setY(-mouseY/h+0.5)
})
上面的程式碼中，我們留了mouseOnNdc 變數，使得每幀執行時，可以取得mouseOnNdc 位置

將NDC轉成世界座標

準備好一個三維向量Vector3，其中X為NDC的X位置，Y為NDC的Y位置，Z則是你要投影到的「深度」。

// 宣告一個變數儲存世界座標
let mouseOnWorld = new THREE.Vector3(0,0,-1)
const updateMouseAffectTarget = () => {
	// 為了避免可變物件(mutable)影響，使用clone()來使mouseOnNdc數值不會被更動
	// clone的結果同時也會回傳給mouseOnFrustumTop
	mouseOnWorld = mouseOnNdc.clone().unproject(camera)
}

function animate() {
	...
	if (agv) {
		...
		updateMouseAffectTarget()
	}

}

如果滑鼠位置的NDC為(0,1)，則反投影後會在橘色位置。只要能取得橘色到藍色（即鏡頭位置）的距離向量，就能用來偏移鏡頭的目標（Camera.target）。

https://ithelp.ithome.com.tw/upload/images/20221007/20142505BT9U2sWIz9.png

const updateMouseAffectTarget = () => {
	mouseOnWorld = mouseOnDnc.clone().unproject(camera)
	// 滑鼠在世界座標的位置跟鏡頭位置相減，得到的落差，就能製作偏移
	const mouseOnWorldToCamera = new THREE.Vector3().subVectors(
		mouseOnWorld, 
		camera.position)
		.normalize();
}
修改鏡頭目標位置
將偏移加到camera.target

const updateMouseAffectTarget = () => {
	mouseOnWorld = mouseOnDnc.clone().unproject(camera)
	const mouseOnWorldToCamera = new THREE.Vector3().subVectors(
		mouseOnWorld, 
		camera.position)
		.normalize();
	// 鏡頭目標的新位置即是車輛位置加上偏移
	control.target.addVectors(mouseOnWorldToCamera.multiplyScalar(10), agv.position)
	control.update()
}
完成之後，我們的滑鼠的位移將可以偏移鏡頭目標

Untitled

偏移得太快速了，我們可以再透過lerp使他更圓滑。

為了使得位移更加圓滑，我加了兩個參數：

idealTarget ：為理想中移動的目標
lerpingTarget：朝向idealTarget移動
取得idealTarget 位置之後，即更新到control.target上

https://ithelp.ithome.com.tw/upload/images/20221007/201425053XE7dy3K9G.png

// 理想要的鏡頭目標
let idealTarget = new THREE.Vector3(0,0,0)
// 漸變Lerp途中的鏡頭目標
let lerpingTarget = new THREE.Vector3(0,0,0)

const updateMouseAffectTarget = () => {
-   control.target.addVectors(mouseOnWorldToCamera.multiplyScalar(10), agv.position)
-   control.update()

+   idealTarget.addVectors(mouseOnWorldToCamera.multiplyScalar(10), agv.position)
+   lerpingTarget.lerp(idealTarget,0.1)
+   control.target.set(...lerpingTarget.toArray())
+    control.update()
}
這樣一來，鏡頭飄移跟追蹤就完成了。

完成品
https://ithelp.ithome.com.tw/upload/images/20221007/20142505lQ33eZuV03.png

Untitled

CodePen
https://codepen.io/umas-sunavan/pen/ZEoMMbq?editors=0010

小結
在開發智慧工廠的各種元件時，最常遇到檢視的功能。畫面檢視的功能體驗如果很好，不僅在簡報、作品品質上都會有很大的加分。

本篇使用過去所提到的各種原理實作，希望能夠幫助大家處理各種鏡頭特效。

接下來將介紹WebGL的開發，敬請期待。

參考資料
機具模型檔案

unproject z值討論

unproject解釋

Shader是什麼
我們所稱呼的Shader，其實是Fragment Shader以及Vertex Shader的合稱。這兩個出現在Program上，使得我們最終可以計算「每一顆」像素應該呈現的顏色。

https://ithelp.ithome.com.tw/upload/images/20221014/20142505dleYwK97vb.png

我們在three.js製作的光、陰影、物件顏色、材質，都是基於three.js架構所建立的物件。這些物件在認清了彼此之間的關係，最後用Shader來渲染畫面，所以Shader一直都在three.js底層。這是什麼意思呢？

我們再用「Day8: Three.js 你有被光速踢過嗎？解析3D界的黃猿——光的底層原理與介紹」來舉例說明。假設我們在three.js建立了光，然後建立了球體。那麼該如何在我們的顯示器上呈現亮度呢？

https://ithelp.ithome.com.tw/upload/images/20221014/20142505EeSWtAz8ey.png

Vertex Shader跟 Fragment Shader 身為底層，在這個場景下，就必須經由three.js傳入的參數（光的位置、亮度，以及球體的錨點等等）資料，進行計算，計算出每一顆像素的顏色。

所以說，three.js始終在運用shader做計算。當然我們也可以跳過three.js，直接撰寫計算邏輯。而這就是我們寫shader的時候了。

Shader是什麼：Vertex Shader跟 Fragment Shader
Vertex Shader每一幀每一個錨點都會執行一遍。如果是一個純粹的立方體，那就有八個錨點，那就會執行八次。執行要來做什麼呢？要負責將錨點投影到螢幕座標中，並且提供Fragment Shader錨點資料，以利錨點計算。也因此它被稱作Vertex（頂點）Shader。

Fragment Shader每一幀每一個像素會跑一次。如果你的電腦解析度是1920x1280，那每一幀Shader就會執行兩百多萬次。如果一秒螢幕跑60幀，那就是大約近一億五千萬次，這是非常大量的計算。當你看完這段文字之後，你的螢幕就已經跑了十五億次了。

https://ithelp.ithome.com.tw/upload/images/20221014/20142505gxiFdaEDnK.png

Fragment Shader執行要來做什麼呢。它計算出每一個像素的R,G,B,A數值，顯示在螢幕上。就是這麼底層。這也因次它被稱作Fragment（碎片，指像素） Shader。

上面這兩個Shader搭配可以組成一個Program，而這就是WebGL的運作模式。

前面二十幾天鐵人賽篇幅的Three.js，最終會把我們所撰寫的javascript，餵入到WebGL中，最終透過shader渲染出來。

Shader是什麼：Shader特性
雖然Fragment Shader要短時間內運算多次，但幸好這些都發生在GPU上。GPU平行運算並且得到像素RGB數值，使得這些計算非常快速。這也意味著：當我們執行Shader時，程式碼就已經在GPU上面運行了。

由於Shader特性，每一顆像素沒辦法存取隔壁像素的數值，它們都是「孤單」的，而且在每一幀運算之後，是不會存下任何變數的。

Shader是什麼：Shader跟three.js的關係
three.js是已經包好用來運算WebGL的js函式庫，Shader是相對來說低階的程式語言GLSL寫成（需要編譯），但基本上都是在渲染畫面。

除了three.js以外，還有P5.js, WebGL API, babylon.js可以傳值到shader實作，但基本上就只有傳值不一樣而已。

Shader要如何開發
Shader使用GLSL（GL Shader Language）撰寫，是很像C系列語言的語言。該語言的介紹我先挪到下篇，我們先在本篇從three.js加入客製化Shader。

Shader要如何開發：準備程式碼
我準備了CodePen，裡面有最基本的three.js場景，這些過去都有介紹到。由於我們聚焦在Shader開發，所以提供程式碼給大家開始。

Shader要如何開發：CodePen
https://ithelp.ithome.com.tw/upload/images/20221014/20142505B1LHYeKaNz.png

https://codepen.io/umas-sunavan/pen/XWqPOPM?editors=1010

先帶一下CodePen裡面的東西。我在場景中製作了一顆球，雖然過去有介紹如何建立Mesh物件，但我這邊簡單介紹一下：

const addSphere = () => {
		// 實例化球的形狀
    const geo = new THREE.SphereGeometry(5,50,50)
		// 實例化材質物件
    const mat = new THREE.MeshBasicMaterial({color: 0xffff00})
		// Mesh得透過上面兩個組成
    const mesh = new THREE.Mesh(geo, mat)
		// 將球加入到場景
    scene.add(mesh)
}

addSphere()

有關three.js的解釋，可以參考「Day2: ThreeJS、OpenGL、WebGL：誰是誰？我要怎麼開始？」

Shader要如何開發：修改材質
基本上，我們可以透過材質來建立Shader。這跟P5.js以及WebGL API不太相同，我將在後續補充。總之，可以先將MeshBasicMaterial改成ShaderMaterial。

const addSphere = () => {
		// 實例化球的形狀
    const geo = new THREE.SphereGeometry(5,50,50)
		// 實例化材質物件
-    const mat = new THREE.MeshBasicMaterial({color: 0xffff00})
+		 const vertex = ''
+		 const fragment = ''
+    const mat = new THREE.ShaderMaterial({
+			vertexShader: vertex,
+			fragmentShader: fragment,
		})
		// Mesh得透過上面兩個組成
    const mesh = new THREE.Mesh(geo, mat)
		// 將球加入到場景
    scene.add(mesh)
}

目前vertex跟fragment是空的。這兩個要傳入字串，以利WebGL編譯program。

但GLSL需要合法的進入點main() ，並且有規定的變數值需要賦予。我們接著實作：

Shader要如何開發：新增GLSL
我們要撰寫字串並傳入到ShaderMaterial，這有很多種方式。有些人另開json檔案儲存，有些直接宣告在字串上，而我用的方法是：寫在HTML，再用innerHTML取字串。

+       <-- HTML -->
<main>
+       <div style="display: none">
+       <-- 這裡撰寫fragmentShader -->
+           <p id="fragmentShader">
+               varying vec3 vertexNormal;
+               void main(void){
+                 gl_FragColor=vec4(0.3, 0.6, 1., 1.);
+               }
+           </p>
+       <-- 這裡撰寫vertexShader -->
+           <p id="vertexShader">
+               varying vec3 vertexNormal;
+               void main(void){
+                 vertexNormal = normal;
+                 gl_Position=projectionMatrix*modelViewMatrix*vec4(position, 1.0);
+               }
+           </p>
+       </div>
</main>
再單向綁定到變數裡：

// index.js
const addSphere = () => {
			// 實例化球的形狀
	    const geo = new THREE.SphereGeometry(5,50,50)
			// 實例化材質物件
-			const vertex = ''
-			const fragment = ''
+			const vertex = document.getElementById('vertexShader').innerHTML
+			const fragment = document.getElementById('fragmentShader').innerHTML
	    const mat = new THREE.ShaderMaterial({
			vertexShader: vertex,
			fragmentShader: fragment,
		})
		// Mesh得透過上面兩個組成
    const mesh = new THREE.Mesh(geo, mat)
		// 將球加入到場景
    scene.add(mesh)
}

接著，我們自製Shader就產生了。

完成品
圖中可以看到，原本黃色的球，透過Shader處理後變成藍色。

https://ithelp.ithome.com.tw/upload/images/20221014/20142505e45bTX70Mw.png

CodePen
https://codepen.io/umas-sunavan/pen/GRdXemK?editors=1010

小結
本篇我們先確保我們進入Shader的世界。下一篇將嘗試透過Shader製作出一個球。

參考資料
texture2D的說明

webglfundamentals的說明

BookOfShader說明


上一篇，我們用最快的方式，透過shader製作了球體。基本上這個球體就跟MeshBasicMaterial({color: 0x4c99ff})一樣，其球體範圍內的像素全是藍色。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505K52Horc4jD.png

本篇將介紹Shader的概念。我們將透過快速修改Shader，先做出一個成果，然後解釋其原理。

我將介紹以下內容：

Shader是什麼？
Shader是怎麼運作的呢？
Three.js之於Shader
要寫shader，就必須理解它所用的程式語言：GLSL
這到底是什麼原理？從認識GLSL開始
GLSL必須知道的變數與函式
Shader是什麼？
Shader是怎麼運作的呢？
基本上是這樣的：three.js的程式碼事實上也是在shader運行，shader是各式各樣3D渲染函式庫（使用WebGLRenderer的函式庫）的底層，它渲染所有像素。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505PqyVuNnIkO.png

所以說：當你在使用three.js、P5.js、babylon.js或WebGL API時，你就正在用Shader，只是它在底層。

Three.js之於Shader
如果你還有印象的話，你應該會記得在「Day8: Three.js 你有被光速踢過嗎？解析3D界的黃猿——光的底層原理與介紹」討論到：three.js有光、有球體等物件。光照射到球體，出現亮面跟暗面。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505iF7msjZ6ou.png

為什麼可以產生亮面跟暗面？這是因為，three.js也正在用shader，每當它執行一個像素，就會計算該像素其光的強度。

光的強度 = 法線的單位向量．向光的單位向量
        = |法線|*|向光|*cos(θ)
一旦像素計算結果趨近1，則該像素最亮，這是因為亮面的向光向量跟像素所處的球面法線向量相近；相反的，當像素計算結果趨近0，代表兩向量角度接近直角。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505E8p4zrHLqQ.png

也就是說，three.js之所以可以幫每一個像素創造亮面跟暗面，那是因為它能夠在shader運算上述的邏輯。都是shader的功勞。

要寫shader，就必須理解它所用的程式語言：GLSL
我們看完了three.js的底層是用shader創造而成，那我們其實也可以實作光源。我們將在下一篇創造環境光，但在這之前，我們必須讀懂shader所使用的程式語言GLSL。

寫Shader從認識GLSL開始
寫Shader從認識GLSL開始：專門為GPU設計的程式語言
GLSL其實跟C語言很相近，如果你過去熟悉C語言，那你應該很快就能上手。然而如果沒有接觸C語言就來涉獵Shader的話，你可能會需要知道如何理解GLSL，本篇介紹GLSL中所需理解的先備知識。

GLSL其實跟C語言很相近，但如果沒有接觸過C語言就跑來前端的話，那可能需要惡補一下，以下介紹GLSL：

寫Shader從認識GLSL開始：變數宣告
GLSL的變數相當多種，舉凡int, float, bool, vec2, vec3, vec4等，一一介紹：

int, float, bool：

前三個你應該可以猜的出來，就是整數、浮點數、布林值

 // 請務必加上分號
int color = 1;
float brighness = 0.0;
bool isWhite = true;

vec2, vec3, vec4：

它們即是Vector的縮寫，它可以一個數組，可以是二維、三維、四維，依照你的需求而定。

vec2 position = vec2(1.0, -1.0);
vec3 color = vec3(1.0, 0.0, 0.5);
vec4 colorWithAlpha = vec4(1.0, 0.0, 0.5, 0.5);

vec2可以裝兩個數值，vec3可以裝三個數值，以此類推

如果想像成物件存取這些可能比較好理解。

// 類似js的
const color = {r: 0, g:0, b:0}

跟js的差別在於：

GLSL對型別是嚴格的，浮點數跟整數不得輕易轉換，但javascript可互通。
GLSL的key並不是r,g,b三種取值，詳情請繼續往下看。
數組的型別不限制僅為浮點數，整數、布林值都可以。但強烈建議都用浮點數。

vec3 redColor = vec3(1, 0, 0); // 給定整數合法，將得出 vec3(1.0,0.0,0.0)
vec3 yellowColor = vec3(1, true, false); // 給定布林合法，將得出 vec3(1.0,1.0,0.0)
vec3 whiteColor = vec3(1, true, 1.0); // 多重型別合法，將得出 vec3(1.0,1.0,1.0)

存取數組中的值，有多種別名。存取時，我們可以分別用r,g,b來依序取得數值，也可以x,y,z依序取得數值。

vec4 redColor = vec4(0.8, 0.3, 0.2, 1.0);
// 以下都能取得數組第一個值
float red = redColor.r // 0.8
float x = redColor.x // 0.8

// 以下都能取得數組第二個值
float red = redColor.g // 0.3
float x = redColor.y // 0.3

// 以下都能取得數組第一個值
float red = redColor.b // 0.2
float x = redColor.z // 0.2

// 以下都能取得數組第一個值
float red = redColor.a // 1.0
float x = redColor.w // 1.0

取得多重數值的方式。GLSL中，可以取出多個數值，其解構的方式十分便利。

vec3 redColor = vec3(0.8, 0.3, 0.2);
// 可以指定成
vec4 noColor = vec3(redColor ,1.0) // 等於vec3(0.8, 0.3, 0.2. 1.0);
// 也可寫作
vec4 noColor = vec3(redColor.xyz ,1.0) // 等於vec3(0.8, 0.3, 0.2. 1.0);
// 可以抽特定的數值
vec4 noColor = vec3(redColor.xy ,0.7 ,1.0) // 等於vec3(0.8, 0.3, 0.7. 1.0);
// 抽取順序可以調整
vec4 noColor = vec3(redColor.yz ,0.7 ,1.0) // 等於vec3(0.3, 0.8, 0.7. 1.0);

寫Shader從認識GLSL開始：函式宣告
函式跟JS的函式很像，但還是有差異，估計你可以直接透過用看的就能看出兩者差異：

// 回傳型別、函式名稱、參數
vec3 rgb(float r, float g, float b){
  return vec3(r / 255.0, g / 255.0, b / 255.0);
}

寫Shader從認識GLSL開始：程式進入點
我們有兩個Shader，vertextShader每個錨點執行一次，fragmentShader每一個像素執行一次。

凡是執行，就得有程式進入點。因為這不是逐行執行的腳本語言，這是程式語言，要編譯的那種。

而這也是為什麼，我們的fragmentShader跟vertextShader有main()，因為它就是程式開始執行的地方。

// vertex shader
void main(void){
	gl_Position=projectionMatrix*modelViewMatrix*vec4(position, 1.0);
}

// fragment shader
void main(void){
  gl_FragColor=vec4(0.0, 0.0, 0.0, 1.);
}

寫Shader從認識GLSL開始：程式目標
Shader有它的任務。vertex shader需要取得渲染範圍，而fragment shader需要每顆像素的顏色。

對vertex shader來說，只要得到gl_Position數值（錨點最終在螢幕上的位置），就算完成任務。對fragment shader來說，只要得到gl_FragColor（像素的顏色），就算完成任務。任務結束之後，剩下的邏輯都沒有必要了。

以vertex shader來說：

// vertex shader
// gl_Position代表螢幕像素的位置
gl_Position=projectionMatrix*modelViewMatrix*vec4(position, 1.0);

gl_Position到底是什麼意義？

由於vertext shader每一個錨點執行一次，所以它可以取得球體的所有頂點，這也使得它能找出球體的形狀，在我們的電腦螢幕中，裁剪出一個範圍。

而這個範圍，使得fragment shader在運算每一個像素的顏色時，能夠得知有哪些像素需要運算，哪些不用運算。

以我們的例子來說，球體錨點中的範圍需要運算，球體以外的不需要運算。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505NKcWgKnpkw.png

projectionMatrix、modelViewMatrix 是什麼意思？

主要是負責將錨點從世界空間中，基於鏡頭的位置，投影到螢幕這平面的座標中。這個之後可以介紹。

以fragment shader來說：

// fragment shader
// gl_FragColor代表每一個像素的顏色
gl_FragColor=vec4(0.0, 0.0, 0.0, 1.0); // 黑色

gl_FragColor就是每一個像素的顏色。

如果有100個像素，不就要設定100個gl_FragColor嗎？這倒不用。設定1個就可以了，因為fragment shader每一顆像素都會各自執行fragment shader，每一顆像素都只要有一組RGBA顏色，所以一個gl_FragColor就可以了。

小結
我們快速修改Shader，並且介紹GLSL。然而還沒完呢！下一篇將繼續介紹GLSL，同時提供小東西實作。

前一篇我們初步修改Shader，並且介紹GLSL的型別、函式、程式進入點、程式最終任務。

本篇將繼續介紹：

實作即時變化的環境光
實作即時變化的環境光：回顧上一篇開發的顏色
準備程式碼
簡單說明上面程式碼的要點
從實作過程中釐清變數類型
從實作過程中釐清：Uniform是什麼？
從實作過程中釐清：從實作過程中釐清：變數類型Const or #define @
從實作過程中釐清：變數類型Attributes
從實作過程中釐清：變數類型Uniforms
從實作過程中釐清：變數類型Varying
實作即時變化的環境光
經由上一篇，有了型別、函式、程式進入點、程式最終任務這些概念之後，我們其實就有能力修改Shader，創造很多效果。

實作即時變化的環境光：回顧上一篇開發的顏色
回顧上一篇，我們準備好了開發環境，並且在shader給定了gl_FragColor變數，賦予了球體一個顏色。

有了gl_FragColor，就可以指定球是綠色、紅色、紫色等各種顏色。就像上一篇提到的那樣，我修改R, G, B, A為0.0, 1.0, 0.0, 0.0，那個就可以產生綠色。

gl_FragColor=vec4(0.0, 1.0, 0.0, 1.);
https://ithelp.ithome.com.tw/upload/images/20221015/201425053M9QcuzcCj.png

有興趣可以看前一篇文章，它介紹如何修改顏色。但操作過你將會發現一件事情：在Fragment Shader當中雖然可以直接指定顏色，可是我們若沒辦法將一些資料傳到的Fragment Shader，那麼Fragment Shader就很孤單的只能換換顏色而已。

為了活化應用，我們必須從javascript傳值到shader，以下將實作開發，使得用戶可以自己調整球體的顏色。

實作即時變化的環境光：準備程式碼
我準備了上手的程式碼，直接複製貼上即可。幾乎跟前一篇的示例一模一樣。主要就是建置three.js的開發環境，然後新增一顆球。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505KIA8V7maeX.png

https://codepen.io/umas-sunavan/pen/xxjBXrB?editors=1010

實作即時變化的環境光：簡單說明上面程式碼的要點
上一篇，我們實例化了ShaderMaterial，並且指定shader的字串內容為vertex跟fragment，在ShaderMaterial用GLSL編譯，最後在GPU渲染。

const addSphere = () => {
	const vertex = document.getElementById('vertexShader').innerHTML
	const fragment = document.getElementById('fragmentShader').innerHTML
    const geo = new THREE.SphereGeometry(5,15,15)
    const mat = new THREE.ShaderMaterial({
		//  指定vertexShader程式碼來源
		vertexShader: vertex,
		//  指定fragmentShader程式碼來源
		fragmentShader: fragment,
	})
    const mesh = new THREE.Mesh(geo, mat)
    scene.add(mesh)
    return mesh
}

addSphere()
在HTML，我給了字串，分別代表Vertex Shader跟Fragment Shader，但我還沒有介紹其原理。

<p id="fragmentShader">
    void main(void){
    gl_FragColor=vec4(0.6, 0.3, 1.0, 1.0);
    }
</p>
<p id="vertexShader">
    void main(void){
    gl_Position=projectionMatrix*modelViewMatrix*vec4(position, 1.0);
    }
</p>
目前，球體的顏色長這樣：

https://ithelp.ithome.com.tw/upload/images/20221015/20142505kynis8hJYP.png

接著我們試試看再進階一點的實作：

實作即時變化的環境光：單向綁定HTML數值
在HTML加上Range，使得滑鼠可以變更亮度

<main>
+ <input type="range" min="0" max="4" step="0.1" value="0.5" id="intensity">
</main>
首先，在shader加上uIntensity，我將在下一篇提到uniforms 的功用，我先將重點放在傳值。

const mat = new THREE.ShaderMaterial({
		vertexShader: vertex,
		fragmentShader: fragment,
+		uniforms: {
+			uIntensity: {
+				value: 0.5 // 實作下一步input事件之前先給它預設值
+			}
+		}
	})
在javascript單向綁定值到intensity

+ document.getElementById('intensity').addEventListener( 'input', event => {
+ 	sphere.material.uniforms.uIntensity.value = +event.target.value
+ })
完成品
接著，就可以看到我們的ambient light做好了。基本上，速成的環境光就這樣完成了。事實上，three.js 的環境光AmbientLight 就是在shader中加上一個intensity來控制整個物件的顏色。

Untitled

CodePen
https://ithelp.ithome.com.tw/upload/images/20221015/20142505XfyHR2fxV7.png

https://codepen.io/umas-sunavan/pen/JjvzrMq

從實作過程中釐清變數類型
如果你重看前面時做的第二點，你會發現，我們使用傳送了intensity ，使得我們可以調整物體亮度，如下面的程式碼，three.js可以傳送數值0.5給shader的變數uIntensity：

const mat = new THREE.ShaderMaterial({
		vertexShader: vertex,
		fragmentShader: fragment,
+		uniforms: {
+			uIntensity: {
+				value: 0.5
+			}
+		}
	})
但我留了幾個伏筆：

uniforms是什麼？為什麼我們得加上這個東西？這是three.js專屬的撰寫方式嗎？還是Shader的撰寫方式？
為什麼我加上uItensity 就能夠在shader宣告變數為0.5？這個名稱可以自己自定義嗎？如果是，那為什麼要加上u前綴？
我們目前都把一致的數值傳送給FragmentShader，它一致的將數值渲染在物體的所有像素中，可以傳送各不相同的數值給像素嗎？例如只要判斷是左邊數來第100個像素以上，我就換一個顏色，可以這樣做嗎？
接著就來回答這些問題。

從實作過程中釐清：Uniform是什麼？
如它的名字，uniform核心概念就是一致。無論vertex shader在那一幀所執行的錨點有多少的，到第幾個了，也無論fragment shader那一幀所執行像素到底幾顆，uniform的數值那幀都不會變。

這也是為什麼，我們過uniform傳入資料。而這也代表，事實上有些變數行為不同，例如重要的變數類型：

從實作過程中釐清：變數類型Const or #define @
Const就很像Js ES6的Const。至於Define，則是用來取代文件中提及的所有關鍵字，主要是替換文字，基本上並沒有因此多儲存資料在記憶體，而比較像是單純置換所有關鍵字而已，所以能提升效率。

從實作過程中釐清：變數類型Attributes
依據不同的vertex變化的變數。
可用來從外部獲取資料，主要是從buffers抓取資料。例如從js取得資料到Shader中。
可轉成其他變數如vec3。
從實作過程中釐清：變數類型Uniforms
可以從JS傳值到Shader中。

由於GPU在渲染畫面時，一個螢幕會有很多平行的thread一起渲染，但無論是哪一個thread在渲染，這個數值固定一致，這也是被稱作uniforms的原因。

透過其他套件，我們能夠從js傳值到Shader。

例如three.js將uniform傳值的方法：

const mat = new THREE.ShaderMaterial({
		vertexShader: vertex,
		fragmentShader: fragment,
		uniforms: {
			uIntensity: {
				value: 0.5
			}
		}
	})
如此一來，就能在Shader中存取該值

// 在fragment shader，重新宣告uIntensity為uniform即可
uniform float uIntensity;
void main(void){
gl_FragColor=vec4(uIntensity * 1.0, uIntensity * 1.0, uIntensity * 0.0, 1.0);
}
又例如p5.js的作法：

theShader.setUniform("u_resolution", [width, height]); // 傳螢幕大小給shader
接著在Fragment宣告同名的名稱，即可從Js接收資料並且加以應用。

uniform vec2 u_resolution;
從實作過程中釐清：變數類型Varying
跟uniform不同，uniform在每個像素渲染時保持不變，但在varying則各不相同。
通常用來傳遞texture coordinates
小結
本篇從實作環境光開始，快速建立一個shader案例。在這個案例裡面，我們從javascript傳遞數值到了shader。在傳遞的過程中，發現了陌生的關鍵字uniform，並且經過uniform，帶出其它GLSL類別。

經過本篇跟上一篇的說明，現在我們可以自由的從javascript傳送數值到fragment shader，藉此有了進階的操作。

下一篇，我們將透過數值，建立一個光點。

到目前為止，我們都是用three.js製作shader。

但其實three.js並不是唯一的選項，我們的選項其實很多。為了幫助大家順利應用shader在three.js以外的地方，我這邊將使用p5.js以及three.js兩個工具操作shader。

透過這個方式，我們可以稍微認識一下其他前端函式庫怎麼操作shader。

本篇內容包含：

一、為甚麼要用Shader?
二、快速建置Shader環境—透過P5.js
三、快速建置Shader環境—透過three.js
四、建立具有光暈的粒子－原理
五、建立具有光暈的粒子－實作放射狀漸層
六、建立具有光暈的粒子－移動中心點
七、建立具有光暈的粒子－反白整個畫面
八、更多探索
先看看成果:

https://ithelp.ithome.com.tw/upload/images/20221015/20142505Uj3MmWnJhD.png

一、為甚麼要用Shader?
使用Shader製作光暈效果有什麼好處?

要用CSS製作也不是不可以，但要寫的CSS可不少。
流暢，由於Shader是透過顯示卡GPU去算圖，比起CPU來說，圖像處理能力非常好
能做的特效非常多變，每種特效都是一個獨特的萬花筒
Shader也有缺點，例如:

邏輯思維跟Javascript差很多，跟CSS差更多，需要花時間認識shader的運作模式
探索一個特效可能要來回調校參數很多次，你可能會放入很多Magic Number，這並不容易讓其他人閱讀
通常會需要別的API來幫忙存取Shader，例如在本篇使用P5.js，P5.js是很好入門的程式視覺創作的資源庫，你也可以用其他工具，例如WebGL API或是Three.js
二、快速建置Shader環境—透過P5.js
我們快速建置P5.js環境，可以參考官方網站的建置教學

https://p5js.org/get-started/

我們建立一個js檔，並用html嵌入。完成之後，將必要的程式碼填入。

讓js讀取Shader
let theShader;
 
function setup() {

		// 建立canvas，並指定使用WEBGL
    createCanvas(windowWidth, windowHeight, WEBGL);
 
    // load vert/frag defined below
	  theShader = createShader(vertex, fragment);

		// 螢幕像素固定為1物理像素
    pixelDensity(1)
}
 
 
function draw() {
		// 傳送參數給Shader
    theShader.setUniform("u_resolution", [windowWidth, windowHeight]);

    theShader.setUniform('u_time', frameCount*.01);
		// 每次渲染幀(frame)時套用Shader
    shader(theShader)
		// 利用p5.js的rect()建立一個矩形，這個矩形將被shader拿來處理
    rect(0, 0, windowWidth, windowHeight)
}
 
 
const vertex = document.getElementById('vertexShader').innerHTML
const fragment = document.getElementById('fragmentShader').innerHTML
Codepen
我這邊也準備好了CodePen可以實作。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505PP0ZLqHtZ4.png

https://codepen.io/umas-sunavan/pen/gOzEXpx?editors=1011

建立一個Vertext Shader，稱之為'vertexShader.vert'讓Javascript讀取
由於每次算圖，都會先透過Vertex Shader定義形狀，再透過Fragment Shader定義每個像素的顏色。我們先看看Vertex Shader做的事情:

<--- index.html --->
<p id="vertexShader">
	precision highp float;
	//設定畫面精確度為高
	
	attribute vec3 aPosition;
	// 接收P5.js傳入的形狀參數。attribute是一種變數。有多少個錨點Vertex Shader就要跑多少次，而每一次attribute變數的數值都會不一樣。
	// vec3 是一種型別，能儲存三個float的值，其他像是vec2能儲存兩個值, vex4則能儲存四個值。
	void main() {
		// 程式進入點
		vec4 positionVec4 = vec4(aPosition, 1.0);
		// 建立一個能儲存四個值的錨點，將aPosition的三個值當做positionVec4的前三個值，第四個值為1.0
		positionVec4.xy = positionVec4.xy * 2.0 - 1.0;
		// gl_Position 是終點，代表每個錨點應該要在哪個位置呈現
		gl_Position = positionVec4;
	}
</p>
設定畫面精確度為高

接收P5.js傳入的形狀參數。每個形狀的錨點Vertex Shader都會算一遍，像矩形一共會算四遍。

由於對Shader來說，整個canvas就是-1~1個大小。我們利用Vertex Shader將畫布的座標改為X,Y皆為0~1的座標範圍。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505uEHIXFxwJ0.png

Shader的座標

https://ithelp.ithome.com.tw/upload/images/20221015/20142505sgXL3ooiMh.png

修改後的Shader做標

將修改後的座標位置傳給gl_Position 。gl_Position 將代表畫面中的錨點應該要在什麼位置。

建立一個Fragment Shader，稱之為'fragmentShader.frag'讓Javascript讀取
Vertex Shader定義完形狀之後，由Fragment Shader來填色，我們看看Vertex Shader做的事情:

#ifdef GL_ES
precision mediump float;
//設定畫面精確度為中
#endif
uniform vec2 u_resolution;
// 接收javascript傳過來的參數，在這邊是canvas的長寬。要注意這是vec2，所以一次能儲存兩個點
void main() {
	vec2 st = gl_FragCoord.xy/u_resolution.xy;
// gl_FragCoord是Fragment Shader內建的每個像素座標資料。每個像素的長寬除上canvas長寬，可以得到每個像素的單位座標(0~1座標)
	gl_FragColor = vec4(st.xy, 0.0 , 1.0);
// gl_FragColor 為程式的終點。我們設定紅色為每個像素的x單位座標，綠色為每個像素的y單位座標
}
設定畫面精確度為中
接收javascript傳過來的參數
算出每個像素在0~1座標的位置。由於Fragment Shader會計算每一個像素的顏色，所以一個1920*1080大小的螢幕來說，Fragment Shader會跑2073600遍，每一遍都可以得到不同的像素座標位置。
利用每個像素的位置資訊填入顏色。X座標將成為顏色R的大小，Y座標將成為G的大小。像素越左邊，X越趨近0，像素越上面，Y越趨近1。
回去看看畫面，一個漂亮的漸層就完成了

https://ithelp.ithome.com.tw/upload/images/20221015/20142505yM2pVWYExH.png

如果不想看three.js的過程，可以跳過下一章，直接從大標題「建立具有光暈的粒子－原理」繼續看。

三、快速建置Shader環境—透過three.js
我已經準備好範本，直接從範本開始即可。

CodePen
https://ithelp.ithome.com.tw/upload/images/20221015/20142505Kkr5IO6MfC.png

https://codepen.io/umas-sunavan/pen/wvjOPrx?editors=1010

簡介範本程式碼
我節錄addSquare() 函式，可以看到，我建立四個三維向量：lb, lt, rt, rb 分別代表左下角、左上角、右上角、右下角。四個皆透過函式.unproject(camera) 轉成世界座標。這件事情我們在「Day21: three.js 前端3D視覺特效開發實戰—智慧工廠：鏡頭投影、追蹤與飄移特效」也有實作過。

const addSquare = () => {
	const vertex = document.getElementById('vertexShader').innerHTML
	const fragment = document.getElementById('fragmentShader').innerHTML
	// 將螢幕座標的左下角、左上角、右上角、右下角轉成世界座標
	const lb = new THREE.Vector3(-1, -1, 0.8).unproject(camera)
	const lt = new THREE.Vector3(-1, 1, 0.8).unproject(camera)
	const rt = new THREE.Vector3(1, 1, 0.8).unproject(camera)
	const rb = new THREE.Vector3(1, -1, 0.8).unproject(camera)
}

lb, lt, rt, rb代表鏡頭在世界座標投影下的四個頂點。我們可以透過四個頂點建立一個平面。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505sm9mRcEZed.png


const addSquare = () => {
	//	...承接上一段程式碼
	// 在世界座標建立一個平面
	const vertices = new Float32Array([
		// 一個矩形平面至少要有兩個三角面，以下是第一個三角面的三個頂點
		...lb.toArray(),
		...rb.toArray(),
		...rt.toArray(),
		// 以下是第二個三角面的三個頂點
		...rt.toArray(),
		...lt.toArray(),
		...lb.toArray()
	]);
	// 將世界座標組成一個平面
	const geo = new THREE.BufferGeometry()
	// 將三角面組合成形狀
	geo.setAttribute('position', new THREE.BufferAttribute(vertices, 3));
}
製作出形狀之後，我們將螢幕的寬高傳送到shader中。

const addSquare = () => {
	//	...承接上一段程式碼
	const mat = new THREE.ShaderMaterial({
		vertexShader: vertex,
		fragmentShader: fragment,
		uniforms: {
			u_resolution: {
				value: [window.innerHeight,window.innerWidth]
			}
		}
	})
	const mesh = new THREE.Mesh(geo, mat)
	scene.add(mesh)
	return mesh
}
釐清之後，我們就可以繼續往下研究光暈粒子的原理。

四、建立具有光暈的粒子－原理
光暈，就是中間白周圍黑，事實上就是一種漸層。

我們只要能實現一個放射狀的漸層，就離光暈不遠了。

1. 原理
假設畫布有800x600的像素大小，左下角為第(1,1)個像素，右上角為第(800,600)個像素。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505oD7ag1ksD9.png

我們可以拿像素的位置，當做顏色的依據。

對於Fragment Shader來說，每個像素都要有一組rgb顏色，每組顏色都是0~1的亮度(而不是0~255的亮度)。

先讓所有像素座標變成單位座標（0~1座標）。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505Isn1P4nvDw.png

當像素越接近右上角，距離(0,0)原點越遠，長度越長，顏色越亮；當像素越靠近左下角，距離(0,0)原點近，長度越短，則越沒有顏色。透過這個方式，我們就能創造放射狀漸層的畫布。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505WP5uxLCc1c.png

https://ithelp.ithome.com.tw/upload/images/20221015/201425058nSHN4i6SK.png

只要我把沒有顏色的地方改到中心點，就可以創造出我們要的光暈了

五、建立具有光暈的粒子－實作放射狀漸層
我們從javascript開始，透過p5.js提供的setUniform()函式，而three.js透過ShaderMaterial的參數，我們可以在每次渲染幀(frame)時帶入整個畫布的長寬大小，先稱它為u_resolution。

// p5.js:
myShader.setUniform("u_resolution", [windowWidth, windowHeight]);

// three.js:
new THREE.ShaderMaterial({
	...,
	uniforms: {
		u_resolution: {
			value: [window.innerHeight,window.innerWidth]
		}
	}
})
在Fragment Shader裡面，為了接收js用setUniform傳過來的數值，需要宣告一個變數叫u_resolution。

uniform vec2 u_resolution;
// 接收javascript傳過來的參數，在這邊是canvas的長寬。要注意這是vec2，所以一次能儲存兩個點
透過u_resolution，能知道整個畫布的長寬有多大，也能求得每個像素的單位座標

vec2 st = gl_FragCoord.xy/u_resolution;
// gl_FragCoord是Fragment Shader自己提供的變數，代表每個像素的像素位置。
// 畫布大小除上像素位置，就是每個像素的單位座標(0.0~1.0)
取得每個像素距離左下角原點(0,0)有多遠

float length = length(st);
// 每個像素距離(0,0)多遠呢？使用length就可以得到距離(0,0)的長度
// 越靠近(0,0)的值越小，越靠近(1,1)的值越大
現在每個像素的length 都不一樣。由於每個像素都會跑一遍，現在左下角的像素算出來length 比較小，右上角的像素length 比較大。依照不同的距離數值當做顏色數值。

gl_FragColor = vec4(length,length,length , 1.0);
// 每個像素離原點的距離，就是RGB亮度
https://ithelp.ithome.com.tw/upload/images/20221015/20142505Z56jZpIkOg.png

現在我們得到了一個放射狀的漸層。看起來像是一個黑色的粒子吧？現在我們需要把黑色粒子移到畫面中心點。

六、建立具有光暈的粒子－移動中心點
雖說是「移動」黑色粒子的中心點，但概念有點不一樣。實際上fragment shader只能計算每個像素的顏色，沒辦法移動某個東西。

我們看到的黑色中心點，是因為左下角的像素距離原點最短，顏色看齊來最深。我們只要讓中間像素距離原點最短，那最暗的地方就會是中間點。

怎麼實現呢?

float length = length(st-vec2(0.5,0.5));
// 原本位於(0.5,0.5)的像素減掉(0.5,0.5)之後，變成了(0,0)。現在，原點變成了畫布中心。
https://ithelp.ithome.com.tw/upload/images/20221015/20142505cs0goWDpPc.png

效果會是這樣:

https://ithelp.ithome.com.tw/upload/images/20221015/20142505HJtCUaPbgc.png

七、建立具有光暈的粒子－反白整個畫面
怎麼讓黑色變成白色，白色變成黑色? 倒數就可以了。

導數的特性是，100的倒數為0.01，10的倒數為0.1，越大的數值，倒數之後越小。

但目前的畫畫布最小值是0，最大值是0.7，倒數之後一定會超過1，因此，我們需要額外乘上一個小數來縮小我們的數值。

gl_FragColor = vec4(1.0/length*0.1,1.0/length*0.1,1.0/length*0.1 , 1.0);
https://ithelp.ithome.com.tw/upload/images/20221015/20142505p7iTal8LcC.png

一個有光暈的粒子就做出來了。

八、更多探索
頁面越寬，粒子變形越嚴重？
https://ithelp.ithome.com.tw/upload/images/20221015/20142505Hnkrj5haLE.png

螢幕上每個像素大小都一樣，為什麼畫面會被拉寬？雖然寬度上被分配到的像素數目比高度還要多，但對於shader來說，畫面不過是長0~1、寬0~1的矩型罷了。顏色的亮度取決於每個像素離中心的距離，而不是像素的長寬。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505cs1069Z2Sk.png

https://ithelp.ithome.com.tw/upload/images/20221015/20142505YzBwfVJi79.png

讓長寬比例保持一致
我的方法是，讓每寬度的比例從「0~1」拉寬成「0長寬比~1長寬比」。

vec2 screenRatio = vec2(u_resolution.x/u_resolution.y,1.0);
// 長寬比。假設螢幕是800x600，長寬比就是1.33，screenRation就是(1.33,1.0)
	st*=screenRatio;
// 讓st乘上成寬比，(0.25,0.5)的像素原本是距離中心點0.55，現在變成(0.60)
float length = length(st-vec2(0.5,0.5)*screenRatio);
// 讓st乘上成寬比，中心點的比例也會變化
https://ithelp.ithome.com.tw/upload/images/20221015/20142505c5yENpFzAm.png

https://ithelp.ithome.com.tw/upload/images/20221015/20142505sspAGT5aHJ.png

短短幾行可以做出那麼好的效果，Shader非常厲害。

#ifdef GL_ES
precision mediump float;
#endif
uniform vec2 u_resolution;
void main() {
	vec2 st = gl_FragCoord.xy/u_resolution.xy;
	vec2 screenRatio = vec2(u_resolution.x/u_resolution.y,1.0);
	st*=screenRatio;
	float length = length(st-vec2(0.5,0.5)*screenRatio);
	gl_FragColor = vec4(1.0/length*0.1,1.0/length*0.1,1.0/length*0.1 , 1.0);
}
最佳化效能
由於Shader讓我們直接控制GPU。fragment shader幫每個像素跑一遍，一個台13吋的macbook pro有2560*1600像素，也就是四百萬個像素要跑四百萬遍，每秒60個frame，一秒就要跑2億4千萬遍。

一秒兩億多遍，一旦GLSL沒有寫好，就會讓GPU非常非常辛苦，我們需要好好檢視我們的程式碼。

#ifdef GL_ES
precision mediump float;
#endif
uniform vec2 u_resolution;
void main() {
	vec2 st = gl_FragCoord.xy/u_resolution.xy;
	float screenRatio = u_resolution.x/u_resolution.y;
// 將screenRatio改成一個浮點數，如此一來節省要儲存的數值
	st.x*=screenRatio;
// 只讓x乘上長寬比
	float brightness = 0.1/length(st-vec2(0.5*screenRatio,0.5));
// 除了讓中心點成上長寬比以外，也先讓length成為倒數，乘上數值縮小亮度，改名成brightness
	gl_FragColor = vec4(brightness,brightness,brightness, 1.0);
}
除此之外，我們還能讓宣告的變數名稱更精簡

#ifdef GL_ES
precision mediump float;
#endif
uniform vec2 u_resolution;
void main() {
	vec2 st = gl_FragCoord.xy/u_resolution.xy;
float sr = u_resolution.x/u_resolution.y;st.x*=sr;
float b = 0.1/length(st-vec2(0.5*sr,0.5));
gl_FragColor = vec4(b,b,b, 1.0);
}
以上就是創造光暈粒子的過程，如果有偏誤之處還歡迎多多交流。

喜歡的話幫我拍拍手吧?

下面我將介紹如何透過Shader製作一個光暈。

分三個階段：

用three.js製作Shader材質
在vertex shader加上vertexNormal
在fragment shader加上「神秘的程式碼」
準備程式碼
CodePen
我已經準備好範本程式碼。如果看到畫面是淡藍色，那代表這是正常顯示的範本。

https://ithelp.ithome.com.tw/upload/images/20221016/20142505ZiQYyhHC3V.png

https://codepen.io/umas-sunavan/pen/gOzEqwa?editors=1010

用three.js製作Shader材質
我們建立一個球體。球體的材質是由ShaderMaterial組成。而ShaderMaterial所使用的Shader程式碼，來自HTML。

+const addSphere = () => {
+	const vertex = document.getElementById('vertexShader').innerHTML
+	const fragment = document.getElementById('fragmentShader').innerHTML
+    const geo = new THREE.SphereGeometry(5,50,50)
+    const mat = new THREE.ShaderMaterial({
+		vertexShader: vertex,
+		fragmentShader: fragment,
+	})
+    const mesh = new THREE.Mesh(geo, mat)
+    scene.add(mesh)
+    return mesh
+}

+addSphere()
HTML：

+<div style="display: none">
+    <p id="fragmentShader">
+        #ifdef GL_ES
+        precision mediump float;
+        #endif
+        void main(void){
+					gl_FragColor=vec4(0.,0.,0.2,1.);
+        }
+    </p>
+    <p id="vertexShader">
+        void main(void){gl_Position=projectionMatrix*modelViewMatrix*vec4(position, 1.0);
+        }
+    </p>
+</div>
https://ithelp.ithome.com.tw/upload/images/20221016/20142505oOJTkhQMCi.png

在vertex shader加上vertexNormal
在vertex shader我們添加vertexNormal。vertexNormal 是我們即將從vertex shader傳入到fragment shader的變數，而normal則是three.js提供的變數。

+varying vec3 vertexNormal;

void main(void){
+  vertexNormal = normal;
	void main(void){gl_Position=projectionMatrix*modelViewMatrix*vec4(position, 1.0);
}
在fragment shader我們添加。

	#ifdef GL_ES
	precision mediump float;
	#endif

+	varying vec3 vertexNormal;
	void main(void){
		gl_FragColor=vec4(0.,0.,0.2,1.);
	}
在fragment shader加上「神秘的程式碼」
過去我們有介紹過fragment shader，gl_FragColor會是每個像素最終的顏色。如果我們設置成vec4(0.2,0.2,0.4,1.)，那大概長這樣：

https://ithelp.ithome.com.tw/upload/images/20221016/20142505JdMJrzzPnL.png

我們加上「神秘的程式碼」：

	varying vec3 vertexNormal;
	void main(void){
+		float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.));
+		vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
+		gl_FragColor=vec4(atmosphere,0.) + vec4(0.,0.,0.2,1.);
-		gl_FragColor=vec4(0.,0.,0.2,1.);
	}
如此一來，光暈就完成了。

完成品
https://ithelp.ithome.com.tw/upload/images/20221016/20142505yU0DVyvMAk.png

CodePen
https://ithelp.ithome.com.tw/upload/images/20221016/20142505fgJB1fEeit.png

https://codepen.io/umas-sunavan/pen/KKREJzq

小結
你現在可能會充滿問號，對於為什麼可以形成光暈有滿滿的問號。

不過沒關係，我們接下來將用兩篇的篇幅解釋為什麼光暈可以生成。並且透過這個案例，不斷挖掘shader的原理，最後完整的釐清光暈的運作方式。

前兩篇，我們先講解原理，再討論實作方式。這樣的作法非常教科書。很多時候我們在Shader研究原理時，順序往往是到過來的。意思是：我們常常會先看到一個很好的Shader程式碼，但不知道其原理，不斷推敲回去。

所以從本篇開始，我會從程式碼去推敲其作用，並且延伸其作用的概念，最後講解整個原理。

參考資料
經典大作Book of shader的說明

GLSL提供的函式

WebGLProgram的說明


本篇內容
vertexNormal 是什麼？
兩個Shader之間的傳值方式
WebGLProgram 添加變數的特性
vertexNormal 從哪裡來？
視覺化SphereGeometry 的法線向量位置
什麼是「神秘的程式碼」
上一篇，我們加上了神秘的程式碼，突然之間球體就有了光暈。

+ varying vec3 vertexNormal;
	void main(void){
+		float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.));
+		vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
-		gl_FragColor=vec4(0.,0.,0.2,1.);
+		gl_FragColor=vec4(atmosphere,0.) + vec4(0.,0.,0.2,1.);
	}
沒有修改之前：

https://ithelp.ithome.com.tw/upload/images/20221016/201425059WLJ3ScJZW.png

修改之後：

https://ithelp.ithome.com.tw/upload/images/20221016/20142505rAo1ZCdJ0A.png

這之間發生什麼事？為什麼加上這幾行，就會出現光暈？背後的原理是什麼？本篇將釐清這「神秘程式碼」的邏輯。

觀察程式碼
我們再重新看一次程式碼：

+ varying vec3 vertexNormal;
	void main(void){
+		float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.));
+		vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
-		gl_FragColor=vec4(0.,0.,0.2,1.);
+		gl_FragColor=vec4(atmosphere,0.) + vec4(0.,0.,0.2,1.);
	}
已目前我們所能釐清的事情來看，我們知道幾件事情：

fragment shader宣告了一個varying ，代表vertexNormal 是一個三維變數，而且每個像素的vertexNormal 可能都不太一樣。vertexNormal 有數值嗎？如果有的話，數值是從哪裡來的？怎麼都沒有看到它被賦值？
vertexNormal 被放進了函式dot() 的參數。dot()是在哪裡宣告的？它的作用是什麼？
除了這兩個不確定以外，我們確定intensity 是一個浮點數，它後來乘上了一個三維數值，形成atmosphere
atmosphere 最終用作計算gl_FragColor的顏色，所以atmosphere 是一個顏色。
gl_FragColor的顏色除了atmosphere 以外，還被加上了一點點的藍色（vec4(0.,0.,0.2,1.)）
這五點中，最大的謎團就是第一點跟第二點。基本上，只要解開第一點跟第二點，我們就可以破解光暈的實作原理了。

前兩篇，我們先講原理，再討論實作方式。這樣的作法非常教科書。但很多時候我們在Shader研究一個原理，順序往往是到過來的。意思是，我們常常會先看到一個很好的Shader程式碼，但不知道其原理。

所以從本篇開始，我會從程式碼去推敲其作用，並且延伸其作用的概念，最後講解整個原理。

好的，我們針對第一點跟第二點開始講解，而本篇（Day27）將解開第一點，下一篇（Day28）將解開第二點。

vertexNormal 有值嗎？如果有的話，數值是從哪裡來的？
vertexNormal 有值嗎：vertexNormal 是什麼？
先觀察vertexNormal。它的來源，其實是來自vertex shader。

// vertex shader
varying vec3 vertexNormal; <=從這裡來
void main(void){
  vertexNormal = normal; <=被賦予normal數值
  gl_Position=projectionMatrix*modelViewMatrix*vec4(position, 1.0);
}
vertexNormal 在vertext shader被宣告，而被賦了normal值。

現在我們越看越含糊了，你會問：

為什麼vertex shader可以將數值傳送給的fragment shader？前者每一個錨點執行一次，後者每顆像素執行一次，那到底是什麼時候傳值的？
normal是打哪裡來的變數？
兩個問題我下面回答：

vertexNormal 有值嗎：兩個Shader之間的傳值
事實上，vertex shader可以將錨點資料傳送給fragment shader。我們在「Day10: three.js 前端視覺特效工程師實戰：全球戰情室—貼圖原理」有提到：當fragment shader要「採樣（sample）」材質圖來幫每一顆像素上色時，必須透過vertext shader來確認UV位置。如此一來，才能從材質圖中找到正確的位置採樣。

https://ithelp.ithome.com.tw/upload/images/20221016/20142505CD5gf5hU3J.png

由此可知，vertex shader一直都能夠將重要的數值傳遞給fragment shader加做使用。當然，如果fragment shader要「接住」來自vertex shader的變數，仍需要在fragment shader宣告同樣名字的變數。

// vertexShader
varying vec3 vertexNormal; // 宣告了vertexNormal
void main(void){
  vertexNormal = normal;
  gl_Position=projectionMatrix*modelViewMatrix*vec4(position, 1.0);
}
// fragmentShader
varying vec3 vertexNormal; // <== 雖然vertex shader有宣告，但我們在fragment shader也需要宣告同樣的數值
void main(void){
	float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.));
	vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
	gl_FragColor=vec4(0.,0.,0.2,1.);
	gl_FragColor=vec4(atmosphere,0.) + vec4(0.,0.,0.2,1.);
}
宣告時，我們宣告它是varying，而且是一個vec3。它之所以是varing，是因為varying最大的特色，是他在執行每一個錨點時，值都不太相同。而這樣的特性剛好跟uniform 相反。有興趣可以從前一篇「Day24: WebGL Shader——快認識速Shader並使用Variable Qualifiers」深入理解。

vertexNormal 有值嗎：varying 傳值的邏輯
varying可以在每一次vertex shader計算錨點時，依據錨點的資訊（例如位置、UV、法線）變化。

所以如果你有一個平面，平面有四個頂點，那麼vertex shader會執行四次，以取得渲染範圍，與此同時，vertex shader也會傳送位置、UV、法線到fragment shader。

一旦fragment shader接收到數值之後，可以依照像素的位置，「推估」出像素所在的模性位置其UV、法線跟位置本身。推估的方式就是利用插值（Interpolation），這個邏輯就是用位置去推算像素所在位置的值。

https://ithelp.ithome.com.tw/upload/images/20221016/20142505l5qrMs7qsG.png

插值可以「推估」自身的數值，這使得fragment shader可以推估出varying的數值。

而至於它為何之所以是vec3，則是因為它在vertex shader的源頭變數是vec3。兩者得相符才能順利傳值。

總之，以上解釋vertex shader跟fragment shader之間傳遞數值的關係。我們可以用一張圖解釋：

https://ithelp.ithome.com.tw/upload/images/20221016/20142505SB4hEsgF1U.png

從圖片可以看到，fragment shader的vertexNormal 是從vertex shader來的，但vertexNormal的數值又是normal給的，那normal的數值從哪裡來？接下來我們繼續追溯這個來源。

vertexNormal 有值嗎：被偷偷加上去（Prepend）的程式碼
目前我們從程式碼可以得知：vertexNormal的數值來自normal，而normal則不知道來自何方。我們沒有宣告，它也沒有出現在任何一處。

為什麼會有這個變數？誰宣告它？它的資料怎麼來？

答案是：當shader在編譯時，早就被偷偷宣告變數了。

// vertexShader
varying vec3 vertexNormal; // <== 雖然vertex shader有宣告，但我們在fragment shader也需要宣告同樣的數值
void main(void){
  vertexNormal = normal;
  gl_Position=projectionMatrix*modelViewMatrix*vec4(position, 1.0);
}
當我們在three.js實例化WebGLRenderer 時，WebGLRenderer 就負責WebgL渲染的大小事。WebGLRenderer渲染畫面以外，也令WebGLProgram 在編譯vertext shader以及fragment shader之前，宣告並加上了特定的變數。

總共有哪些變數？可以參考WebGLProgram的說明。WebGLProgram掌控其底下的fragment shader以及vertex shader，同時也能夠添加變數。雖然我們看不到，但我們很肯定它將會在編譯之前先宣告。

這也使得我們可以任意取用，畢竟編譯之前怎麼宣告都可以。

https://ithelp.ithome.com.tw/upload/images/20221016/20142505FT6L3lX2Uh.png

這也是為什麼當你Shader出現Error時，會有一大堆你明明沒宣告過的東西。

https://ithelp.ithome.com.tw/upload/images/20221016/20142505oHzkMEar5u.png

這就是底層原因。所以normal是才自WebGLProgram，那WebGLProgram給它什麼數值呢？

如果你翻開three.js官網的話，答案很快就會出現：

https://ithelp.ithome.com.tw/upload/images/20221016/20142505VjSzFLM1i8.png

normal連同position跟uv，從geometry而來。

而這裡的Geometry是指哪裡呢？指的是我們javascript的程式碼中，由three.js實例化SphereGeometry時就定義出來的球形。

const geo = new SphereGeometry(5,50,50) // <=從這裡取得
const mat = new ShaderMaterial({
  fragmentShader: fragText,
  vertexShader: vertText,
})
const mesh = new Mesh(geo, mat)
SphereGeometry 在實例化時，就會產生形狀所需的錨點。這跟其它種Geometry 一樣，以一個PlaneGeometry來說至少會產生四個頂點，一個BoxGeometry至少要有八個錨點。

這些錨點將會在實例化時生成，除了生成位置（position）資訊以外，也會生成法線（normal）以及UV（uv）。但當我們建立Mesh時，vertex shader就可以存取normal、position以及uv。

所以關於vertexNormal怎麼來的，我們已經解開神秘面紗了。vertexNormal最源頭，是從three.js中的SphereGeometry 來的。

https://ithelp.ithome.com.tw/upload/images/20221016/20142505EF5YyNsAZh.png

如果我們在three.js加上一個helper，觀察其normal的向量，我們可以看到法線的方向。

const addSphere = async () => {
	const vertex = document.getElementById('vertexShader').innerHTML
	const fragment = document.getElementById('fragmentShader').innerHTML
    const geo = new THREE.SphereGeometry(5,50,50)
    const mat = new THREE.ShaderMaterial({
		fragmentShader: fragment,
		vertexShader: vertex
	  })
  const mesh = new THREE.Mesh(geo, mat)
  scene.add(mesh)
+	const helper = new VertexNormalsHelper( mesh, 1, 0xff0000 );
+	scene.add( helper );
  return mesh
}
加上程式碼之後，就可以看到，這些normal的向量。這些向量是在我們透過SphereGeometry 實例化球體時所建立的。

https://ithelp.ithome.com.tw/upload/images/20221016/20142505U5YI8AbQ1y.png

講到這裡，我們就已經破解了vertexNormal 的由來。vertexNormal 就是球體的法線。

雖然如此，我們仍然必須釐清第二個問題：vertexNormal 被放進了函式dot() 的參數。dot()是在哪裡宣告的？它的作用是什麼？

varying vec3 vertexNormal;
void main(void){
+		float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.));
		vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
		gl_FragColor=vec4(0.,0.,0.2,1.);
		gl_FragColor=vec4(atmosphere,0.) + vec4(0.,0.,0.2,1.);
}
這個問題，將在下一篇解答。雖然我們還沒完全釐清神秘程式碼，但我們在釐清問題時，已經認識了好多原理。這些原理包含：

fragment透過插值（Interpolation）取得任何類別為varying的數值
WebGLProgram在編譯vertext shader以及fragment shader之前，會prepend特定變數
prepend的數值中，會有來自three.js的Geometry數值
SphereGeometry 的法線向量位置
參考資料
fragment shader的插值方式

VertexNormalsHelper

Shader是前端視覺特效的重要戰場，而本篇所介紹的shader，不僅只是說明怎麼辦到，還要解釋期原理，並且帶出我們在鐵人賽一開始所打下的重要基礎。

Shader不能只是看人家怎麼作，還必須親自應用，才能夠有更好的發揮。而要親自應用時，必須理解底層的原理，才能操作得如魚得水。而這也是我的設計這個順序的想法。

上一篇，我們釐清了vertexNormal 的前是今生，而本篇必須接著釐清最後一塊拼圖：dot()是在哪裡宣告的？它的作用是什麼？

釐清之後，就可以根據前一篇破解的謎團，以及本篇破解的謎團，把這段程式碼順一遍。

快速回顧上一篇
varying vec3 vertexNormal;
void main(void){
+		float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.));
		vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
		gl_FragColor=vec4(0.,0.,0.2,1.);
		gl_FragColor=vec4(atmosphere,0.) + vec4(0.,0.,0.2,1.);
}
上一篇，我們得出了vertexNormal 是從哪裡來的。

https://ithelp.ithome.com.tw/upload/images/20221016/20142505dQWU1o9qZl.png

既然已經解釋vertexNormal，本篇將繼續解答第二個疑問：dot()是在哪裡宣告的？它的作用是什麼？

dot()是在哪裡宣告的？它的作用是什麼？
dot()怎來的：解釋dot()
我們在「Day8: Three.js 你有被光速踢過嗎？解析3D界的黃猿——光的底層原理與介紹」其實有提到也同樣叫做dot()的函式。不同的是，那時提及的dot，是three.js中Vector3提供的函式。

dot()的作用，是計算兩個向量有多相近。兩向量越是相近，越是趨近於1。最終如果是同方向，那就是1。相反的，如果兩個向量越是相反，則越趨近-1，如果完全相反，那就是-1。概念很簡單吧？

而在GLSL提供的函式dot() 也是同樣的概念，我們給它兩個參數，它將回傳1~-1區間的結果，來表示兩個向量的相近程度。dot其實就是Dot Product的簡稱，中文叫做內積，是相當實用的函式。

If A, B are vectors: (Ax, Ay), (Bx, By)

dotProduct = |A| • |B| • cosθ

dot()怎來的：圖解dot()
如果不懂，我就用圖片說明：

現在我們有一個解析度超級低的球體，我們從正Y軸往下看這個場景，也會看到鏡頭位於正Z的位置：

https://ithelp.ithome.com.tw/upload/images/20221016/20142505PIGYnHZow0.png

這顆球有很多個面，每一個頂點都有一個法線輻射狀指向四方。

每一個法線，都可以拆成x,y,z數值

https://ithelp.ithome.com.tw/upload/images/20221016/20142505cUFq9cUaPG.png

如果光看球體於xz剖面來看，可以發現面對鏡頭的頂點，z值最大，離正z軸(0,0,1)最相近，內積相乘之後最大。背對鏡頭的頂點z值最小（因為指向負z），離(0,0,1)最遙遠，相乘之後最小。

https://ithelp.ithome.com.tw/upload/images/20221016/2014250536cPgrFrWu.png

如果全部變成了負數，又加上1.05，就會變成這樣：

https://ithelp.ithome.com.tw/upload/images/20221016/20142505AnAAFDH8jo.png

這張圖可以看見，接近鏡頭的頂點數值最小，相反的，背對鏡頭的錨點，數值最大。

上面這些流程，也再次解釋了為什麼會出現光暈：

https://ithelp.ithome.com.tw/upload/images/20221016/20142505ZzKi7x5nBQ.png

我們釐清了關鍵問題，現在順一遍程式碼
所以說，我們回頭看到一開始討論的這行程式碼：

varying vec3 vertexNormal;
void main(void){
+		float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.));
		vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
		gl_FragColor=vec4(0.,0.,0.2,1.);
		gl_FragColor=vec4(atmosphere,0.) + vec4(0.,0.,0.2,1.);
}
綜合目前的所討論的結果，我們就可以推敲這行程式碼的意圖：

vertexNormal 就是像素所在位置的法線單位向量（根據上一篇）
它計算vertexNormal以及正Z軸單位向量的內積（透過dot()），所以說，如果該像素的法線越接近正z軸，則數值越接近1；如果該像素的法線越遠離正Z軸，則數值越接近-1。
由第二點可得知，dot() 會回傳-1到1之間的數值（視法線方向而定）。而它加上了負值（1.05 - dot()就是-dot() + 1.05），變成1（偏離正z軸）到-1（接近正z軸）的數值。
1~-1的數值加上1.05，使數值區間變成2.05（偏離正z軸）到0.05（接近正z軸）。
所以說，intensity代表法線跟z軸的相似程度。若法線剛好跟正z軸同方向，則為0.05，如果相反則為2.05
而這樣的數值，達到了光暈的效果。光暈就是邊界比較明亮（intensity 數值大），中心比較陰暗的效果：

https://ithelp.ithome.com.tw/upload/images/20221016/20142505X0JRZXI9lS.png

透過Intensity生成顏色
現在我們已經知道Intensity使得每個像素呈現的數值不同，而這將生成光暈。

但這並沒有完整的解釋光暈是如何從一個數值(intensity)變成顏色的。以下解釋：

透過Intensity生成顏色
觀察intensity後續怎麼被使用的話，我們可以看到，它乘上了一個三維數值，並被宣告成atmosphere。

varying vec3 vertexNormal;
void main(void){
  float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.));
  vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
  gl_FragColor=vec4(atmosphere,0.) + vec4(0.2,0.2,0.4,1.);
}
基本上，atmosphere 就是藍色（vec3(.3, .6, 1.) ）乘上像素的亮度，使得藍色在球體最靠近鏡頭的地方黯淡，而在球體靠近邊界的地方明亮，形成內光暈。

透過將顏色加到球體上
有了atmosphere ，只要再加上球體本身的顏色（vec4(0.2,0.2,0.4,1.)），就可以計算出每顆像素最終的顏色。所以最後一行正是在疊加顏色。

gl_FragColor=vec4(atmosphere,0.) + vec4(0.2,0.2,0.4,1.);

成品
https://ithelp.ithome.com.tw/upload/images/20221016/20142505InwhAoPrh9.png

延伸嘗試
而身為視覺特效，內光暈基本上是創造地球最重要的特效之一，當我們理解內光暈之後，才能夠加以發揮。

本次的內光暈，純粹使用intensity來控制而已，就像這張圖一樣，只有線性的變化。

https://ithelp.ithome.com.tw/upload/images/20221016/20142505AXkE8hSA4e.png

但我們還可以有很多種變化，例如：

透過mod()做出階梯的視覺感

mod函式：

https://ithelp.ithome.com.tw/upload/images/20221016/20142505bJWipctw4N.png

varying vec3 vertexNormal;
void main(void){
  float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.));
-	vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
+ vec3 atmosphere = vec3(.6, .4, 0.) * mod(intensity, 0.1) * 5.; // <= 使用mod限制範圍
  gl_FragColor=vec4(atmosphere,0.) + vec4(0.8,0.6,0.1,1.);
}
https://ithelp.ithome.com.tw/upload/images/20221016/201425052Umkx2IBPa.png

阻尼器是你？！

更對比的內光暈

透過pow()產生指數的變化

https://ithelp.ithome.com.tw/upload/images/20221016/20142505LTfIzcplq4.png

varying vec3 vertexNormal;
void main(void){
  float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.));
-	vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
+ vec3 atmosphere = vec3(.3, .6, 1.) * pow(intensity,2.);
  gl_FragColor=vec4(atmosphere,0.) + vec4(0.2,0.2,0.4,1.);
}
https://ithelp.ithome.com.tw/upload/images/20221016/20142505NeixSyJfLt.png

前後對稱的球體

透過sin()限制數值由-1到1

https://ithelp.ithome.com.tw/upload/images/20221016/20142505IQpd9iGRFg.png

varying vec3 vertexNormal;
void main(void){
  float intensity = 1.5 - dot(vertexNormal, vec3(0.,0.,1.));
-	vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
+ vec3 atmosphere = vec3(.3, .6, 1.) * sin(intensity);
  gl_FragColor=vec4(atmosphere,0.) + vec4(0.2,0.2,0.4,1.);
}
Untitled

詭異的環

由於sin()只能在1單位內變化，我們可以放大它的變化。

varying vec3 vertexNormal;
void main(void){
	float intensity = 1.45 - dot(vertexNormal, vec3(0.,0.,1.));
-	vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
+	vec3 atmosphere = vec3(.3, .6, 1.) * sin(intensity*20.);
	gl_FragColor=vec4(atmosphere,0.) + vec4(0.2,0.2,0.4,1.);
}
Untitled

比較柔和的漸層

透過ceil()產生階層感。

https://ithelp.ithome.com.tw/upload/images/20221016/20142505dutq8OTYId.png

varying vec3 vertexNormal;
void main(void){
  float intensity = 1.45 - dot(vertexNormal, vec3(0.,0.,1.));
-	vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
+ vec3 atmosphere = vec3(.3, .6, 1.) * ceil(intensity*10.)/10.;
  gl_FragColor=vec4(atmosphere,0.) + vec4(0.2,0.2,0.4,1.);
}
Untitled

CodePen
https://codepen.io/umas-sunavan/pen/QWrYqwq?editors=1010

小結
本篇解釋許多核心概念。並且用圖解的方式解釋函式的成因。

我們透過normal來製作球體特效。

本篇我們學到：

dot()的作用
Intensity 生成顏色
利用向量生成多種樣式的球體
下一篇我們將解決視角問題。現在還有視角問題，意思是：一旦鏡頭離開正Z軸視角，我們的內光暈就破功了。我們將在下一篇探討。

Untitled

參考資料
經典大作Book of shader的說明

GLSL提供的函式

WebGLProgram的說明

本篇內容
一、全視角的內光暈
二、內光暈在地球的應用
成品
earth.gif

一、全視角的內光暈
前一篇我們完成了具有內光暈的球體。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505uSftX9xOeS.png

但是最大的問題，就是當鏡頭轉向時，會出現破綻：

Untitled

為什麼會有這個問題呢？

全視角的內光暈：我們先準備上一篇的程式碼
CodePen

https://ithelp.ithome.com.tw/upload/images/20221014/201425057c40T8eoEL.png

https://codepen.io/umas-sunavan/pen/QWrYqwq

回顧一下上一篇，我們新增了以下Fragment Shader程式碼：

// index.html
<p id="fragmentShader">
+    varying vec3 vertexNormal;
    void main(void){
+      float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.));
+      vec3 atmosphere = vec3(.3, .6, 1.) * intensity;
+      gl_FragColor=vec4(atmosphere,0.) + vec4(0.,0.,0.2,1.);
-      gl_FragColor=vec4(0.,0.,0.2,1.);
    }
</p>
<p id="vertexShader">
    varying vec3 vertexNormal;
    void main(void){
      vertexNormal = normal;
      gl_Position=projectionMatrix*modelViewMatrix*vec4(position, 1.0);
    }
</p>
全視角的內光暈：為什麼鏡頭移動到後面就會有破綻？
前一篇提到，指向正Z軸的法線向量，其數值最小。這是因為，我們透過函式dot()，計算了每一個像素其法線向量跟正Z軸向量的內積。兩者越接近，intensity越小。

float intensity = 1.05 - dot(vertexNormal, vec3(0.,0.,1.0));
如果我們從場景上方（正Y軸）往下俯瞰，示意圖大概長這樣子：

https://ithelp.ithome.com.tw/upload/images/20221014/20142505cX2VGIJAOG.png

下圖中，紅色是vertexNormal大致的方向，灰色是vec3(0.,0.,1.0) 方向，而內積計算兩向量相近程度。intensity最終計算結果可得到：

https://ithelp.ithome.com.tw/upload/images/20221014/20142505mTASyi0QIP.png

因為鏡頭剛好位在正Z軸，所以剛好可以看到中心數值最小，周圍數值最大。但如果鏡頭離開正Z軸，就可以看到另外一面並不是如此。下圖可以見到鏡頭不再於Z軸。

https://ithelp.ithome.com.tw/upload/images/20221014/20142505tO3VnQyW2W.png

Untitled

那解決的方法很簡單：

目前我們已經知道，我們只要提供dot()兩個向量（法線向量、位置向量），就可以兩向量的相似度，製作光暈。以目前的狀況來說，我們提供正z軸(0.,0.,1.)拿去跟法線向量計算，所以光暈只有從正z軸的方向看才有正確的光暈，從別的方向看就會破功。

那很簡單，我們就將鏡頭的位置，取代正z軸的位置，使得鏡頭不管往哪個方向看，都是正確的光暈。

那我們就試試看將鏡頭的數值，傳送到fragment shader中。

全視角的內光暈：將鏡頭位置傳送到Fragment Shader
在從javascript傳送鏡頭位置到Fragment Shader之前，先說明當前的程式碼。目前在three.js，我們建立了一個ShaderMaterial，它提供我們撰寫兩個shader。

const mat = new THREE.ShaderMaterial({
	fragmentShader: fragment,
	vertexShader: vertex
})
為了傳送數值，我們必須將數值放到參數裡面。最快的方法，就是加入uniform。如果你不知道uniform是什麼的話，我們有在「Day23: WebGL Shader——快認識速Shader並實作」使用過。如果你還是沒有印象為什麼要用uniform的話，我先在下面簡單解釋一下，再回來繼續討論。

全視角的內光暈：簡單解釋傳入參數的種類
我們可以從javascript 傳入參數到 vertex shader以及fragment shader，但傳入的參數有種類之分。傳入的種類我這邊介紹兩種最常用的：一種可以傳入buffer資料（可用來描述一連串位置、UV、Normal），稱作attribute；另一種可以傳入單一變數稱為uniform。

shader需要得知類型（不是型別喔）才可以運作。而three.js為了確保開發者傳入正確的類型，所以有了這樣的物件架構：

new THREE.ShaderMaterial({
	類別: { // 如uniform
		物件名稱: { // 如myPosition
			value: xxxx // 如0.5
		}
	}
})
透過上面的物件，three.js將可以幫我們把參數傳送到下面程式碼的myPosition中：

    uniform vec3 myPosition;
    void main(void){
        ...
    }
這就是簡單的解釋。我們繼續討論如何從javascript 傳入數值到vertex shader以及fragment shader：

全視角的內光暈：從javascript傳入參數
傳入的方法如下：

const control = new OrbitControls(camera, renderer.domElement);
+ const myPosition = control.object.position.clone().normalize()

const mat = new THREE.ShaderMaterial({
	fragmentShader: fragment,
	vertexShader: vertex,
+	uniforms: {
+		cameraPosition: {
+			value: myPosition
+		}
+	}
})
由上面可見，除了vertex shader以及fragment shader以外，我還抓取了鏡頭位置myPosition。

我用clone()避免影響原本的數值，再用normalize()使myPosition的長度變成只有一單位的單位向量。
如此一來，即使鏡頭起初位置隨便設定，都可以正確的呈現內光暈

// 鏡頭改成位在Y軸
+ camera.position.set(0, 30, 0);
- camera.position.set(14, 30, 20);
其內光暈也能正確顯示：

https://ithelp.ithome.com.tw/upload/images/20221014/20142505DcRd8bNtB5.png

全視角的內光暈：鏡頭移動時，動態傳入參數
OrbitControl有可以傾聽點擊事件，加上點擊事件之後，就可以在每幀滑鼠移動時，傳入滑鼠位置到shader。

const addSphere = () => {
		...
		const myPosition = control.object.position.clone().normalize()
		const mat = new THREE.ShaderMaterial({
			...
		})
		...
	}

	const mesh = addSphere()

+	let cameraPosition = control.object.position.clone().normalize()
+	const onCameraChange = (event) => {
+		const control = event.target
+		cameraPosition = control.object.position.clone().normalize()
+		mesh.material.uniforms.orbitcontrolPosition.value = cameraPosition
+	}
+	control.addEventListener('change', onCameraChange)
如此一來，當鏡頭移動時，面向鏡頭的球面，其shader計算結果永遠都是最小。

成品
Untitled

CodePen
https://ithelp.ithome.com.tw/upload/images/20221014/20142505iip6xVUL3r.png

https://codepen.io/umas-sunavan/pen/poVYJYx?editors=1010

二、內光暈在地球的應用
我們有了內光暈，如果可以套用在地球上，就能夠相當完美。

有內光暈的地球
earth.gif

沒有內光暈的地球
Untitled

要怎麼製作具有內光暈的地球呢？有兩個方法：

用混合模式的作法，將光暈疊在地球上
將材質圖傳入shader，在shader上製作材質
我們使用第一個作法。

內光暈在地球的應用：準備程式碼
我們可以直接把我們在第十一天的程式碼搬過來用：

CodePen
https://ithelp.ithome.com.tw/upload/images/20221014/20142505Ms8cHob6cL.png

https://codepen.io/umas-sunavan/pen/yLjwNrQ?editors=0010

內光暈在地球的應用：大概介紹所準備的程式碼
基本上，就是將地球、雲以及其材質圖添加在

// 加入天球
const skydomeMaterial = ...
const skydomeGeometry = ...
const skydome = ...
scene.add(skydome);

// 新增環境光
const addAmbientLight = () => {
	...
}

// 新增點光
const addPointLight = () => {
	...
}

// 新增平行光
const addDirectionalLight = () => {
	...
}

addPointLight()
addAmbientLight()
addDirectionalLight()

// 加入地球
const earthGeometry = ...
const earthMaterial = ..
const earth = new THREE.Mesh(earthGeometry, earthMaterial);
scene.add(earth);

// 加入雲
const cloudGeometry = ...
const cloudMaterial = ...
const cloud = new THREE.Mesh(cloudGeometry, cloudMaterial);
scene.add(cloud);

function animate() {
	...
// 旋轉物件
	earth.rotation.y +=0.005
	cloud.rotation.y +=0.004
	skydome.rotation.y += 0.001

}
添加之後，會先看到地球，因為地球比我們的內光暈球體還要大

https://ithelp.ithome.com.tw/upload/images/20221014/20142505FZjgvkA0sD.png

內光暈在地球的應用：放大光暈
使光暈的球體比地球大，就可以呈現光暈效果。

const addSphere = () => {
	const vertex = document.getElementById('vertexShader').innerHTML
	const fragment = document.getElementById('fragmentShader').innerHTML
+	const geo = new THREE.SphereGeometry(5.39, 60, 60)
-	const geo = new THREE.SphereGeometry(5, 60, 60)
	const myPosition = control.object.position.clone().normalize()
	...
}
雖然說此舉可以添加光暈，但也使得陸地跟海洋看不到了，因為被光暈的球體包覆住。

https://ithelp.ithome.com.tw/upload/images/20221014/201425056rpuZfnO7Q.png

內光暈在地球的應用：混合模式
為了解決這個問題，我們加上混合模式，並且設定光暈為半透明。

const addSphere = () => {
		const vertex = document.getElementById('vertexShader').innerHTML
		const fragment = document.getElementById('fragmentShader').innerHTML
		const geo = new THREE.SphereGeometry(5.39, 60, 60)
		const myPosition = control.object.position.clone().normalize()
		const mat = new THREE.ShaderMaterial({
+			transparent: true,
+			blending: THREE.AdditiveBlending,
			vertexShader: vertex,
			uniforms: {
				orbitcontrolPosition: {
					value: myPosition
				}
			}
		})
		const mesh = new THREE.Mesh(geo, mat)
		scene.add(mesh)
		return mesh
	}
內光暈在地球的應用：成品
Untitled

CodePen
https://ithelp.ithome.com.tw/upload/images/20221014/20142505NMbgUFZGgf.png

https://codepen.io/umas-sunavan/pen/PoeLPad?editors=1010

小結
由於Shader的概念很難解釋，在這幾篇文章中，我重複的用多種說法解釋Shader，就是希望能夠完整的幫助大家釐清Shader的概念。

我們成功的建立了具有光暈的地球，下一篇將介紹如何透過shader，製作邊框。

參考資料
GLSL 三种变量类型（uniform，attribute和varying）理解

有時候我們會需要給一個物件邊框。無論是要讓物件在背景中突出、點選物件時有選中的感覺，或是在綠幕上有比較好裁切，物件邊框都能達到我們所需要的需求。

本篇介紹篇框，作為30天鐵人賽的最後一篇。

本篇內容
簡單形狀邊框——物件放大
複雜形狀的邊框——用Normal調整裁剪範圍
LowPoly形狀的邊框——用OutlinePass
完成品
https://storage.googleapis.com/umas_public_assets/michaelBay/day30/Untitled%20(94).gif

簡單形狀邊框——物件放大
邏輯很簡單，複製本體，讓複製品比本體大一點點，就可以形成邊框了。

準備程式碼
我們直接沿用上一篇的程式碼即可。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505WLL6SKeGdm.png

https://codepen.io/umas-sunavan/pen/vYjPRmZ?editors=1010

建立邊框物件
我們製作另一個球體，取代它的materail，使其呈現白色，並且些微放大，即可完成。

	const mesh = addSphere()
	scene.add(mesh)
+	const outline = addSphere()
+	outline.material = new THREE.MeshBasicMaterial({color: 0xffffff, side: THREE.BackSide})
+	outline.geometry.scale(1.05,1.05,1.05)
+	scene.add(outline)
https://ithelp.ithome.com.tw/upload/images/20221015/20142505BOQ9L6C7Bl.png

但這個作法的缺點在於，邊框會隨著鏡頭放大而放大。如下圖：

https://ithelp.ithome.com.tw/upload/images/20221015/201425057ONToS1xUs.png

而且，這樣的作法將使得錨點數目倍增。

同樣的方法，也可以透過Shader來達成，我繼續說明。

複雜形狀的邊框——用Normal調整裁剪範圍
前一個方法相當好用，因為形狀簡單。但如果我們面對一個形狀複雜的物件，這個方法就不太合適了。

我們把前一篇同樣的邏輯，套用在比較複雜的物體的話：

- const geo = new THREE.SphereGeometry(5, 12, 12)
+ const geo = new THREE.TorusKnotGeometry( 10, 3, 100, 16 );
https://ithelp.ithome.com.tw/upload/images/20221015/201425056mVdcglgac.png

為什麼有些邊框比較細，有些邊框比較粗？如果我們設定wireframe是true，就可以知道其中的構造。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505giH8CTHSYn.png

可以看到，由於物件是整理放大，所以並不是所有的面都向「外」突出。離中心越遙遠的地方，突出越是明顯，但離中心比較近的地方，突出非常不明顯。

而這也使得我們必須要用比較複雜的方法來處理。

如果我們加上這行程式碼，就可以解決這個問題。

	const mesh = addSphere()
	scene.add(mesh)
	const outline = addSphere()
+	outline.material.onBeforeCompile = shader => {      
+	  const token = `#include <begin_vertex>`
+	  const customTransform = `vec3 transformed = position + objectNormal*0.05;`
+	  shader.vertexShader = shader.vertexShader.replace(token,customTransform)
+	}
-	outline.material = new THREE.MeshBasicMaterial({color: 0xffffff, side: THREE.BackSide})
-	outline.geometry.scale(1.05,1.05,1.05)
	scene.add(outline)
WebGL會編譯GLSL，因為它不像javascript是腳本語言，而onBeforeCompile 將會在編譯之前執行。所以，即使我們已經在HTML準備好Shader程式碼，仍然可以在這裡進行修改。

我準備了token，只要shader有包含token的文字，就會換成update文字。如此一來就可以修改shader邏輯，同時又不影響本體物件的Shader。

在上面總共修改了一處vertex shader。

其中，#include <begin_vertex>就是在vertext shader當中的一段程式碼，從整個shader上下文大概可以知道 這行主要在描述每個錨點應該如何呈現。

而position就是每個錨點的位置，objectNormal就是每個面的垂直向量。作由將垂直向量向外延伸0.05，讓每個面依據自己的垂直normal向外延伸。

如果我們開啟wireframe預覽的話就可以看到黑色的物件是怎麼放大的。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505UhEoGuQTyo.png

過去在「Day23: WebGL Shader——從認識GLSL開始釐清Shader」有提到，vertex shader很重要的任務，就是取得渲染的裁剪範圍，這使得fragment shader知道應該要修改哪些像素的顏色。

position 改成 position+normal*0.5，能夠擴大裁剪範圍。這是因為每一個錨點，都往他們的法線向量位移了，而法線向量都是朝外的（除非有其他貼圖設定），所以就直接向外擴大了。

LowPoly形狀的邊框——用OutlinePass
同樣的邏輯，面對面數比較少的物件，就會出現破綻。

+	const addBook = async () => {
+			const path = 'https://storage.googleapis.com/umas_public_assets/michaelBay/day30/book06%20outline.gltf'
+			const gltf = await new GLTFLoader().loadAsync(path);
+			const mesh = gltf.scene
+			gltf.scene.traverse(object => {
+				if (object.isMesh) {
+					object.castShadow = true
+					object.receiveShadow = true
+				}
+			})
+			return mesh
+		}
	
+	const book = await addBook()
-	const mesh = await addSphere()
+	scene.add(book);
-	scene.add(mesh);
https://ithelp.ithome.com.tw/upload/images/20221015/20142505xJT6cckd77.png

要了解決這個問題，已經有神人開發出了OutlinePass，pass像是一個濾鏡，只要套用，就能透過其本身的shader，去增加指定物件的邊框。

如果有興趣，可以看它程式碼是怎麼寫的。

https://ithelp.ithome.com.tw/upload/images/20221015/20142505feP0b6PCN8.png

我們先引入套件：

+import { OutlinePass } from 'https://unpkg.com/three@latest/examples/jsm/postprocessing/OutlinePass';
+import { EffectComposer } from 'https://unpkg.com/three@latest/examples/jsm/postprocessing/EffectComposer';
+import { RenderPass } from 'https://unpkg.com/three@latest/examples/jsm/postprocessing/RenderPass';
接著加上Composer：

+const initComposer = () => {
+    composer = new EffectComposer(renderer);
+    var renderPass = new RenderPass(scene, camera);
+   composer.addPass(renderPass);
+    outlinePass = new OutlinePass(new THREE.Vector2(window.innerWidth, window.innerHeight), scene, camera);
+		outlinePass.selectedObjects = [book];
+	}
+	initComposer()
最後，修改animate()

function animate() {
	requestAnimationFrame(animate);
- renderer.render(scene, camera);
+	if (composer) {
+		composer.render();
+		outlinePass.edgeStrength = 80
+		outlinePass.edgeThickness = 4
+		console.log(outlinePass.edgeStrength);
+	}

}
animate();
完成品
https://storage.googleapis.com/umas_public_assets/michaelBay/day30/Untitled%20(94).gif

CodePen
https://ithelp.ithome.com.tw/upload/images/20221015/20142505zHJha5Kdt9.png

https://codepen.io/umas-sunavan/pen/eYrXrmz

參考資料
outlinePass教學
shader放大原理
outlinePass github


.
iT邦幫忙行銷！就用中文網址輔助租虛擬主機架站，再附信箱全新系列【數位轉型攻略 IV：戰略新 IT】
iT邦幫忙
技術問答
技術文章
iT 徵才
Tag
聊天室
2022 鐵人賽
鐵人發文
發問
發文 
技術
徵才
伍瑪斯
我的主頁
我的發問
我的回答
我的發文
追蹤的問答
追蹤的文章
追蹤的tag
追蹤的邦友
邀請我回答
設定
找邦友
登出
恭喜完賽！這是此系列第 31 天的文章了。
Software Development 
30天成為鍵盤麥可貝：前端視覺特效開發實戰
Day31: 完賽心得
# 這是對自己負責的比賽

這一路走來真的非常辛苦，而且很多時候是對自己負責任。

我當然可以每篇寫一點點，然後分成好幾篇寫，但我不要灌水。我希望可以把一直以來所學習的知識無私的跟大家分享，就像我從網路上從大家身邊學到前端視覺特效一樣。

我的知識是來自於大家的，當然要奉獻給大家。而且，不必再像我一樣頻頻繞路頻頻卡關了。我秉持這個信念，最終完成鐵人賽。

### 趕稿時的糾結

我完成30天鐵人在只是幸運，我很幸運這過程中並不是只有我，更多的是朋友、同事、上司的支持與鼓勵，我才能連續不斷撰寫。

我以為我有足夠的文章備存可以連續貼30天。但我真的沒辦法接受我發佈一個讓人看不懂的筆記，並且讓人從中找答案。所以即使我有30天的備存，我仍然會找很多網路資源反覆驗證，並且繪製圖片加以解說，為的就是讓人看得懂，並且學到東西，而不是帶著一個問題造訪我的文章，然後帶著更多問題離開。

為了使文章看得懂，我盡量將文字描述的比較線性，比較直觀。所以在寫法上，我會不斷的從理論穿插實作，從實作再帶出理論。我相信這樣的作法，不僅可以讓理論看起來比較落地，也可以很線性的描述一件事情而不致於發散。我希望這樣的論述方法是能有所幫助的。

### 我很感謝大家幫忙我完成的小小夢想

30天比我想像中的長很多，前半段衝勁很強。我印象很深刻，這陣子都寫到三點快四點才睡覺，隔天睡眼惺忪的去上班。甚至有一次不小心睡過頭，幸好公司的HR知道我是因為參加鐵人賽，所以也沒有扣我的考績，只是叮嚀我要早點睡較不然身體容易壞掉。

有一個離職的前同事剛好也要學three.js，他每天都看我的文章，並且提出疑問，他幫助我很多，修正我寫稿的一些盲點，使得文章更好懂。其它在職的同事，沒事也會幫我「抓錯字」，幫我看哪裡怪怪的，告訴我哪邊的錯字要改，十分貼心。

### 這不是我的成就，是大家的成就

這30天以來，身邊的每個人都在幫忙完成我30天鐵人賽的小小夢想，他們使出畢生專業幫我校稿。

例如太空科學博士畢業的同事，他幫我看了經緯度座標轉換的問題，還有地理系畢業的同事也不時幫我看問題，我身邊的數學老師也幫我看內積的描述是否正確，還有在遊戲業做美術的朋友幫我補充貼圖的知識，這些使得我的30天鐵人賽更完美。

### 鐵人賽在辦公室發生的趣事

我的同事也都很關心我的瀏覽量。他們認為我的文章標題像是教科書一樣死板，所以幫我分析了我的目標客群，然後用一堆梗當作文章標題，希望可以讓文章有趣一點。

每天早上我一到辦公室，他們就會要我觀察文章發布的流量，開一個非正式的站立會議，集思廣益的思考是什麼因素導致文章流量衝高，又或是什麼因素導致流量不如預期。

他們幫我處理「行銷」，甚至比我寫文章還認真。他們那時候討論的結果是：如果標題引用動漫《七大罪》，則流量低迷，代表我的目標客群根本沒在看《七大罪》。相反的，他們發現《火影忍者》流量普遍很高，所以隔天的文章標題就下《火影忍者》。

最後，他們之中還出現了「Marketing Leader」，幫我衝瀏覽量，他們玩得超級開心，殊不知我則是每天趕稿痛苦萬分。

# 統計

這30天以來，我總共製作了500張圖片，其中68張是引用其他人的圖片。
這500張圖片中，有127張是動圖，373張是靜態圖片。

如果你每篇都有讀的話，可以獲得13個前端視覺特效作品。
在這期間，我也發佈了35個CodePen，[連結下收](https://codepen.io/collection/eJGNqY?grid_type=list)。

自製的圖片都是我一直一個繪製的，如果有需要引用，記得註明出處即可。

# 需要改進的地方

事實上我在後半段有幾次來不及發文，只好先發佈再修改。當我最後看到比賽規定明定「評審將看到發佈當天的快照」時，覺得蠻後悔的。因為後半段時間真的來不及使得一堆錯字、圖片連結失連，讓我挫折感很重。但我還是告訴自己要是後把「寫作債」給還一還。就算沒有辦法得獎，希望也能幫到大家。

寫到最後，跟一開始所設計的目錄有出入，這也是我應該改進的地方。下次應該要注意自己設計的是否有連貫性，這樣在閱讀時才能降低讀者的閱讀成本。

鐵人賽一直都會放在這裡，提供大家取用。我相信一定還有一些東西可以修改、優化，或是一些錯字，或是圖片授權問題。如果你有發現，歡迎寄信告訴我，我會立刻處理。不知道為什麼我沒辦法用站內信，所以歡迎用Email聯絡：

fareastsunflower@gmail.com

# 感謝

感謝一直以來幫助我完成鐵人賽的人，即使只是讀者，也帶給我很大的動力。

我相向我依然只是初學者，我會繼續網前端視覺特效發展。你會閱讀這系列文章，代表你也在網這個領域發展，那這就代表，我們很有機會相遇，到時候一定要多多指教，我們可以好好交流的！

# 這是對自己負責的比賽
​
這一路走來真的非常辛苦，而且很多時候是對自己負責任。
​
我當然可以每篇寫一點點，然後分成好幾篇寫，但我不要灌水。我希望可以把一直以來所學習的知識無私的跟大家分享，就像我從網路上從大家身邊學到前端視覺特效一樣。
​
我的知識是來自於大家的，當然要奉獻給大家。而且，不必再像我一樣頻頻繞路頻頻卡關了。我秉持這個信念，最終完成鐵人賽。
​
### 趕稿時的糾結
​
我完成30天鐵人在只是幸運，我很幸運這過程中並不是只有我，更多的是朋友、同事、上司的支持與鼓勵，我才能連續不斷撰寫。
​
我以為我有足夠的文章備存可以連續貼30天。但我真的沒辦法接受我發佈一個讓人看不懂的筆記，並且讓人從中找答案。所以即使我有30天的備存，我仍然會找很多網路資源反覆驗證，並且繪製圖片加以解說，為的就是讓人看得懂，並且學到東西，而不是帶著一個問題造訪我的文章，然後帶著更多問題離開。
​
為了使文章看得懂，我盡量將文字描述的比較線性，比較直觀。所以在寫法上，我會不斷的從理論穿插實作，從實作再帶出理論。我相信這樣的作法，不僅可以讓理論看起來比較落地，也可以很線性的描述一件事情而不致於發散。我希望這樣的論述方法是能有所幫助的。
​
### 我很感謝大家幫忙我完成的小小夢想
​
30天比我想像中的長很多，前半段衝勁很強。我印象很深刻，這陣子都寫到三點快四點才睡覺，隔天睡眼惺忪的去上班。甚至有一次不小心睡過頭，幸好公司的HR知道我是因為參加鐵人賽，所以也沒有扣我的考績，只是叮嚀我要早點睡較不然身體容易壞掉。
​
有一個離職的前同事剛好也要學three.js，他每天都看我的文章，並且提出疑問，他幫助我很多，修正我寫稿的一些盲點，使得文章更好懂。其它在職的同事，沒事也會幫我「抓錯字」，幫我看哪裡怪怪的，告訴我哪邊的錯字要改，十分貼心。
​
### 這不是我的成就，是大家的成就
​
這30天以來，身邊的每個人都在幫忙完成我30天鐵人賽的小小夢想，他們使出畢生專業幫我校稿。
​
例如太空科學博士畢業的同事，他幫我看了經緯度座標轉換的問題，還有地理系畢業的同事也不時幫我看問題，我身邊的數學老師也幫我看內積的描述是否正確，還有在遊戲業做美術的朋友幫我補充貼圖的知識，這些使得我的30天鐵人賽更完美。
​
### 鐵人賽在辦公室發生的趣事
​
我的同事也都很關心我的瀏覽量。他們認為我的文章標題像是教科書一樣死板，所以幫我分析了我的目標客群，然後用一堆梗當作文章標題，希望可以讓文章有趣一點。
​
每天早上我一到辦公室，他們就會要我觀察文章發布的流量，開一個非正式的站立會議，集思廣益的思考是什麼因素導致文章流量衝高，又或是什麼因素導致流量不如預期。
​
他們幫我處理「行銷」，甚至比我寫文章還認真。他們那時候討論的結果是：如果標題引用動漫《七大罪》，則流量低迷，代表我的目標客群根本沒在看《七大罪》。相反的，他們發現《火影忍者》流量普遍很高，所以隔天的文章標題就下《火影忍者》。
​
最後，他們之中還出現了「Marketing Leader」，幫我衝瀏覽量，他們玩得超級開心，殊不知我則是每天趕稿痛苦萬分。
​
# 統計
​
這30天以來，我總共製作了500張圖片，其中68張是引用其他人的圖片。
這500張圖片中，有127張是動圖，373張是靜態圖片。
​
如果你每篇都有讀的話，可以獲得13個前端視覺特效作品。
在這期間，我也發佈了35個CodePen，[連結下收](https://codepen.io/collection/eJGNqY?grid_type=list)。
​
自製的圖片都是我一直一個繪製的，如果有需要引用，記得註明出處即可。
​
# 需要改進的地方
​
事實上我在後半段有幾次來不及發文，只好先發佈再修改。當我最後看到比賽規定明定「評審將看到發佈當天的快照」時，覺得蠻後悔的。因為後半段時間真的來不及使得一堆錯字、圖片連結失連，讓我挫折感很重。但我還是告訴自己要是後把「寫作債」給還一還。就算沒有辦法得獎，希望也能幫到大家。
​
寫到最後，跟一開始所設計的目錄有出入，這也是我應該改進的地方。下次應該要注意自己設計的是否有連貫性，這樣在閱讀時才能降低讀者的閱讀成本。
​
鐵人賽一直都會放在這裡，提供大家取用。我相信一定還有一些東西可以修改、優化，或是一些錯字，或是圖片授權問題。如果你有發現，歡迎寄信告訴我，我會立刻處理。不知道為什麼我沒辦法用站內信，所以歡迎用Email聯絡：
​
fareastsunflower@gmail.com
​
# 感謝
​
感謝一直以來幫助我完成鐵人賽的人，即使只是讀者，也帶給我很大的動力。
​
我相向我依然只是初學者，我會繼續網前端視覺特效發展。你會閱讀這系列文章，代表你也在網這個領域發展，那這就代表，我們很有機會相遇，到時候一定要多多指教，我們可以好好交流的！
​
這是對自己負責的比賽
這一路走來真的非常辛苦，而且很多時候是對自己負責任。

我當然可以每篇寫一點點，然後分成好幾篇寫，但我不要灌水。我希望可以把一直以來所學習的知識無私的跟大家分享，就像我從網路上從大家身邊學到前端視覺特效一樣。

我的知識是來自於大家的，當然要奉獻給大家。而且，不必再像我一樣頻頻繞路頻頻卡關了。我秉持這個信念，最終完成鐵人賽。

趕稿時的糾結
我完成30天鐵人在只是幸運，我很幸運這過程中並不是只有我，更多的是朋友、同事、上司的支持與鼓勵，我才能連續不斷撰寫。

我以為我有足夠的文章備存可以連續貼30天。但我真的沒辦法接受我發佈一個讓人看不懂的筆記，並且讓人從中找答案。所以即使我有30天的備存，我仍然會找很多網路資源反覆驗證，並且繪製圖片加以解說，為的就是讓人看得懂，並且學到東西，而不是帶著一個問題造訪我的文章，然後帶著更多問題離開。

為了使文章看得懂，我盡量將文字描述的比較線性，比較直觀。所以在寫法上，我會不斷的從理論穿插實作，從實作再帶出理論。我相信這樣的作法，不僅可以讓理論看起來比較落地，也可以很線性的描述一件事情而不致於發散。我希望這樣的論述方法是能有所幫助的。

我很感謝大家幫忙我完成的小小夢想
30天比我想像中的長很多，前半段衝勁很強。我印象很深刻，這陣子都寫到三點快四點才睡覺，隔天睡眼惺忪的去上班。甚至有一次不小心睡過頭，幸好公司的HR知道我是因為參加鐵人賽，所以也沒有扣我的考績，只是叮嚀我要早點睡較不然身體容易壞掉。

有一個離職的前同事剛好也要學three.js，他每天都看我的文章，並且提出疑問，他幫助我很多，修正我寫稿的一些盲點，使得文章更好懂。其它在職的同事，沒事也會幫我「抓錯字」，幫我看哪裡怪怪的，告訴我哪邊的錯字要改，十分貼心。

這不是我的成就，是大家的成就
這30天以來，身邊的每個人都在幫忙完成我30天鐵人賽的小小夢想，他們使出畢生專業幫我校稿。

例如太空科學博士畢業的同事，他幫我看了經緯度座標轉換的問題，還有地理系畢業的同事也不時幫我看問題，我身邊的數學老師也幫我看內積的描述是否正確，還有在遊戲業做美術的朋友幫我補充貼圖的知識，這些使得我的30天鐵人賽更完美。

鐵人賽在辦公室發生的趣事
我的同事也都很關心我的瀏覽量。他們認為我的文章標題像是教科書一樣死板，所以幫我分析了我的目標客群，然後用一堆梗當作文章標題，希望可以讓文章有趣一點。

每天早上我一到辦公室，他們就會要我觀察文章發布的流量，開一個非正式的站立會議，集思廣益的思考是什麼因素導致文章流量衝高，又或是什麼因素導致流量不如預期。

他們幫我處理「行銷」，甚至比我寫文章還認真。他們那時候討論的結果是：如果標題引用動漫《七大罪》，則流量低迷，代表我的目標客群根本沒在看《七大罪》。相反的，他們發現《火影忍者》流量普遍很高，所以隔天的文章標題就下《火影忍者》。

最後，他們之中還出現了「Marketing Leader」，幫我衝瀏覽量，他們玩得超級開心，殊不知我則是每天趕稿痛苦萬分。

統計
這30天以來，我總共製作了500張圖片，其中68張是引用其他人的圖片。
這500張圖片中，有127張是動圖，373張是靜態圖片。

如果你每篇都有讀的話，可以獲得13個前端視覺特效作品。
在這期間，我也發佈了35個CodePen，連結下收。

自製的圖片都是我一直一個繪製的，如果有需要引用，記得註明出處即可。

需要改進的地方
事實上我在後半段有幾次來不及發文，只好先發佈再修改。當我最後看到比賽規定明定「評審將看到發佈當天的快照」時，覺得蠻後悔的。因為後半段時間真的來不及使得一堆錯字、圖片連結失連，讓我挫折感很重。但我還是告訴自己要是後把「寫作債」給還一還。就算沒有辦法得獎，希望也能幫到大家。

寫到最後，跟一開始所設計的目錄有出入，這也是我應該改進的地方。下次應該要注意自己設計的是否有連貫性，這樣在閱讀時才能降低讀者的閱讀成本。

鐵人賽一直都會放在這裡，提供大家取用。我相信一定還有一些東西可以修改、優化，或是一些錯字，或是圖片授權問題。如果你有發現，歡迎寄信告訴我，我會立刻處理。不知道為什麼我沒辦法用站內信，所以歡迎用Email聯絡：

fareastsunflower@gmail.com

感謝
感謝一直以來幫助我完成鐵人賽的人，即使只是讀者，也帶給我很大的動力。

我相向我依然只是初學者，我會繼續網前端視覺特效發展。你會閱讀這系列文章，代表你也在網這個領域發展，那這就代表，我們很有機會相遇，到時候一定要多多指教，我們可以好好交流的！

已輸入1989字
Tag 14th鐵人賽three.js
系統標準時間 UTC+0800 2022年 10月 16日 17:13:40 

本站編輯器採Markdown語法，請勿使用HTML Code，以避免內容濾掉無法呈現

Markdown常用語法
```
程式碼區塊
```
*斜體*
**粗體**
> 引用
---分隔線
- 列點1
- 列點2
- 列點3
# H1標題
## H2標題
### H3標題
詳細說明

電週文化事業版權所有、轉載必究 | Copyright © iThome 刊登廣告 授權服務 服務信箱 隱私權聲明與會員使用條款 iT邦幫忙使用說明
 
Tip
儲存成功
OK  